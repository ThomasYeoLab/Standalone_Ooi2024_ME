# Code for Multilayer Meta-matching examples

----

## References
+ Chen, P., An, L., Wulan, N., Zhang, C., Zhang, S., Ooi, L. Q. R., ... & Yeo, B. T. (2023). [**Multilayer meta-matching: translating phenotypic prediction models from multiple datasets to small data**](https://www.biorxiv.org/content/10.1101/2023.12.05.569848v1.abstract). bioRxiv, 2023-12.

----

## Usage

### 1. Generate fake data
In this example, we use fake data generated by following code:
```bash
cd $CBIG_CODE_DIR/stable_projects/predict_phenotypes/Chen2024_MMM/examples
python data_generate.py -d exp
```

### 2. Classical KRR
Run the classical KRR:
```matlab
CBIG_CODE_DIR = getenv('CBIG_CODE_DIR');
base_dir = fullfile(CBIG_CODE_DIR, 'stable_projects', 'predict_phenotypes', 'Chen2024_MMM');
example_dir = fullfile(base_dir, 'examples');
cd(example_dir);

code_dir = fullfile(base_dir, 'KRR_CLASSICAL');
input_dir = fullfile(example_dir, 'exp_input');
output_dir = fullfile(example_dir, 'exp_output', 'output_KRR_classical_exp_test');
subj_list = fullfile(input_dir, 'exp_test', 'exp_test_subj_list.txt');
phe_csv = fullfile(input_dir, 'exp_test', 'exp_test_phe_tab.csv');
FC_file = fullfile(input_dir, 'exp_test', 'exp_test_fc.mat');
phe_list = fullfile(input_dir, 'exp_test', 'exp_test_phe_list.txt');
temp = textscan(fopen(phe_list), '%s');
phes = temp{1};
ks = {'10', '20', '50', '100', '200'};
rngs_num = 3; % run the Classical KRR 3 times with 3 different split of K shot

addpath(code_dir);
for i = 1:length(phes)
    for j = 1:length(ks)
        CBIG_MMM_KRR_classical(CBIG_CODE_DIR, subj_list, phe_csv, FC_file, output_dir, rngs_num, phes{i}, ks{j}, false, 'exp_test');
    end
end

% After KRR classical in previous section finished, run following code to get result summary:
CBIG_MMM_KRR_classical_summary(CBIG_CODE_DIR, output_dir, phe_list, rngs_num, 'exp_test')

% Check the result by
result_file = fullfile(output_dir, 'final_result', 'krr_classical_res.mat');
result = load(result_file);
disp(squeeze(mean(mean(result.meta_cor, 2), 1)))
% reference disp result:    0.1720    0.2926    0.4480    0.6349    0.8830
% average correlation for K = 10        20        50        100       200
disp(squeeze(mean(mean(result.meta_cod, 2), 1)))
% reference disp result:    0.0137    0.0456    0.1893    0.3963    0.7765
% average COD for         K = 10        20        50        100       200
```
You can check the result you got against the result with the one in `unit_tests\ref_results\output_KRR_classical_exp_test` folder.


### 3. Get spilt files for target datasets
The transfer learning / meta-matching methods use the split from KRR classical, if you want to run it, you need to run following command to get the split:
```bash
python ../cbig/Chen2024/CBIG_get_split.py -d exp_test
```

### 4. Run DNN
Run following code below. The base DNN model need GPU to run, or you may want to modify the code to use CPU only. You can check the comment for the reference result. Please note, this is just a generated data, please refer to the `Chen2024_MMM/replication` folder for the performance on real dataset. 

#### Train DNN base model on extra-large dataset
```bash
cd $CBIG_CODE_DIR/stable_projects/predict_phenotypes/Chen2024_MMM/examples

# base model training
python ../cbig/Chen2024/CBIG_dnn_xlarge_train.py --exp-dataset --seed 1 --epochs 100 --metric cod --weight_decay 1e-7 --lr 0.01 --dropout 0.2 --n_l1 64 --n_l2 64 --n_l3 64 --n_hidden_layer 2  --batch_size 64 --patience 25
# Best validation at index:  62
# Average validation corr: 0.9546750770647563 , COD: 0.869054946491375 , MAE: 54.97544166266766

```

#### Use DNN models to predict phenotypes for target datasets
```bash
python ../cbig/Chen2024/CBIG_dnn_xlarge_predict.py --exp-dataset
```

### 5. Transfer learning to target datasets
#### Fine-tune the DNN model on example data
```bash
python ../cbig/Chen2024/CBIG_dnn_transfer_learning.py --exp-dataset
# rng 2 at 157.14953351020813s: cor 0.07753, cod -0.21406
# 0.014673 -0.020953 0.082497 0.128478 0.182967  COD  -0.457202 -0.391503 -0.158148 -0.071458 0.008007
```

### 6. Train Ridge Regressiion base models
#### Train LRR on example data (extra-large) for each phenotype
```bash
for phe in `seq 0 9`; do
  python ../cbig/Chen2024/CBIG_rr_xlarge_train.py --phe_idx ${phe} --exp-dataset
done
```
#### Use LRR models (trained on extra-large example data) to predict phenotypes for other datasets
```bash
python ../cbig/Chen2024/CBIG_rr_xlarge_predict.py --exp-dataset
```
#### Train LRR on large source dataset and apply on test data
```bash
for phe in `seq 0 9`; do
  python ../cbig/Chen2024/CBIG_rr_large.py --phe_idx ${phe} --exp-dataset
done
```
#### Train LRR on medium source datasets and apply on test data
```bash
for phe in `seq 0 9`; do
  python ../cbig/Chen2024/CBIG_rr_medium.py --phe_idx ${phe} --exp-dataset
done
```
#### Train 2-layer KRR stacking model on large source dataset and apply on test data
Apply meta-matching from large source dataset to train KRR on medium source dataset, and then applied on test data
```bash
for phe in `seq 0 9`; do
  python ../cbig/Chen2024/CBIG_rr_large.py --phe_idx ${phe} --exp-dataset --2layer
done
```
#### Train 2-layer KRR stacking model on medium source datasets and apply on test data
Wait until previous step ends. Apply meta-matching from extra-large source dataset + large source dataset to train KRR on medium source dataset, and then applied on test data
```bash
for phe in `seq 0 9`; do
  python ../cbig/Chen2024/CBIG_rr_medium.py --phe_idx ${phe} --exp-dataset --2layer
done
```

### 7. Run meta-matching (stacking)
#### Meta-matching with stacking
```bash
python ../cbig/Chen2024/CBIG_mm_stacking.py --exp-dataset --log_stem MM_stacking
# rng 2 at 4.250676870346069s: cor 0.11912, cod 0.01135
# 0.079757 0.079060 0.126949 0.146134 0.163710  COD  0.000831 -0.029663 0.016120 0.028659 0.040813
```
#### Meta-matching with dataset stacking
```bash
python ../cbig/Chen2024/CBIG_mm_stacking.py --exp-dataset --log_stem dataset_stacking
# rng 2 at 8.11669111251831s: cor 0.68122, cod 0.41964
# 0.411921 0.678489 0.735264 0.775562 0.804886  COD  0.136736 0.311514 0.466580 0.552877 0.630481

```
#### Meta-matching with multilayer stacking
```bash
python ../cbig/Chen2024/CBIG_mm_stacking.py --exp-dataset --log_stem multilayer_stacking
# rng 2 at 7.4700329303741455s: cor 0.79568, cod 0.53390
# 0.546794 0.789654 0.845972 0.889568 0.906412  COD  0.175090 0.408757 0.579515 0.710372 0.795763
```

----

## Bugs and Questions
Please contact Pansheng Chen at chenpansheng@gmail.com, Lijun An at anlijun.cn@gmail.com, and Chen Zhang at chenzhangsutd@gmail.com.
