{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bddec446",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb95530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import scipy.stats\n",
    "sys.path.insert(0, '/home/leon_ooi/storage/CBIG_private/stable_projects/predict_phenotypes/Ooi2024_ME/curve_fitting')\n",
    "import CBIG_ORSP_fns as orsp\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472720b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(orsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1986c",
   "metadata": {},
   "source": [
    "# Set directories and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important directories\n",
    "rep_dir = '/home/leon_ooi/storage/optimal_prediction/replication/'\n",
    "img_dir = rep_dir + 'Manuscript_Figures'\n",
    "varname_dir = '/home/leon_ooi/storage/optimal_prediction/github/Ooi2024_ORSP/utilities/variable_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HCP settings\n",
    "# colors for different N (real data)\n",
    "HCP_subcolors = sns.color_palette(\"blend:powderblue,darkslategrey\", n_colors=6)\n",
    "HCP_lgd = [plt.Line2D([], [], marker='.', color=HCP_subcolors[0], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=HCP_subcolors[1], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=HCP_subcolors[2], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=HCP_subcolors[3], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=HCP_subcolors[4], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=HCP_subcolors[5], linestyle='None')]\n",
    "# colors for different N (theoretical fit)\n",
    "HCP_theor_subcolors = sns.color_palette(\"blend:dodgerblue,black\", n_colors=6)\n",
    "# phenotype names\n",
    "HCP_scores = np.genfromtxt(os.path.join(varname_dir,'HCP_variables_short_names.txt'),\n",
    "                            dtype=str, delimiter='\\n')\n",
    "HCP_scores_short = np.genfromtxt(os.path.join(varname_dir,'HCP_variables_legend_names.txt'),\n",
    "                            dtype=str, delimiter='\\n')\n",
    "# different sets of scores\n",
    "# relaxed threshold\n",
    "HCP_abv01_ind = [0,1,2,3,4,5,6,7,8,10,12,14,15,16,18,22,23,24,25,26,29,31,32,34,43,47,48,51]\n",
    "HCP_sat = [0,1,2,3,4,5,6,7,8,10,14,15,16,18,22,23,25,26,29,31,32,34,43,47,48] # remove 12,24,51\n",
    "# strict threshold and subsets\n",
    "HCP_log_ind = [1,2,3,4,5,6,7,8,10,14,23,25,26,29,31,32,34,47]\n",
    "HCP_cog_ind = [1,2,3,4,5,6,8,10,25,26,29,59]\n",
    "HCP_emo_ind = [23]\n",
    "HCP_pers_ind = [7,31,32,34]\n",
    "HCP_phy_ind = [14]\n",
    "HCP_wb_ind = [47]\n",
    "# strict fit to theoretical model\n",
    "HCP_behav_ind_fullstrict = np.array([31,47,9,10,16,5,6,7,59])\n",
    "HCP_behav_ind_randomstrict = np.array([28,33,31,49,9,27,16,5,6,7,3,8,59])\n",
    "\n",
    "# indices for control conditions\n",
    "HCP_rs_log_ind = [1,2,3,4,5,6,7,8,10,14,23,25,26,29,31,32,34,47,59]\n",
    "HCP_mixdays_log_ind = [1,4,5,7,8,10,12,14,15,16,25,26,29,31,34,59]\n",
    "HCP_SC_log_ind = [1,3,4,5,7,8,14,22,26,29,31,50,59]\n",
    "HCP_1000_log_ind = [1,2,3,4,5,6,7,8,10,12,14,16,18,23,24,25,26,29,31,32,34,46,47,59]\n",
    "\n",
    "HCP_intersect = np.intersect1d(HCP_rs_log_ind, HCP_mixdays_log_ind)\n",
    "HCP_intersect = np.intersect1d(HCP_intersect, HCP_SC_log_ind)\n",
    "HCP_intersect = np.intersect1d(HCP_intersect, HCP_1000_log_ind)\n",
    "HCP_log_ind = HCP_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ABCD settings\n",
    "# colors for different N (real data)\n",
    "ABCD_subcolors = sns.color_palette(\"blend:mistyrose,darkred\", n_colors=9)\n",
    "ABCD_lgd = [plt.Line2D([], [], marker='.', color=ABCD_subcolors[0], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=ABCD_subcolors[1], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=ABCD_subcolors[2], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=ABCD_subcolors[3], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=ABCD_subcolors[4], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=ABCD_subcolors[5], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=ABCD_subcolors[6], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=ABCD_subcolors[7], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=ABCD_subcolors[8], linestyle='None')]\n",
    "# colors for different N (theoretical fit)\n",
    "ABCD_theor_subcolors = sns.color_palette(\"blend:orangered,black\", n_colors=9)\n",
    "# phenotype names\n",
    "ABCD_scores = np.genfromtxt(os.path.join(varname_dir,'ABCD_variables_short_names.txt'),\n",
    "                            dtype=str, delimiter='\\n')\n",
    "ABCD_scores_short = np.genfromtxt(os.path.join(varname_dir,'ABCD_variables_legend_names.txt'),\n",
    "                            dtype=str, delimiter='\\n')\n",
    "# different sets of scores\n",
    "# relaxed threshold\n",
    "ABCD_abv01_ind = [3,5,6,8,9,10,11,12,13,14,15,16,17,21,24,25,28,29,30,31,32,33]\n",
    "ABCD_sat = [3,5,6,8,9,10,11,12,13,14,15,16,17,21,24,25,28,29,30,31,32,33] # no scores removed\n",
    "# strict threshold and subsets\n",
    "ABCD_log_ind = [3,5,6,8,10,11,13,14,15,16,17,29,30,31,32,33]\n",
    "ABCD_cog_ind = [8,10,11,13,14,15,16,17,30,31,32,33,36]\n",
    "ABCD_mh_ind = [5,29,6,3]\n",
    "# strict fit to theoretical model\n",
    "ABCD_behav_ind_fullstrict = np.array([16,17,12,35])\n",
    "ABCD_behav_ind_randomstrict = np.array([15,16,17,12,35])\n",
    "\n",
    "# indices for control conditions\n",
    "ABCD_rs_log_ind = [3,5,6,8,10,11,13,14,15,16,17,29,30,31,32,33,36]\n",
    "ABCD_MID_log_ind = [8,9,10,11,13,14,15,16,17,21,30,31,32,33,35,36]\n",
    "ABCD_NBACK_log_ind = [5,8,9,10,11,13,14,15,16,17,25,27,28,30,31,32,33,35,36]\n",
    "ABCD_SST_log_ind = [6,8,10,11,13,14,15,16,17,21,27,28,30,31,32,33,35,36]\n",
    "\n",
    "ABCD_SC_log_ind = [6,8,10,13,14,15,16,17,25,29,31,32,33,36]\n",
    "ABCD_1000_log_ind = [5,6,8,9,10,11,13,14,15,16,17,29,30,31,32,33,34,36]\n",
    "ABCD_rst_intersect = np.intersect1d(ABCD_rs_log_ind, ABCD_SST_log_ind)\n",
    "ABCD_rst_intersect = np.intersect1d(ABCD_rst_intersect, ABCD_NBACK_log_ind)\n",
    "ABCD_rst_intersect = np.intersect1d(ABCD_rst_intersect, ABCD_MID_log_ind)\n",
    "ABCD_sc1000_intersect = np.intersect1d(ABCD_rs_log_ind, ABCD_SC_log_ind)\n",
    "ABCD_sc1000_intersect = np.intersect1d(ABCD_sc1000_intersect, ABCD_1000_log_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset colors and indices\n",
    "# SINGER\n",
    "SINGER_subcolors = sns.color_palette(\"blend:thistle,deeppink\", n_colors=6)\n",
    "SINGER_theor_subcolors = sns.color_palette(\"blend:plum,darkmagenta\", n_colors=6)\n",
    "SINGER_lgd = [plt.Line2D([], [], marker='.', color=SINGER_subcolors[0], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=SINGER_subcolors[1], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=SINGER_subcolors[2], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=SINGER_subcolors[3], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=SINGER_subcolors[4], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=SINGER_subcolors[5], linestyle='None')]\n",
    "SINGER_log_ind = [0,2,3,4,5,7,9,12,13,14,15,16,17,18]\n",
    "SINGER_scores = np.genfromtxt(os.path.join(varname_dir,'SINGER_y_variables.txt'), \\\n",
    "                            dtype=str, delimiter='\\n')\n",
    "\n",
    "# TCP\n",
    "TCP_subcolors = sns.color_palette(\"blend:lemonchiffon,goldenrod\", n_colors=6)\n",
    "TCP_theor_subcolors = sns.color_palette(\"blend:khaki,darkgoldenrod\", n_colors=6)\n",
    "TCP_lgd = [plt.Line2D([], [], marker='.', color=TCP_subcolors[0], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=TCP_subcolors[1], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=TCP_subcolors[2], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=TCP_subcolors[3], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=TCP_subcolors[4], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=TCP_subcolors[5], linestyle='None')]\n",
    "TCP_log_ind = [0,5,7,9,10,14,18]\n",
    "TCP_scores = np.genfromtxt(os.path.join(varname_dir,'TCP_y_variables.txt'), \\\n",
    "                            dtype=str, delimiter='\\n')\n",
    "\n",
    "# MDD\n",
    "MDD_subcolors = sns.color_palette(\"blend:linen,darkorange\", n_colors=10)\n",
    "MDD_theor_subcolors = sns.color_palette(\"blend:bisque,chocolate\", n_colors=10)\n",
    "MDD_lgd = [plt.Line2D([], [], marker='.', color=MDD_subcolors[0], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=MDD_subcolors[1], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=MDD_subcolors[2], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=MDD_subcolors[3], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=MDD_subcolors[4], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=MDD_subcolors[5], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=MDD_subcolors[6], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=MDD_subcolors[7], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=MDD_subcolors[8], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=MDD_subcolors[9], linestyle='None')]\n",
    "MDD_log_ind = [0,1,3,8,9,10,19] \n",
    "MDD_scores = np.genfromtxt(os.path.join(varname_dir,'MDD_y_variables.txt'), \\\n",
    "                            dtype=str, delimiter='\\n')\n",
    "\n",
    "# ADNI\n",
    "ADNI_subcolors = sns.color_palette(\"blend:lightgreen,darkgreen\", n_colors=5)\n",
    "ADNI_theor_subcolors = sns.color_palette(\"blend:springgreen,darkolivegreen\", n_colors=5)\n",
    "ADNI_lgd = [plt.Line2D([], [], marker='.', color=ADNI_subcolors[0], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=ADNI_subcolors[1], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=ADNI_subcolors[2], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=ADNI_subcolors[3], linestyle='None'),\n",
    "             plt.Line2D([], [], marker='.', color=ADNI_subcolors[4], linestyle='None')]\n",
    "ADNI_log_ind = [0,1,3,4,5,6] # 2 is skipped because it is diagnosis\n",
    "ADNI_scores = np.genfromtxt(os.path.join(varname_dir,'ADNI_y_variables.txt'), \\\n",
    "                            dtype=str, delimiter='\\n')\n",
    "\n",
    "# Grey plots of what the original 36 phenotypes predict\n",
    "def theoretical_curve(X_fit, Y, sub_lvl, k0, ax_id):\n",
    "    # theoretical projection\n",
    "    HCP_behav_ind = np.append(HCP_log_ind, 59)\n",
    "    ABCD_behav_ind = np.append(ABCD_log_ind, 36)\n",
    "    theor_subcolors = sns.color_palette(\"blend:lightgray,dimgray\", n_colors=8)\n",
    "    proj_val = np.zeros((len(X_fit),(len(HCP_behav_ind) + len(ABCD_behav_ind))))\n",
    "    w_r_all,w_hcp,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir)\n",
    "    n=0\n",
    "    for i in HCP_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        proj_val[:,n] += np.sqrt(1/(1 + (w_hcp[i,-1,1]/Y[sub_lvl]) + (w_hcp[i,-1,2]/(Y[sub_lvl]*X_fit))))\n",
    "        n += 1\n",
    "    # load ABCD results\n",
    "    w_r_all,w_abcd,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir)\n",
    "    for i in ABCD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        proj_val[:,n] += np.sqrt(1/(1 + (w_abcd[i,-1,1]/Y[sub_lvl]) + (w_abcd[i,-1,2]/(Y[sub_lvl]*X_fit))))\n",
    "        n += 1\n",
    "    proj_val_mean = k0 * np.mean(proj_val,1)\n",
    "    c_int = 1.96 * np.std(proj_val,1)/np.sqrt(len(HCP_behav_ind) + len(ABCD_behav_ind))\n",
    "    #print(proj_val)\n",
    "    ax_id.plot(Y[sub_lvl]*X_fit, proj_val_mean, color=theor_subcolors[sub_lvl])\n",
    "    ax_id.fill_between(Y[sub_lvl]*X_fit, (proj_val_mean-c_int), (proj_val_mean+c_int), color=theor_subcolors[sub_lvl], alpha=.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b0b02",
   "metadata": {},
   "source": [
    "# Fig 1: Contour Plots (HCP & ABCD / KRR / full / acc / corr / cognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7743f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot contour plots\n",
    "#################################################\n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir)\n",
    "# plot contour plot\n",
    "con_lines = [0.3, 0.4, 0.45, 0.5]\n",
    "manual_locations = [(1.5,0.3),(6.5,1.5),(12.5,1.5),(16,4)]\n",
    "behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "fig,ax = plt.subplots(figsize=(3.5,3.5))\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, HCP_extent, fig, ax)\n",
    "fig.savefig(os.path.join(img_dir, 'Fig1_' +\n",
    "                    'HCP_KRR_full_acc_corr_cog_contour.svg'), bbox_inches='tight')\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir)\n",
    "# plot contour plot\n",
    "con_lines = [0.3, 0.4, 0.45, 0.5]\n",
    "manual_locations = [(1,0.3),(4,1.5),(6,6),(8.5,8)]\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "fig,ax = plt.subplots(figsize=(3.5,3.5))\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, ABCD_extent, fig, ax)\n",
    "fig.savefig(os.path.join(img_dir, 'Fig1_' +\n",
    "                    'ABCD_KRR_full_acc_corr_cog_contour.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73c7776",
   "metadata": {},
   "source": [
    "# Fig 2: Scatter Plots (HCP & ABCD component scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29ee57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot scatter plot against total scan time\n",
    "#################################################\n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir)\n",
    "cog_all = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "# plot scatter plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "limit = 15\n",
    "orsp.plot_scatter(6,cog_all,scan_duration,HCP_subcolors,limit,ax)\n",
    "orsp.plot_scatter(6,cog_all,scan_duration,HCP_subcolors,limit,ax,outline='Y')\n",
    "lgd = plt.legend(HCP_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,\n",
    "                 handletextpad=0.05, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                    'Prediction accuracy (r)', ax)\n",
    "fig.savefig(os.path.join(img_dir,'Fig2_HCP_CogComp_58m.svg'), bbox_inches='tight')\n",
    "\n",
    "### Extract points with same accuracy, different total scan time ####\n",
    "print(scan_duration[5, 6], cog_all[5, 6]) # 700 subjects, 14 mins\n",
    "print(scan_duration[1, 28], cog_all[1, 28]) # 300 subjects, 58 mins\n",
    "###\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir)\n",
    "cog_all = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "# plot scatter plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "limit = 10\n",
    "orsp.plot_scatter(9,cog_all,scan_duration,ABCD_subcolors,limit,ax)\n",
    "lgd = plt.legend(ABCD_lgd, Y, markerscale=2,\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                    'Prediction accuracy (r)', ax)\n",
    "fig.savefig(os.path.join(img_dir, 'Fig2_ABCD_CogComp_20m.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot individual scores\n",
    "#################################################\n",
    "fig,ax = plt.subplots(figsize=(8.5, 3.5))\n",
    "all_scores = []\n",
    "legend_handle = []\n",
    "lgd_handles = []\n",
    "limit = 10\n",
    "\n",
    "### cognition\n",
    "## ABCD\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "orsp.plot_norm_scatter('ABCD', 'predacc', rep_dir, 'full', limit,\n",
    "                  ABCD_cog_ind, custom_colors, zorder=None)\n",
    "\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_cog_ind, custom_colors, zorder=None)\n",
    "\n",
    "### mental health\n",
    "## ABCD\n",
    "custom_colors = sns.color_palette(\"blend:lightgrey,darkgrey\", n_colors=4)\n",
    "orsp.plot_norm_scatter('ABCD', 'predacc', rep_dir, 'full', limit,\n",
    "                  ABCD_mh_ind, custom_colors, zorder=-1)\n",
    "\n",
    "### personality\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:powderblue,darkslateblue\", n_colors=4)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_pers_ind, custom_colors, zorder=None)\n",
    "\n",
    "### physical\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:gold,gold\", n_colors=2)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_phy_ind, custom_colors, zorder=None)\n",
    "\n",
    "### emotion\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:forestgreen,forestgreen\", n_colors=2)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_emo_ind, custom_colors, zorder=None)\n",
    "\n",
    "### well being\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:magenta,magenta\", n_colors=2)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_wb_ind, custom_colors, zorder=None)\n",
    "\n",
    "# plot fitted curve\n",
    "orsp.plot_curve(200, 38000)\n",
    "\n",
    "# figure parameters\n",
    "ax.set_ylim([7, 16])\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants x scan time per participant)',\n",
    "                    'Norm. prediction performance', ax)\n",
    "fig.savefig(os.path.join(img_dir, 'Fig2_ScanTime_AllBehavCurves_20m.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9356bea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot individual scores\n",
    "#################################################\n",
    "fig,ax = plt.subplots(figsize=(8.5, 2.5))\n",
    "all_scores = []\n",
    "legend_handle = []\n",
    "lgd_handles = []\n",
    "limit = 10\n",
    "    \n",
    "### cognition\n",
    "## ABCD\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "orsp.plot_norm_scatter('ABCD', 'predacc', rep_dir, 'full', limit,\n",
    "                  ABCD_cog_ind, custom_colors, log_scale = True, zorder=None)\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_cog_ind[:-1]], ['ABCD Cog. Factor']))\n",
    "\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_cog_ind, custom_colors, log_scale = True, zorder=None)\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_cog_ind[:-1]], ['Cog Factor (H)']))\n",
    "\n",
    "### mental health\n",
    "## ABCD\n",
    "custom_colors = sns.color_palette(\"blend:lightgrey,darkgrey\", n_colors=4)\n",
    "orsp.plot_norm_scatter('ABCD', 'predacc', rep_dir, 'full', limit,\n",
    "                  ABCD_mh_ind, custom_colors, log_scale = True, zorder=-1)\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_mh_ind]))\n",
    "\n",
    "### personality\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:powderblue,darkslateblue\", n_colors=4)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_pers_ind, custom_colors, log_scale = True, zorder=None)\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_pers_ind]))\n",
    "\n",
    "### physical\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:gold,gold\", n_colors=2)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_phy_ind, custom_colors, log_scale = True, zorder=None)\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_phy_ind]))\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_emo_ind]))\n",
    "\n",
    "### emotion\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:forestgreen,forestgreen\", n_colors=2)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_emo_ind, custom_colors, log_scale = True, zorder=None)\n",
    "\n",
    "### well being\n",
    "## HCP\n",
    "custom_colors = sns.color_palette(\"blend:magenta,magenta\", n_colors=2)\n",
    "orsp.plot_norm_scatter('HCP', 'predacc', rep_dir, 'full', limit,\n",
    "                  HCP_wb_ind, custom_colors, log_scale = True, zorder=None)\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_wb_ind]))\n",
    "\n",
    "## Add legend\n",
    "# Add the custom legend handle to the legend\n",
    "lgd = plt.legend(all_scores, handletextpad=0.01, bbox_to_anchor=[1.06, -0.27],\n",
    "           fontsize=9, ncol=6, columnspacing=0.5, frameon=False)\n",
    "\n",
    "# plot log curve\n",
    "X_fit = np.linspace(350, 38000, num=100, dtype=int)\n",
    "curve_val = np.log(X_fit) / np.log(2)\n",
    "plt.plot(np.log(X_fit)/ np.log(2), curve_val, color='k')\n",
    "\n",
    "# figure parameters\n",
    "ax.set_ylim([6, 16])\n",
    "ax.set_xlim([8, 15.5])\n",
    "orsp.format_scatter_plot('log\\N{SUBSCRIPT TWO}(Total Scan Duration)',\n",
    "                    'Norm. prediction performance', ax)\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'Fig2_ScanTime_Log_AllBehavCurves_20m.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COD for 36 ABCD and HCP phenotypes for log (20mins)\n",
    "log_cod = []\n",
    "# ABCD\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir)\n",
    "for b in ABCD_rs_log_ind:\n",
    "    log_cod.append(loss_log_all[b,10-3])\n",
    "print(len(log_cod), np.mean(log_cod))\n",
    "# HCP\n",
    "log_cod = []\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "for b in HCP_rs_log_ind:\n",
    "    log_cod.append(loss_log_all[b,10-3])\n",
    "print(len(log_cod), np.mean(log_cod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1464c7",
   "metadata": {},
   "source": [
    "# Fig 3: Acc N and T are not equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad243a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Violin plot comparing same total scan time\n",
    "#################################################\n",
    "# HCP: 6000 total scan time but different N and T\n",
    "b = 59\n",
    "n_seeds = 50\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "mat = os.path.join(HCP_img_dir,'acc_KRR_avg_indiv_corr_landscape.mat')\n",
    "res = scipy.io.loadmat(mat)\n",
    "\n",
    "# extract points with 6000m of total scan time\n",
    "full_df = pd.DataFrame()\n",
    "tenm_vals = []\n",
    "twenm_vals = []\n",
    "thirm_vals = []\n",
    "fourm_vals = []\n",
    "fiftm_vals = []\n",
    "sixtm_vals = []\n",
    "for n in range(0,n_seeds):\n",
    "    behav = res['acc_landscape'][:,:,n,b]\n",
    "    dten = pd.DataFrame(data={'acc': [behav[4,1]]})\n",
    "    dten['Time'] = '10'\n",
    "    dten['Subs'] = '600subs'\n",
    "    tenm_vals.append(behav[4,1])\n",
    "    dtwen = pd.DataFrame(data={'acc': [behav[9,4]]})\n",
    "    dtwen['Time'] = '20'\n",
    "    dtwen['Subs'] = '300subs'\n",
    "    twenm_vals.append(behav[9,4])\n",
    "    dthir = pd.DataFrame(data={'acc': [behav[14,5]]})\n",
    "    dthir['Time'] = '30'\n",
    "    dthir['Subs'] = '200subs'\n",
    "    thirm_vals.append(behav[14,5])\n",
    "    dfour = pd.DataFrame(data={'acc': [behav[19,6]]})\n",
    "    dfour['Time'] = '40'\n",
    "    dfour['Subs'] = '150subs'\n",
    "    fourm_vals.append(behav[19,6])\n",
    "    dfift = pd.DataFrame(data={'acc': [behav[24,7]]})\n",
    "    dfift['Time'] = '50'\n",
    "    dfift['Subs'] = '120subs'\n",
    "    fiftm_vals.append(behav[24,7])\n",
    "    dsixt = pd.DataFrame(data={'acc': [behav[28,8]]})\n",
    "    dsixt['Time'] = '~60'\n",
    "    dsixt['Subs'] = '100subs'\n",
    "    sixtm_vals.append(behav[28,8])\n",
    "    full_df = pd.concat([full_df, dten, dtwen, dthir, dfour, dfift, dsixt])\n",
    "\n",
    "# plot violin plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "vp = sns.violinplot(data=full_df, x=\"Time\", y=\"acc\", palette=\"Blues_r\",orient='v', width=0.9)\n",
    "orsp.format_scatter_plot(\"\", 'Prediction accuracy (r)', ax)\n",
    "vp.set(xticklabels=[])\n",
    "ax.set_xlim([-0.7,5.7])\n",
    "fig.savefig(os.path.join(img_dir,'Fig3_HCP_not1to1_violin.svg'), bbox_inches='tight')\n",
    "\n",
    "# mean accuracy\n",
    "print('10m mean:', np.mean(tenm_vals))\n",
    "print('20m mean:', np.mean(twenm_vals))\n",
    "print('30m mean:', np.mean(thirm_vals))\n",
    "print('40m mean:', np.mean(fourm_vals))\n",
    "print('50m mean:', np.mean(fiftm_vals))\n",
    "print('60m mean:', np.mean(sixtm_vals))\n",
    "\n",
    "# stats \n",
    "print('10m vs 20m:', orsp.corrected_resample_ttest([a - b for a, b in zip(tenm_vals, twenm_vals)], 1/9, 0))\n",
    "print('20m vs 30m:', orsp.corrected_resample_ttest([a - b for a, b in zip(twenm_vals, thirm_vals)], 1/9, 0))\n",
    "print('30m vs 40m:', orsp.corrected_resample_ttest([a - b for a, b in zip(thirm_vals, fourm_vals)], 1/9, 0))\n",
    "print('40m vs 50m:', orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, fiftm_vals)], 1/9, 0))\n",
    "print('50m vs 58m:', orsp.corrected_resample_ttest([a - b for a, b in zip(fiftm_vals, sixtm_vals)], 1/9, 0))\n",
    "\n",
    "# start saving pvals for FDR\n",
    "p_list = []\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(tenm_vals, twenm_vals)], 1/9, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(twenm_vals, thirm_vals)], 1/9, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(thirm_vals, fourm_vals)], 1/9, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, fiftm_vals)], 1/9, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(fiftm_vals, sixtm_vals)], 1/9, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bdf8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Tom's theoretical equations\n",
    "#################################################\n",
    "c_vers = 'full'\n",
    "# load HCP results\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir)\n",
    "b = 59 # Cognition Factor\n",
    "behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,b].T),1)\n",
    "# scatter plot with theoretical equation fit\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "orsp.plot_scatter(len(Y),behav,scan_duration,HCP_subcolors,len(X), ax)\n",
    "# Tom's equation fit to full duration\n",
    "w = w_pa_all[b,-1,:]\n",
    "X_fit = np.linspace(2, 60, num=100, dtype=int)\n",
    "for sub_lvl in range(0,len(Y)):\n",
    "    curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "    plt.plot(Y[sub_lvl]*X_fit, curve_val, color=HCP_theor_subcolors[sub_lvl])\n",
    "lgd = plt.legend(HCP_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,\n",
    "                 handletextpad=0.05, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                    'Prediction accuracy (r)', ax)\n",
    "fig.savefig(os.path.join(img_dir,'Fig3_HCP_CogFac_Theoretical_acc.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COD for 36 ABCD and HCP phenotypes for log (20mins)\n",
    "theor_cod = []\n",
    "# ABCD\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir)\n",
    "for b in ABCD_rs_log_ind:\n",
    "    theor_cod.append(loss_pa_all[b,-1])\n",
    "print(len(theor_cod), np.mean(theor_cod))\n",
    "# HCP\n",
    "theor_cod = []\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "for b in HCP_rs_log_ind:\n",
    "    theor_cod.append(loss_pa_all[b,-1])\n",
    "print(len(theor_cod), np.mean(theor_cod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### t-test comparing log and theoretical models for 36 ABCD and HCP phenotypes\n",
    "# ABCD\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir)\n",
    "theor_vals = []\n",
    "log_vals = []\n",
    "for b in ABCD_rs_log_ind:\n",
    "    theor_vals.append(loss_pa_all[b,-1])\n",
    "    log_vals.append(loss_log_all[b,-1])\n",
    "print(len(theor_vals), np.mean(theor_vals),np.mean(log_vals))\n",
    "print(scipy.stats.ttest_rel(log_vals, theor_vals))\n",
    "\n",
    "# HCP\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir)\n",
    "theor_vals = []\n",
    "log_vals = []\n",
    "for b in HCP_rs_log_ind:\n",
    "    theor_vals.append(loss_pa_all[b,-1])\n",
    "    log_vals.append(loss_log_all[b,-1])\n",
    "print(len(theor_vals), np.mean(theor_vals),np.mean(log_vals))\n",
    "print(scipy.stats.ttest_rel(log_vals, theor_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a80419f",
   "metadata": {},
   "source": [
    "# Fig 4: Why behaviors don't follow log curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36927f77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Example of high prediction acc vs low prediction acc\n",
    "#################################################\n",
    "c_vers = 'full'\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir, vers=c_vers)\n",
    "b=8\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "# plot scatter plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "orsp.plot_scatter(9,behav,scan_duration,ABCD_subcolors,10,ax)\n",
    "lgd = plt.legend(ABCD_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,\n",
    "                 handletextpad=0.05, columnspacing=0.7, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                    'Prediction accuracy (r)', ax, fontsz=10)\n",
    "fig.savefig(os.path.join(img_dir,'Fig4_ABCD_Vocabulary_HiAcc.svg'), bbox_inches='tight')\n",
    "\n",
    "b=0\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "# plot scatter plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "orsp.plot_scatter(9,behav,scan_duration,ABCD_subcolors,10,ax)\n",
    "lgd = plt.legend(ABCD_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,\n",
    "                 handletextpad=0.05, columnspacing=0.7, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                    'Prediction accuracy (r)', ax, fontsz=10)\n",
    "fig.savefig(os.path.join(img_dir,'Fig4_ABCD_AnxDep_LoAcc.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a963d84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Example of state effect\n",
    "#################################################\n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir, vers='full')\n",
    "b=43\n",
    "cog_all = np.flip(np.flip(HCP_res['acc_landscape'][:,:,b].T),1)\n",
    "# plot scatter plot\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "orsp.plot_scatter(6,cog_all,scan_duration,HCP_subcolors,58,ax)\n",
    "lgd = plt.legend(HCP_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,\n",
    "                 handletextpad=0.05, columnspacing=0.7, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                    'Prediction accuracy (r)', ax, fontsz=10)\n",
    "fig.savefig(os.path.join(img_dir,'Fig5_HCP_AngAgr_NoShuff.svg'), bbox_inches='tight')\n",
    "\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir, vers='random')\n",
    "cog_all = np.flip(np.flip(HCP_res['acc_landscape'][:,:,b].T),1)\n",
    "# plot scatter plot\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "orsp.plot_scatter(6,cog_all,scan_duration,HCP_subcolors,58,ax)\n",
    "lgd = plt.legend(HCP_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,\n",
    "                 handletextpad=0.05, columnspacing=0.7, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                    'Prediction accuracy (r)', ax, fontsz=10)\n",
    "fig.savefig(os.path.join(img_dir,'Fig5_HCP_AngAgr_Shuff.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18da053",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=43\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir,vers='full')\n",
    "print(loss_log_all[b,10-3], loss_log_all[b,29-3], loss_pa_all[b,29-3])\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir,vers='random')\n",
    "print(loss_log_all[b,10-3], loss_log_all[b,29-3], loss_pa_all[b,29-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e9f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Acc against fit (ABCD)\n",
    "#################################################\n",
    "c_vers = 'full'\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir, vers=c_vers)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers=c_vers)\n",
    "# score classifications\n",
    "bpass = []\n",
    "cog_ind = np.array([9,10,11,12,13,14,15,16,17,18,31,32,33,34,35,36,37])-1\n",
    "per_ind = np.array([19,20,21,22,23,24,25,26,27])-1\n",
    "mh_ind = np.array([1,2,3,4,5,6,7,8,28,29,30])-1\n",
    "acc_all = np.array([])\n",
    "log_loss = np.array([])\n",
    "pa_loss = np.array([])\n",
    "log_limit = 10\n",
    "pa_limit = 10\n",
    "# get scores with looser threshold\n",
    "for b_idx in range(0,37):\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b_idx].T),1)\n",
    "    if (np.sum(behav.flatten() < 0) < 10): # remove scores with > 10% negative predictions\n",
    "        bpass.append(b_idx)\n",
    "    acc_all = np.append(acc_all, behav[8,9])\n",
    "    log_loss = np.append(log_loss, loss_log_all[b_idx,log_limit-3])\n",
    "    pa_loss = np.append(pa_loss, loss_pa_all[b_idx,pa_limit-3])\n",
    "for i in cog_ind:\n",
    "    if i not in bpass:\n",
    "        cog_ind = np.delete(cog_ind, np.where(cog_ind==i))\n",
    "for i in per_ind:\n",
    "    if i not in bpass:\n",
    "        per_ind = np.delete(per_ind, np.where(per_ind==i))\n",
    "for i in mh_ind:\n",
    "    if i not in bpass:\n",
    "        mh_ind = np.delete(mh_ind, np.where(mh_ind==i)) \n",
    "# final list of scores for reference\n",
    "print(\"Scores < 10% negative:\", bpass)\n",
    "        \n",
    "# log fit at 20m\n",
    "print(\"Log Fit:\", scipy.stats.spearmanr(log_loss[bpass],acc_all[bpass]))\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "plt.scatter(acc_all[cog_ind],log_loss[cog_ind], c='orangered')\n",
    "plt.scatter(acc_all[per_ind],log_loss[per_ind], c='darkslateblue')\n",
    "plt.scatter(acc_all[mh_ind],log_loss[mh_ind], c='darkgray')\n",
    "plt.legend(['Cognition', 'Personality', 'Mental Health'], loc=\"lower right\", frameon=False,\n",
    "             prop={'family' : 'Arial'}, labelspacing=0.1,handletextpad=0.05, fontsize=10)\n",
    "orsp.format_scatter_plot('Prediction accuracy (r)','Goodness of fit (COD)',ax, fontsz=10)\n",
    "# plot trend line\n",
    "# calculate polynomial\n",
    "y = log_loss[bpass]\n",
    "x = acc_all[bpass]\n",
    "z = np.polyfit(x, y, 4)\n",
    "f = np.poly1d(z)\n",
    "# calculate new x's and y's\n",
    "x_new = np.linspace(np.min(x), np.max(x), 50)\n",
    "y_new = f(x_new)\n",
    "y_new = 1 - np.exp(-10*x_new)\n",
    "plt.plot(x_new, y_new, color='k',linestyle='dashed')\n",
    "fig.savefig(os.path.join(img_dir,'Fig4_ABCD_AccvsFit_Log.svg'), bbox_inches='tight')\n",
    "# save pvals for FDR\n",
    "c,p = scipy.stats.spearmanr(log_loss[bpass],acc_all[bpass])\n",
    "p_list.append(p)\n",
    "# Nichols fit at 20m\n",
    "print(\"Theoretical Fit:\", scipy.stats.spearmanr(pa_loss[bpass],acc_all[bpass]))\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "plt.scatter(acc_all[cog_ind],pa_loss[cog_ind], c='orangered')\n",
    "plt.scatter(acc_all[per_ind],pa_loss[per_ind], c='darkslateblue')\n",
    "plt.scatter(acc_all[mh_ind],pa_loss[mh_ind], c='darkgray')\n",
    "plt.legend(['Cognition', 'Personality', 'Mental Health'], loc=\"lower right\", frameon=False,\n",
    "           prop={'family' : 'Arial'}, labelspacing=0.1,handletextpad=0.05, fontsize=10)\n",
    "orsp.format_scatter_plot('Prediction accuracy (r)','Goodness of fit (COD)',ax, fontsz=10)\n",
    "# plot trend line\n",
    "# calculate new x's and y's\n",
    "x_new = np.linspace(np.min(x), np.max(x), 50)\n",
    "y_new = 1 - np.exp(-10*x_new)\n",
    "plt.plot(x_new, y_new, color='k',linestyle='dashed')\n",
    "fig.savefig(os.path.join(img_dir,'Fig4_ABCD_AccvsFit_Theoretical.svg'), bbox_inches='tight')\n",
    "# save pvals for FDR\n",
    "c,p = scipy.stats.spearmanr(pa_loss[bpass],acc_all[bpass])\n",
    "p_list.append(p)\n",
    "\n",
    "#################################################\n",
    "# Improvement to fit after shuffling (ABCD)\n",
    "#################################################\n",
    "# load ABCD data\n",
    "w_r_f,w_pa_f,zk_f,loss_r_f,loss_pa_f,loss_log_f = orsp.load_fits('ABCD','predacc',rep_dir,vers='full')\n",
    "w_r_r,w_pa_r,zk_r,loss_r_r,loss_pa_r,loss_log_r = orsp.load_fits('ABCD','predacc',rep_dir,vers='random')\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "# t test for selected behaviors\n",
    "print(\"Log:\", scipy.stats.ttest_rel(loss_log_f[bpass,pa_limit-3], loss_log_r[bpass,pa_limit-3]))\n",
    "df = pd.DataFrame(data={'COD': loss_log_f[bpass,pa_limit-3]})\n",
    "df['Domain'] = 'Log Fit'\n",
    "df['Class'] = 'Original'\n",
    "dr = pd.DataFrame(data={'COD': loss_log_r[bpass,pa_limit-3]})\n",
    "dr['Domain'] = 'Log Fit'\n",
    "dr['Class'] = 'Randomized'\n",
    "full_df = pd.concat([full_df, df, dr])\n",
    "print(\"Theoretical:\", scipy.stats.ttest_rel(loss_pa_f[bpass,pa_limit-3], loss_pa_r[bpass,pa_limit-3]))\n",
    "df = pd.DataFrame(data={'COD': loss_pa_f[bpass,pa_limit-3]})\n",
    "df['Domain'] = 'Theoretical Fit'\n",
    "df['Class'] = 'Original'\n",
    "dr = pd.DataFrame(data={'COD': loss_pa_r[bpass,pa_limit-3]})\n",
    "dr['Domain'] = 'Theoretical Fit'\n",
    "dr['Class'] = 'Randomized'\n",
    "full_df = pd.concat([full_df, df, dr])\n",
    "# plot box plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "sns.boxplot(data=full_df, x=\"Domain\", y=\"COD\", hue=\"Class\",palette=\"Reds\",orient='v')\n",
    "plt.legend(frameon=False, fontsize=10,  prop={'family' : 'Arial'}, bbox_to_anchor=(0.68,0.23))\n",
    "orsp.format_scatter_plot('','Goodness of fit (COD)',ax, fontsz=10)\n",
    "fig.savefig(os.path.join(img_dir,'Fig5_ABCD_origvsrandom.svg'), bbox_inches='tight')\n",
    "# save pvals for FDR\n",
    "print(np.mean(loss_log_f[bpass,pa_limit-3]), np.mean(loss_log_r[bpass,pa_limit-3]))\n",
    "print(np.mean(loss_pa_f[bpass,pa_limit-3]), np.mean(loss_pa_r[bpass,pa_limit-3]))\n",
    "log_p = scipy.stats.ttest_rel(loss_log_f[bpass,pa_limit-3], loss_log_r[bpass,pa_limit-3])\n",
    "theor_p = scipy.stats.ttest_rel(loss_pa_f[bpass,pa_limit-3], loss_pa_r[bpass,pa_limit-3])\n",
    "p_list.append(log_p[1])\n",
    "p_list.append(theor_p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9bb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_r_f,w_pa_f,zk_f,loss_r_f,loss_pa_f,loss_log_f = orsp.load_fits('ABCD','predacc',rep_dir,vers='full')\n",
    "timelimit = 10\n",
    "\n",
    "# loose threshold\n",
    "b_set = bpass\n",
    "print(\"(loose threshold) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_pa_f[b_set,timelimit-3]))\n",
    "\n",
    "# strict threshold\n",
    "b_set =np.append(ABCD_abv01_ind, 37)\n",
    "print(\"(strict threshold) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_pa_f[b_set,timelimit-3]))\n",
    "\n",
    "# log ind\n",
    "b_set =np.append(ABCD_log_ind, 37)\n",
    "print(\"(log ind) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_pa_f[b_set,timelimit-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_r_f,w_pa_f,zk_f,loss_r_f,loss_pa_f,loss_log_f = orsp.load_fits('ABCD','tstats',rep_dir,vers='full')\n",
    "timelimit = 5\n",
    "\n",
    "# loose threshold\n",
    "b_set = bpass\n",
    "print(\"(loose threshold) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_r_f[b_set,timelimit-3]))\n",
    "\n",
    "# strict threshold\n",
    "b_set =np.append(ABCD_abv01_ind, 37)\n",
    "print(\"(strict threshold) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_r_f[b_set,timelimit-3]))\n",
    "\n",
    "# log ind\n",
    "b_set =np.append(ABCD_log_ind, 37)\n",
    "print(\"(log ind) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_r_f[b_set,timelimit-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e1855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Acc against fit (HCP)\n",
    "#################################################\n",
    "c_vers = 'full'\n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir, vers=c_vers)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir, vers=c_vers)\n",
    "# score classifications\n",
    "bpass = []\n",
    "cog_ind = np.array([1,2,3,4,5,6,7,9,10,11,12,13,14,25,26,27,28,29,30,60])-1\n",
    "per_ind = np.array([8,31,32,33,34,35])-1\n",
    "emo_ind = np.array([24,36,37,38,39,40,41,42,43,44,45,46,47])-1\n",
    "phy_ind = np.array([15,16,17,18,19,20,21,22,23])-1\n",
    "wb_ind = np.array([48,49,50,51,52,53,54,55,56,57,58])-1\n",
    "acc_all = np.array([])\n",
    "log_loss = np.array([])\n",
    "pa_loss = np.array([])\n",
    "log_limit = 10\n",
    "pa_limit = 29\n",
    "# get scores with looser threshold\n",
    "for b_idx in range(0,60):\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,b_idx].T),1)\n",
    "    if (np.sum(behav.flatten() < 0) < 18) and b_idx != 58: # remove scores with > 10% negative predictions\n",
    "        bpass.append(b_idx)\n",
    "    acc_all = np.append(acc_all, behav[5,28])\n",
    "    log_loss = np.append(log_loss, loss_log_all[b_idx,log_limit-3])\n",
    "    pa_loss = np.append(pa_loss, loss_pa_all[b_idx,pa_limit-3])\n",
    "for i in cog_ind:\n",
    "    if i not in bpass:\n",
    "        cog_ind = np.delete(cog_ind, np.where(cog_ind==i))\n",
    "for i in per_ind:\n",
    "    if i not in bpass:\n",
    "        per_ind = np.delete(per_ind, np.where(per_ind==i))\n",
    "for i in emo_ind:\n",
    "    if i not in bpass:\n",
    "        emo_ind = np.delete(emo_ind, np.where(emo_ind==i))\n",
    "for i in phy_ind:\n",
    "    if i not in bpass:\n",
    "        phy_ind = np.delete(phy_ind, np.where(phy_ind==i))\n",
    "for i in wb_ind:\n",
    "    if i not in bpass:\n",
    "        wb_ind = np.delete(wb_ind, np.where(wb_ind==i))  \n",
    "# final list of scores for reference\n",
    "print(\"Scores < 10% negative:\", bpass)\n",
    "        \n",
    "# log fit at 20m\n",
    "print(\"Log Fit:\", scipy.stats.spearmanr(log_loss[bpass],acc_all[bpass]))\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "plt.scatter(acc_all[cog_ind],log_loss[cog_ind], c='orangered')\n",
    "plt.scatter(acc_all[per_ind],log_loss[per_ind], c='darkslateblue')\n",
    "plt.scatter(acc_all[emo_ind],log_loss[emo_ind], c='forestgreen')\n",
    "plt.scatter(acc_all[phy_ind],log_loss[phy_ind], c='goldenrod')\n",
    "plt.scatter(acc_all[wb_ind],log_loss[wb_ind], c='deeppink')\n",
    "plt.legend(['Cognition','Personality','Emotion', 'Physical','Well-being'], prop={'family' : 'Arial'},\n",
    "           loc=\"lower right\", labelspacing=0.1,handletextpad=0.05, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Prediction accuracy (r)','Goodness of fit (COD)',ax,fontsz=10)\n",
    "# plot trend line\n",
    "# calculate polynomial\n",
    "y = log_loss[bpass]\n",
    "x = acc_all[bpass]\n",
    "z = np.polyfit(x, y, 2)\n",
    "f = np.poly1d(z)\n",
    "# calculate new x's and y's\n",
    "x_new = np.linspace(np.min(x), np.max(x), 50)\n",
    "y_new = f(x_new)\n",
    "y_new = 0.95 - 1.3*np.exp(-14.5*x_new)\n",
    "#y_new = 1 - np.exp(-10*x_new)\n",
    "plt.plot(x_new, y_new, color='k',linestyle='dashed')\n",
    "fig.savefig(os.path.join(img_dir,'Fig4_HCP_AccvsFit_Log.svg'), bbox_inches='tight')\n",
    "# save pvals for FDR\n",
    "c,p = scipy.stats.spearmanr(log_loss[bpass],acc_all[bpass])\n",
    "p_list.append(p)\n",
    "\n",
    "# Nichols fit at 58m\n",
    "print(\"Theoretical Fit:\", scipy.stats.spearmanr(pa_loss[bpass],acc_all[bpass]))\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "plt.scatter(acc_all[cog_ind],pa_loss[cog_ind], c='orangered')\n",
    "plt.scatter(acc_all[per_ind],pa_loss[per_ind], c='darkslateblue')\n",
    "plt.scatter(acc_all[emo_ind],pa_loss[emo_ind], c='forestgreen')\n",
    "plt.scatter(acc_all[phy_ind],pa_loss[phy_ind], c='goldenrod')\n",
    "plt.scatter(acc_all[wb_ind],pa_loss[wb_ind], c='deeppink')\n",
    "plt.legend(['Cognition','Personality','Emotion', 'Physical','Well-being'], prop={'family' : 'Arial'},\n",
    "           loc=\"lower right\", labelspacing=0.1,handletextpad=0.05, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Prediction accuracy (r)','Goodness of fit (COD)',ax, fontsz=10)\n",
    "# plot trend line\n",
    "# calculate polynomial\n",
    "y = log_loss[bpass]\n",
    "x = acc_all[bpass]\n",
    "z = np.polyfit(x, y, 4)\n",
    "f = np.poly1d(z)\n",
    "# calculate new x's and y's\n",
    "x_new = np.linspace(np.min(x), np.max(x), 50)\n",
    "y_new = f(x_new)\n",
    "y_new = 1 - np.exp(-10*x_new)\n",
    "plt.plot(x_new, y_new, color='k',linestyle='dashed')\n",
    "fig.savefig(os.path.join(img_dir,'Fig4_HCP_AccvsFit_Theoretical.svg'), bbox_inches='tight')\n",
    "# save pvals for FDR\n",
    "c,p = scipy.stats.spearmanr(pa_loss[bpass],acc_all[bpass])\n",
    "p_list.append(p)\n",
    "\n",
    "\n",
    "#################################################\n",
    "# Improvement to fit after shuffling (HCP)\n",
    "#################################################\n",
    "# load HCP data\n",
    "w_r_f,w_pa_f,zk_f,loss_r_f,loss_pa_f,loss_log_f = orsp.load_fits('HCP','predacc',rep_dir,vers='full')\n",
    "w_r_r,w_pa_r,zk_r,loss_r_r,loss_pa_r,loss_log_r = orsp.load_fits('HCP','predacc',rep_dir,vers='random')\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "# t test for selected behaviors\n",
    "# use all 58 min for comparison\n",
    "print(\"Log:\", scipy.stats.ttest_rel(loss_log_f[bpass,pa_limit-3], loss_log_r[bpass,pa_limit-3]))\n",
    "df = pd.DataFrame(data={'COD': loss_log_f[bpass,pa_limit-3]})\n",
    "df['Domain'] = 'Log Fit'\n",
    "df['Class'] = 'Original'\n",
    "dr = pd.DataFrame(data={'COD': loss_log_r[bpass,pa_limit-3]})\n",
    "dr['Domain'] = 'Log Fit'\n",
    "dr['Class'] = 'Randomized'\n",
    "full_df = pd.concat([full_df, df, dr])\n",
    "\n",
    "print(\"Theoretical:\", scipy.stats.ttest_rel(loss_pa_f[bpass,pa_limit-3], loss_pa_r[bpass,pa_limit-3]))\n",
    "df = pd.DataFrame(data={'COD': loss_pa_f[bpass,pa_limit-3]})\n",
    "df['Domain'] = 'Theoretical Fit'\n",
    "df['Class'] = 'Original'\n",
    "dr = pd.DataFrame(data={'COD': loss_pa_r[bpass,pa_limit-3]})\n",
    "dr['Domain'] = 'Theoretical Fit'\n",
    "dr['Class'] = 'Randomized'\n",
    "full_df = pd.concat([full_df, df, dr])\n",
    "# plot box plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "sns.boxplot(data=full_df, x=\"Domain\", y=\"COD\", hue=\"Class\",palette=\"Blues\",orient='v')\n",
    "plt.legend(frameon=False,  prop={'family' : 'Arial'}, fontsize=10)\n",
    "orsp.format_scatter_plot('','Goodness of fit (COD)',ax,fontsz=10)\n",
    "fig.savefig(os.path.join(img_dir,'Fig5_HCP_origvsrandom.svg'), bbox_inches='tight')\n",
    "# save pvals for FDR\n",
    "print(np.mean(loss_log_f[bpass,pa_limit-3]), np.mean(loss_log_r[bpass,pa_limit-3]))\n",
    "print(np.mean(loss_pa_f[bpass,pa_limit-3]), np.mean(loss_pa_r[bpass,pa_limit-3]))\n",
    "log_p = scipy.stats.ttest_rel(loss_log_f[bpass,pa_limit-3], loss_log_r[bpass,pa_limit-3])\n",
    "theor_p = scipy.stats.ttest_rel(loss_pa_f[bpass,pa_limit-3], loss_pa_r[bpass,pa_limit-3])\n",
    "p_list.append(log_p[1])\n",
    "p_list.append(theor_p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa2fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_r_f,w_pa_f,zk_f,loss_r_f,loss_pa_f,loss_log_f = orsp.load_fits('HCP','predacc',rep_dir,vers='full')\n",
    "timelimit = 10\n",
    "\n",
    "# loose threshold\n",
    "b_set = bpass\n",
    "print(\"(loose threshold) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_pa_f[b_set,timelimit-3]))\n",
    "\n",
    "# strict threshold\n",
    "b_set =np.append(HCP_abv01_ind, 59)\n",
    "print(\"(strict threshold) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_pa_f[b_set,timelimit-3]))\n",
    "\n",
    "# log ind\n",
    "b_set =np.append(HCP_log_ind, 59)\n",
    "print(\"(log ind) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_pa_f[b_set,timelimit-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39737506",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_r_f,w_pa_f,zk_f,loss_r_f,loss_pa_f,loss_log_f = orsp.load_fits('HCP','Haufe',rep_dir,vers='random')\n",
    "timelimit = 5\n",
    "\n",
    "# loose threshold\n",
    "b_set = bpass\n",
    "print(\"(loose threshold) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_r_f[b_set,timelimit-3]))\n",
    "\n",
    "# strict threshold\n",
    "b_set =np.append(HCP_abv01_ind, 59)\n",
    "print(\"(strict threshold) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_r_f[b_set,timelimit-3]))\n",
    "\n",
    "# log ind\n",
    "b_set =np.append(HCP_log_ind, 59)\n",
    "print(\"(log ind) log:\", np.mean(loss_log_f[b_set,timelimit-3]), \"theoretical:\", np.mean(loss_r_f[b_set,timelimit-3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d4691",
   "metadata": {},
   "source": [
    "# Fig 6: Theoretical N vs T improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed91f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Tom's theoretical equations without overhead cost\n",
    "#################################################\n",
    "theoretical_extent = [1,120,10,10000]\n",
    "theoretical_Y = np.array([10,50,100,200,300,400,500,1000,2000,3000,4000,5000,10000,20000,30000,400000,50000])\n",
    "theoretical_Y = np.exp(np.linspace(2, 14, num=10000))\n",
    "theoretical_X = np.linspace(1, 200, num=1000)\n",
    "\n",
    "ABCD_theor = 0\n",
    "HCP_theor = 0\n",
    "num_scores = 0\n",
    "training_factor = 0.9\n",
    "\n",
    "# load HCP results\n",
    "HCP_behav_ind = HCP_rs_log_ind\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir)\n",
    "theor_vals = np.zeros((10000,1000))\n",
    "\n",
    "for b in HCP_behav_ind:\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    for sub_lvl in range(0,len(theoretical_Y)):\n",
    "        training_y = np.floor(training_factor*theoretical_Y[sub_lvl])\n",
    "        theor_vals[sub_lvl,:] += np.sqrt(1/(1 + (w[1]/training_y) + (w[2]/(training_y*theoretical_X))))\n",
    "    ABCD_theor += np.sqrt(1/(1 + (w[1]/2565) + (w[2]/(2565*20)))) \n",
    "    HCP_theor += np.sqrt(1/(1 + (w[1]/792) + (w[2]/(792*57.6)))) \n",
    "    num_scores += 1\n",
    "    \n",
    "# load ABCD results\n",
    "ABCD_behav_ind = ABCD_rs_log_ind\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir)\n",
    "for b in ABCD_behav_ind:\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    for sub_lvl in range(0,len(theoretical_Y)):\n",
    "        training_y = np.floor(training_factor*theoretical_Y[sub_lvl])\n",
    "        theor_vals[sub_lvl,:] += np.sqrt(1/(1 + (w[1]/training_y) + (w[2]/(training_y*theoretical_X))))\n",
    "    ABCD_theor += np.sqrt(1/(1 + (w[1]/2565) + (w[2]/(2565*20)))) \n",
    "    HCP_theor += np.sqrt(1/(1 + (w[1]/792) + (w[2]/(792*57.6)))) \n",
    "    num_scores += 1\n",
    "\n",
    "# load SINGER results\n",
    "SINGER_behav_ind = SINGER_log_ind\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('SINGER', 'predacc', rep_dir)\n",
    "for b in SINGER_behav_ind:\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    for sub_lvl in range(0,len(theoretical_Y)):\n",
    "        training_y = np.floor(training_factor*theoretical_Y[sub_lvl])\n",
    "        theor_vals[sub_lvl,:] += np.sqrt(1/(1 + (w[1]/training_y) + (w[2]/(training_y*theoretical_X))))\n",
    "    ABCD_theor += np.sqrt(1/(1 + (w[1]/2565) + (w[2]/(2565*20)))) \n",
    "    HCP_theor += np.sqrt(1/(1 + (w[1]/792) + (w[2]/(792*57.6)))) \n",
    "    num_scores += 1\n",
    "    \n",
    "# load TCP results\n",
    "TCP_behav_ind = TCP_log_ind\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('TCP', 'predacc', rep_dir)\n",
    "for b in TCP_behav_ind:\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    for sub_lvl in range(0,len(theoretical_Y)):\n",
    "        training_y = np.floor(training_factor*theoretical_Y[sub_lvl])\n",
    "        theor_vals[sub_lvl,:] += np.sqrt(1/(1 + (w[1]/training_y) + (w[2]/(training_y*theoretical_X))))\n",
    "    ABCD_theor += np.sqrt(1/(1 + (w[1]/2565) + (w[2]/(2565*20)))) \n",
    "    HCP_theor += np.sqrt(1/(1 + (w[1]/792) + (w[2]/(792*57.6)))) \n",
    "    num_scores += 1\n",
    "\n",
    "# load MDD results\n",
    "MDD_behav_ind = MDD_log_ind\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('MDD', 'predacc', rep_dir)\n",
    "for b in MDD_behav_ind:\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    for sub_lvl in range(0,len(theoretical_Y)):\n",
    "        training_y = np.floor(training_factor*theoretical_Y[sub_lvl])\n",
    "        theor_vals[sub_lvl,:] += np.sqrt(1/(1 + (w[1]/training_y) + (w[2]/(training_y*theoretical_X))))\n",
    "    ABCD_theor += np.sqrt(1/(1 + (w[1]/2565) + (w[2]/(2565*20)))) \n",
    "    HCP_theor += np.sqrt(1/(1 + (w[1]/792) + (w[2]/(792*57.6)))) \n",
    "    num_scores += 1\n",
    "    \n",
    "# load ADNI results\n",
    "ADNI_behav_ind = ADNI_log_ind\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ADNI', 'predacc', rep_dir)\n",
    "for b in ADNI_behav_ind:\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    for sub_lvl in range(0,len(theoretical_Y)):\n",
    "        training_y = np.floor(training_factor*theoretical_Y[sub_lvl])\n",
    "        theor_vals[sub_lvl,:] += np.sqrt(1/(1 + (w[1]/training_y) + (w[2]/(training_y*theoretical_X))))\n",
    "    ABCD_theor += np.sqrt(1/(1 + (w[1]/2565) + (w[2]/(2565*20)))) \n",
    "    HCP_theor += np.sqrt(1/(1 + (w[1]/792) + (w[2]/(792*57.6)))) \n",
    "    num_scores += 1\n",
    "    \n",
    "# load ABCD MID results\n",
    "ABCD_behav_ind = ABCD_MID_log_ind\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='full_MID')\n",
    "for b in ABCD_behav_ind:\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    for sub_lvl in range(0,len(theoretical_Y)):\n",
    "        training_y = np.floor(training_factor*theoretical_Y[sub_lvl])\n",
    "        theor_vals[sub_lvl,:] += np.sqrt(1/(1 + (w[1]/training_y) + (w[2]/(training_y*theoretical_X))))\n",
    "    ABCD_theor += np.sqrt(1/(1 + (w[1]/2565) + (w[2]/(2565*20)))) \n",
    "    HCP_theor += np.sqrt(1/(1 + (w[1]/792) + (w[2]/(792*57.6)))) \n",
    "    num_scores += 1\n",
    "    \n",
    "# load ABCD NBACK results\n",
    "ABCD_behav_ind = ABCD_NBACK_log_ind\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='full_NBACK')\n",
    "for b in ABCD_behav_ind:\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    for sub_lvl in range(0,len(theoretical_Y)):\n",
    "        training_y = np.floor(training_factor*theoretical_Y[sub_lvl])\n",
    "        theor_vals[sub_lvl,:] += np.sqrt(1/(1 + (w[1]/training_y) + (w[2]/(training_y*theoretical_X))))\n",
    "    ABCD_theor += np.sqrt(1/(1 + (w[1]/2565) + (w[2]/(2565*20)))) \n",
    "    HCP_theor += np.sqrt(1/(1 + (w[1]/792) + (w[2]/(792*57.6)))) \n",
    "    num_scores += 1\n",
    "    \n",
    "# load ABCD SST results\n",
    "ABCD_behav_ind = ABCD_SST_log_ind\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='full_SST')\n",
    "for b in ABCD_behav_ind:\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    for sub_lvl in range(0,len(theoretical_Y)):\n",
    "        training_y = np.floor(training_factor*theoretical_Y[sub_lvl])\n",
    "        theor_vals[sub_lvl,:] += np.sqrt(1/(1 + (w[1]/training_y) + (w[2]/(training_y*theoretical_X))))\n",
    "    ABCD_theor += np.sqrt(1/(1 + (w[1]/2565) + (w[2]/(2565*20)))) \n",
    "    HCP_theor += np.sqrt(1/(1 + (w[1]/792) + (w[2]/(792*57.6)))) \n",
    "    num_scores += 1\n",
    "    \n",
    "    \n",
    "theor_vals = theor_vals / num_scores\n",
    "theor_vals = np.round(theor_vals,2) + 0.01\n",
    "\n",
    "ABCD_theor = ABCD_theor / num_scores\n",
    "HCP_theor = HCP_theor / num_scores\n",
    "\n",
    "print(num_scores)\n",
    "print(\"ABCD:\", ABCD_theor, \"HCP:\", HCP_theor)\n",
    "\n",
    "con_lines = [0.4,0.5,0.6,\n",
    "             0.7,0.8,0.9,1] \n",
    "              \n",
    "manual_loc = [(5,2),(10,3.5),(10,4.6),\n",
    "              (10,5.2),(10,6),(10,7),\n",
    "              (10,11)]\n",
    "\n",
    "## plot contour plot\n",
    "#fig,ax = plt.subplots(figsize=(7, 8))\n",
    "fig,ax = plt.subplots(figsize=(8, 4))\n",
    "extent=[0-0.5, theoretical_X[:-1].max(),0-0.5, np.log(theoretical_Y[:-1]).max()]\n",
    "theor_vals_flipped = np.flip(np.flip(theor_vals),1)\n",
    "contours = plt.contour(theor_vals_flipped[::-1], con_lines,extent=extent, colors='black')\n",
    "plt.clabel(contours, inline=True, manual=manual_loc, fontsize=12)\n",
    "# overlay colours\n",
    "plt.imshow(theor_vals_flipped[::-1], extent=extent, origin='lower',\n",
    "            aspect='auto', cmap='rainbow', alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.yaxis.set_major_formatter(ScalarFormatter())\n",
    "ax.minorticks_off()\n",
    "custom_y_ticks = np.concatenate((np.arange(2.5, 7, step=0.5),np.arange(7, 14, step=1)))\n",
    "custom_y_ticks = [2.3, 3.0, 3.401, 3.912, 4.605, 5.521, \n",
    "                  6.2146, 6.908, 8.294, 9.6803, 11.1562,\n",
    "                  12.89922]\n",
    "ax.set_yticks(np.array(custom_y_ticks),\n",
    "                np.round(np.exp(custom_y_ticks),-1).astype(int), \n",
    "                fontsize=11)\n",
    "xtic = ax.get_xticks()\n",
    "xtic[1] = 2\n",
    "ax.set_xticks(xtic, fontsize=11)\n",
    "ax.set_ylim([2.3, 14])\n",
    "ax.set_xlim([2, 200])\n",
    "plt.xlabel('Scan Time per Participant (mins)', fontsize=11)\n",
    "plt.ylabel('# Participants', fontsize=11)\n",
    "cbar = plt.colorbar(pad=0.02)\n",
    "\n",
    "prefix = os.path.join(img_dir,'Fig6_Theoretical_PredAcc_Graph_')\n",
    "fig.savefig(prefix + 'contour.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93109a45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Calculate correlation to ABCD and HCP contour plot in Fig 1\n",
    "#################################################\n",
    "theor_vals_unravel = np.flip(np.flip(theor_vals_flipped,1))\n",
    "\n",
    "# N \n",
    "theoretical_Y = np.exp(np.linspace(2, 14, num=10000))\n",
    "# T\n",
    "theoretical_X = np.linspace(1, 200, num=1000)\n",
    "\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir)\n",
    "b = 59\n",
    "behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,b].T),1)\n",
    "pred_sav = []\n",
    "actual_sav = []\n",
    "t_idx = 0\n",
    "for T_val in X:\n",
    "    n_idx = 0\n",
    "    T_diff = np.abs(theoretical_X - T_val)\n",
    "    T_closest = np.argmin(T_diff)\n",
    "    for N_val in Y:\n",
    "        N_diff = np.abs(theoretical_Y - N_val)\n",
    "        N_closest = np.argmin(N_diff)\n",
    "        #print(T_val, N_val )\n",
    "        pred_sav.append(theor_vals_unravel[N_closest,T_closest])\n",
    "        actual_sav.append(behav[n_idx,t_idx])\n",
    "        n_idx += 1\n",
    "    t_idx += 1\n",
    "#print(pred_sav, actual_sav )\n",
    "fig,ax = plt.subplots(figsize=(6, 6))\n",
    "plt.scatter(actual_sav,pred_sav)\n",
    "res = scipy.stats.linregress(actual_sav,pred_sav)\n",
    "xy_line = np.linspace(0.2,0.55,100)\n",
    "plt.plot(xy_line , res.intercept + res.slope*xy_line , 'k', linestyle='--')\n",
    "orsp.format_scatter_plot('HCP Prediction Accruacy (r)',\n",
    "                    'Predicted Frac of Max Accuracy', ax)\n",
    "corr_val = np.corrcoef(actual_sav,pred_sav)\n",
    "ax.text(0.8,0.1,'r = ' + str(np.round(corr_val[0][1],2)), transform=ax.transAxes, size=12)\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir)\n",
    "b = 36\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "pred_sav = []\n",
    "actual_sav = []\n",
    "t_idx = 0\n",
    "for T_val in X:\n",
    "    n_idx = 0\n",
    "    T_diff = np.abs(theoretical_X - T_val)\n",
    "    T_closest = np.argmin(T_diff)\n",
    "    for N_val in Y:\n",
    "        N_diff = np.abs(theoretical_Y - N_val)\n",
    "        N_closest = np.argmin(N_diff)\n",
    "        #print(T_val, N_val )\n",
    "        pred_sav.append(theor_vals_unravel[N_closest,T_closest])\n",
    "        actual_sav.append(behav[n_idx,t_idx])\n",
    "        n_idx += 1\n",
    "    t_idx += 1\n",
    "#print(pred_sav, actual_sav )\n",
    "fig,ax = plt.subplots(figsize=(6, 6))\n",
    "plt.scatter(actual_sav,pred_sav)\n",
    "res = scipy.stats.linregress(actual_sav,pred_sav)\n",
    "xy_line = np.linspace(0.2,0.5,100)\n",
    "plt.plot(xy_line , res.intercept + res.slope*xy_line , 'k', linestyle='--')\n",
    "orsp.format_scatter_plot('ABCD Prediction Accruacy (r)',\n",
    "                    'Predicted Frac of Max Accuracy', ax)\n",
    "ax.text(0.8,0.1,'r = ' + str(np.round(corr_val[0][1],2)), transform=ax.transAxes, size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319f704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_avgAcc(N, T, trainingsize = 0.9, rd = False):\n",
    "    theor_vals = []\n",
    "    training_N = trainingsize * N\n",
    "    if rd:\n",
    "        training_N = np.floor(training_N)\n",
    "    # load HCP results\n",
    "    HCP_behav_ind = HCP_rs_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir)\n",
    "    for b in HCP_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T)))) \n",
    "        theor_vals.append(b_acc)\n",
    "\n",
    "    # load ABCD results\n",
    "    ABCD_behav_ind = ABCD_rs_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir)\n",
    "    for b in ABCD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        theor_vals.append(b_acc)\n",
    "        \n",
    "    # load SINGER results\n",
    "    SINGER_behav_ind = SINGER_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('SINGER', 'predacc', rep_dir)\n",
    "    for b in SINGER_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        theor_vals.append(b_acc)\n",
    "        \n",
    "    # load TCP results\n",
    "    TCP_behav_ind = TCP_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('TCP', 'predacc', rep_dir)\n",
    "    for b in TCP_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        theor_vals.append(b_acc)\n",
    "        \n",
    "    # load MDD results\n",
    "    MDD_behav_ind = MDD_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('MDD', 'predacc', rep_dir)\n",
    "    for b in MDD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        theor_vals.append(b_acc)\n",
    "        \n",
    "    # load ADNI results\n",
    "    ADNI_behav_ind = ADNI_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ADNI', 'predacc', rep_dir)\n",
    "    for b in ADNI_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        theor_vals.append(b_acc)\n",
    "        \n",
    "    # load ABCD results\n",
    "    ABCD_behav_ind = ABCD_MID_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='full_MID')\n",
    "    for b in ABCD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        theor_vals.append(b_acc)\n",
    "        \n",
    "    # load ABCD results\n",
    "    ABCD_behav_ind = ABCD_NBACK_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='full_NBACK')\n",
    "    for b in ABCD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        theor_vals.append(b_acc)\n",
    "        \n",
    "    # load ABCD results\n",
    "    ABCD_behav_ind = ABCD_SST_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='full_SST')\n",
    "    for b in ABCD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        theor_vals.append(b_acc)\n",
    "    \n",
    "    # get confidence interval\n",
    "    c_int = 1.96 * np.std(theor_vals)/np.sqrt((len(theor_vals)))\n",
    "        \n",
    "    return np.mean(theor_vals,0),c_int\n",
    "\n",
    "#################################################\n",
    "# Tom's theoretical equations\n",
    "#################################################\n",
    "budgets = [10000000, 1000000, 100000]\n",
    "scanner_costs = np.array([500, 1000, 2000]) / 60\n",
    "recruitment_costs = [0, 500, 1000, 2000, 5000]\n",
    "max_T = 200\n",
    "theoretical_X = np.linspace(1, max_T, num=1000)\n",
    "y_bottom_lim = [0.65, 0.25, 0.1]\n",
    "perc = 1\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "gspec = gridspec.GridSpec(3,3,hspace=0.22,wspace=0.28)\n",
    "\n",
    "# add in various costs\n",
    "curr_y = 0\n",
    "for budget in budgets:\n",
    "    curr_x = 0\n",
    "    for scanner_cost in scanner_costs:\n",
    "        \n",
    "        ax = plt.subplot(gspec[curr_y,curr_x])\n",
    "\n",
    "        # $500 per participant\n",
    "        c = 'blue'\n",
    "        # smooth curve\n",
    "        remaining_Y = budget / (theoretical_X*scanner_cost + recruitment_costs[1])\n",
    "        final_predacc, c_int = calc_avgAcc(remaining_Y,theoretical_X)\n",
    "        l1,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0)\n",
    "        # limits using rounded down sample size\n",
    "        remaining_Y = np.floor(budget / (theoretical_X*scanner_cost + recruitment_costs[1]))\n",
    "        final_predacc, c_int = calc_avgAcc(remaining_Y,theoretical_X,rd=True)\n",
    "        lb,rb = orsp.calc_percOfmax(final_predacc,perc)\n",
    "        print(\"B$\"+str(budget)+\", S\"+ str(np.round(scanner_cost*60)) + \", P$500\")\n",
    "        print(\"Left bound: N=\", remaining_Y[lb], \" T=\", theoretical_X[lb])\n",
    "        print(\"Optima: N=\", remaining_Y[np.argmax(final_predacc)], \" T=\", theoretical_X[np.argmax(final_predacc)])\n",
    "        print(\"Right bound: N=\", remaining_Y[rb], \" T=\", theoretical_X[rb])\n",
    "        orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "        \n",
    "        # $1000 per participant\n",
    "        c = 'green'\n",
    "        # smooth curve\n",
    "        remaining_Y = budget / (theoretical_X*scanner_cost + recruitment_costs[2])\n",
    "        final_predacc, c_int = calc_avgAcc(remaining_Y,theoretical_X)\n",
    "        l2,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0)\n",
    "        # limits using rounded down sample size\n",
    "        remaining_Y = np.floor(budget / (theoretical_X*scanner_cost + recruitment_costs[2]))\n",
    "        final_predacc, c_int = calc_avgAcc(remaining_Y,theoretical_X)\n",
    "        orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "        # $2000 per participant\n",
    "        c = 'orange'\n",
    "        # smooth curve\n",
    "        remaining_Y = budget / (theoretical_X*scanner_cost + recruitment_costs[3])\n",
    "        final_predacc, c_int = calc_avgAcc(remaining_Y,theoretical_X)\n",
    "        l3,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0)\n",
    "        # limits using rounded down sample size\n",
    "        remaining_Y = np.floor(budget / (theoretical_X*scanner_cost + recruitment_costs[3]))\n",
    "        final_predacc, c_int = calc_avgAcc(remaining_Y,theoretical_X)\n",
    "        orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "        lb,rb = orsp.calc_percOfmax(final_predacc,perc)\n",
    "        print(\"B$\"+str(budget)+\", S\"+ str(np.round(scanner_cost*60)) + \", P$2k\")\n",
    "        print(\"Left bound: N=\", remaining_Y[lb], \" T=\", theoretical_X[lb])\n",
    "        print(\"Optima: N=\", remaining_Y[np.argmax(final_predacc)], \" T=\", theoretical_X[np.argmax(final_predacc)])\n",
    "        print(\"Right bound: N=\", remaining_Y[rb], \" T=\", theoretical_X[rb])\n",
    "\n",
    "        # $5000 per participant\n",
    "        c = 'red'\n",
    "        # smooth curve\n",
    "        remaining_Y = budget / (theoretical_X*scanner_cost + recruitment_costs[4])\n",
    "        final_predacc, c_int = calc_avgAcc(remaining_Y,theoretical_X)\n",
    "        l4,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0)\n",
    "        # limits using rounded down sample size\n",
    "        remaining_Y = np.floor(budget / (theoretical_X*scanner_cost + recruitment_costs[4]))\n",
    "        final_predacc, c_int = calc_avgAcc(remaining_Y,theoretical_X)\n",
    "        orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "        lb,rb = orsp.calc_percOfmax(final_predacc,perc)\n",
    "        print(\"B$\"+str(budget)+\", S\"+ str(np.round(scanner_cost*60)) + \", P$5k\")\n",
    "        print(\"Left bound: N=\", remaining_Y[lb], \" T=\", theoretical_X[lb])\n",
    "        print(\"Optima: N=\", remaining_Y[np.argmax(final_predacc)], \" T=\", theoretical_X[np.argmax(final_predacc)])\n",
    "        print(\"Right bound: N=\", remaining_Y[rb], \" T=\", theoretical_X[rb])\n",
    "        \n",
    "        # modify plotting settings\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xlabel('')\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "        ax.set_ylim([y_bottom_lim[curr_y],1.03])\n",
    "        ax.set_xlim([0,max_T])\n",
    "        ax.spines[['right', 'top']].set_visible(False)\n",
    "        # move to next plot\n",
    "        curr_x += 1\n",
    "    \n",
    "    # move to next plot\n",
    "    curr_y += 1\n",
    "    \n",
    "plt.legend(handles=[l1,l2,l3,l4], \n",
    "           labels=['$500', '$1000', '$2000', '$5000'],\n",
    "           title=\"Overhead Cost Per participant\",title_fontproperties={'family' : 'Arial', 'weight':'bold', 'size': 11},\n",
    "           frameon=False, bbox_to_anchor=[0.5, -0.5], ncol=5)\n",
    "\n",
    "fig.savefig(os.path.join(img_dir,'Fig6_BudgetvsAcc.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9801d7",
   "metadata": {},
   "source": [
    "# Supplementary xlsx of prediction accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245520b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save prediction accuracy results\n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir)\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_HCP_PredAcc.xlsx')\n",
    "mode = 'w'\n",
    "for b in np.append(range(0,58),59):\n",
    "    behav = HCP_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=700','N=600','N=500',\n",
    "                'N=400','N=300','N=200']\n",
    "    df.columns = ['T=2min','T=4min','T=6min','T=8min','T=10min',\n",
    "                       'T=12min','T=14min','T=16min','T=18min','T=20min',\n",
    "                       'T=22min','T=24min','T=26min','T=28min','T=30min',\n",
    "                       'T=32min','T=34min','T=36min','T=38min','T=40min',\n",
    "                       'T=42min','T=44min','T=46min','T=48min','T=50min',\n",
    "                       'T=52min','T=54min','T=56min','T=58min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        if b == 59:\n",
    "            df.to_excel(writer, sheet_name = 'HCP score '+str(59))\n",
    "        else:\n",
    "            df.to_excel(writer, sheet_name = 'HCP score '+str(b+1))\n",
    "        mode = 'a'\n",
    "            \n",
    "# load ABCD rest data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir)\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_ABCD_rest_PredAcc.xlsx')\n",
    "mode = 'w'\n",
    "for b in np.append(range(0,36),36):\n",
    "    behav = ABCD_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=1800','N=1600','N=1400','N=1200','N=1000',\n",
    "                'N=800','N=600','N=400','N=200']\n",
    "    df.columns = ['T=2min','T=4min','T=6min','T=8min','T=10min',\n",
    "                       'T=12min','T=14min','T=16min','T=18min','T=20min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'ABCD score '+str(b+1))\n",
    "        mode = 'a'\n",
    "    \n",
    "# load SINGER data\n",
    "SINGER_img_dir,SINGER_res,X,Y,SINGER_extent,scan_duration = orsp.load_data('SINGER', 'predacc', rep_dir)\n",
    "scores_names = SINGER_scores\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_SINGER_PredAcc.xlsx')\n",
    "mode = 'w'\n",
    "for b in range(0,19):\n",
    "    behav = SINGER_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=580','N=500','N=400','N=300',\n",
    "                'N=200','N=100']\n",
    "    df.columns = ['T=2min','T=3min','T=4min','T=5min','T=6min',\n",
    "                       'T=7min','T=8min','T=9min','T=10min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'SINGER score '+str(b+1))\n",
    "        mode = 'a'\n",
    "    create_file = 0\n",
    "    \n",
    "# load TCP data\n",
    "TCP_img_dir,TCP_res,X,Y,TCP_extent,scan_duration = orsp.load_data('TCP', 'predacc', rep_dir)\n",
    "scores_names = TCP_scores\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_TCP_PredAcc.xlsx')\n",
    "mode = 'w'\n",
    "for b in range(0,19):\n",
    "    behav = TCP_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=175','N=150','N=125','N=100',\n",
    "                'N=75','N=50']\n",
    "    df.columns = ['T=2min','T=4min','T=6min','T=8min','T=10min',\n",
    "                       'T=12min','T=14min','T=16min','T=18min',\n",
    "                       'T=20min','T=22min','T=24min','T=26min',]\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'TCP score '+str(b+1))\n",
    "        mode = 'a'\n",
    "    create_file = 0\n",
    "    \n",
    "# load MDD data\n",
    "MDD_img_dir,MDD_res,X,Y,MDD_extent,scan_duration = orsp.load_data('MDD', 'predacc', rep_dir)\n",
    "scores_names = SINGER_scores\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_MDD_PredAcc.xlsx')\n",
    "mode = 'w'\n",
    "for b in range(0,20):\n",
    "    behav = MDD_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=260','N=250','N=225','N=200',\n",
    "                'N=175','N=150','N=125','N=100',\n",
    "                'N=75','N=50']\n",
    "    df.columns = ['T=3min','T=5min','T=7min','T=9min','T=11min',\n",
    "                       'T=13min','T=15min','T=17min','T=19min',\n",
    "                       'T=21min','T=23min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'MDD score '+str(b+1))\n",
    "        mode = 'a'\n",
    "    create_file = 0\n",
    "    \n",
    "# load ADNI data\n",
    "ADNI_img_dir,ADNI_res,X,Y,ADNI_extent,scan_duration = orsp.load_data('ADNI', 'predacc', rep_dir)\n",
    "scores_names = ADNI_scores\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_ADNI_PredAcc.xlsx')\n",
    "mode = 'w'\n",
    "for b in np.append(range(0,1),range(3,7)):\n",
    "    behav = ADNI_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=500','N=400','N=300','N=200',\n",
    "                'N=100']\n",
    "    df.columns = ['T=2min','T=3min','T=4min','T=5min','T=6min',\n",
    "                       'T=7min','T=8min','T=9min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        if b < 2:\n",
    "            df.to_excel(writer, sheet_name = 'ADNI score '+str(b))\n",
    "        else:\n",
    "            df.to_excel(writer, sheet_name = 'ADNI score '+str(b+1))\n",
    "        mode = 'a'\n",
    "    create_file = 0\n",
    "\n",
    "# load ABCD MID data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir,vers='full_MID')\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_ABCD_MID_PredAcc.xlsx')\n",
    "mode = 'w'\n",
    "for b in np.append(range(0,36),36):\n",
    "    behav = ABCD_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=1600','N=1400','N=1200','N=1000',\n",
    "                'N=800','N=600','N=400','N=200']\n",
    "    df.columns = ['T=2min','T=3min','T=4min','T=5min','T=6min',\n",
    "                       'T=7min','T=8min','T=9min','T=10min','T=11min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'ABCD score '+str(b+1))\n",
    "        mode = 'a'\n",
    "        \n",
    "# load ABCD NBACK data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir,vers='full_NBACK')\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_ABCD_NBACK_PredAcc.xlsx')\n",
    "mode = 'w'\n",
    "for b in np.append(range(0,36),36):\n",
    "    behav = ABCD_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=1600','N=1400','N=1200','N=1000',\n",
    "                'N=800','N=600','N=400','N=200']\n",
    "    df.columns = ['T=2min','T=3min','T=4min','T=5min','T=6min',\n",
    "                       'T=7min','T=8min','T=9min','T=10min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'ABCD score '+str(b+1))\n",
    "        mode = 'a'\n",
    "        \n",
    "# load ABCD SST data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir,vers='full_SST')\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_ABCD_SST_PredAcc.xlsx')\n",
    "mode = 'w'\n",
    "for b in np.append(range(0,36),36):\n",
    "    behav = ABCD_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=1600','N=1400','N=1200','N=1000',\n",
    "                'N=800','N=600','N=400','N=200']\n",
    "    df.columns = ['T=2min','T=3min','T=4min','T=5min','T=6min',\n",
    "                       'T=7min','T=8min','T=9min','T=10min','T=11min','T=12min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'ABCD score '+str(b+1))\n",
    "        mode = 'a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ccab35",
   "metadata": {},
   "source": [
    "# Supplementary xlsx of theoretical model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bfce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save prediction accuracy results\n",
    "xlsx_path = os.path.join(img_dir,'CBIG_ME_TheoreticalModel_Params.xlsx')\n",
    "\n",
    "# categories\n",
    "# ABCD\n",
    "abcd_mh = [0,1,2,3,4,5,6,7,27,28,29]\n",
    "abcd_cog = [8,9,10,11,12,13,14,15,16,17,30,31,32,33,34,35,36]\n",
    "abcd_pers=[18,19,20,21,22,23,24,25,26]\n",
    "# HCP\n",
    "hcp_cog = [0,1,2,3,4,5,6,8,9,10,11,12,13,24,25,26,27,28,29,59]\n",
    "hcp_pers = [7,30,31,32,33,34]\n",
    "hcp_phy = [14,15,16,17,18,19,20,21,22]\n",
    "hcp_emo = [23,35,36,37,38,39,40,41,42,43,44,45,46]\n",
    "hcp_wb = [47,48,49,50,51,52,53,54,55,56,57]\n",
    "# SINGER\n",
    "singer_phy = [0,3,4,5]\n",
    "singer_cog = [1,2,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "# TCP\n",
    "tcp_phy = [0,18]\n",
    "tcp_mh = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "# MDD\n",
    "mdd_phy = [0,18]\n",
    "mdd_mh = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,19]\n",
    "# ADNI\n",
    "adni_phy = [0,1]\n",
    "adni_cog = [3,4]\n",
    "adni_pet = [5,6]\n",
    "\n",
    "# load ABCD full data\n",
    "c_vers = 'full'\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir,vers=c_vers)\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "for b in ABCD_rs_log_ind:\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    # find score type\n",
    "    cat = []\n",
    "    if b in abcd_cog:\n",
    "        cat = \"Cognition\"\n",
    "    elif b in abcd_mh:\n",
    "        cat = \"Mental Health\"\n",
    "    elif b in abcd_pers:\n",
    "        cat = \"Personality\"\n",
    "    new_row = pd.DataFrame({'Dataset': 'ABCD', 'Version': c_vers,\n",
    "                            'Phenotype':scores_names[b],'Category': cat,\n",
    "                            'K0':w[0], 'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "    \n",
    "# load HCP full data\n",
    "c_vers = 'full'\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir,vers=c_vers)\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "for b in HCP_rs_log_ind:\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    # find score type\n",
    "    cat = []\n",
    "    if b in hcp_cog:\n",
    "        cat = \"Cognition\"\n",
    "    elif b in hcp_pers:\n",
    "        cat = \"Personality\"\n",
    "    elif b in hcp_phy:\n",
    "        cat = \"Physical\"\n",
    "    elif b in hcp_emo:\n",
    "        cat = \"Emotion\"\n",
    "    elif b in hcp_wb:\n",
    "        cat = \"Well Being\"\n",
    "    new_row = pd.DataFrame({'Dataset': 'HCP', 'Version': c_vers,\n",
    "                            'Phenotype':scores_names[b],'Category': cat,\n",
    "                            'K0':w[0], 'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "    \n",
    "# load SINGER full data\n",
    "c_vers = 'full'\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('SINGER', 'predacc', rep_dir,vers=c_vers)\n",
    "scores_names = SINGER_scores\n",
    "for b in SINGER_log_ind:\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    # find score type\n",
    "    cat = []\n",
    "    if b in singer_cog:\n",
    "        cat = \"Cognition\"\n",
    "    elif b in singer_phy:\n",
    "        cat = \"Physical\"\n",
    "    new_row = pd.DataFrame({'Dataset': 'SINGER', 'Version': c_vers,\n",
    "                            'Phenotype':scores_names[b],'Category': cat,\n",
    "                            'K0':w[0], 'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "    \n",
    "# load TCP full data\n",
    "c_vers = 'full'\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('TCP', 'predacc', rep_dir,vers=c_vers)\n",
    "scores_names = TCP_scores\n",
    "for b in TCP_log_ind:\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    # find score type\n",
    "    cat = []\n",
    "    if b in tcp_phy:\n",
    "        cat = \"Physical\"\n",
    "    elif b in tcp_mh:\n",
    "        cat = \"Mental Health\"\n",
    "    new_row = pd.DataFrame({'Dataset': 'TCP', 'Version': c_vers,\n",
    "                            'Phenotype':scores_names[b],'Category': cat,\n",
    "                            'K0':w[0], 'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "    \n",
    "# load MDD full data\n",
    "c_vers = 'full'\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('MDD', 'predacc', rep_dir,vers=c_vers)\n",
    "scores_names = MDD_scores\n",
    "for b in MDD_log_ind:\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    # find score type\n",
    "    cat = []\n",
    "    if b in mdd_phy:\n",
    "        cat = \"Physical\"\n",
    "    elif b in mdd_mh:\n",
    "        cat = \"Mental Health\"\n",
    "    new_row = pd.DataFrame({'Dataset': 'MDD', 'Version': c_vers,\n",
    "                            'Phenotype':scores_names[b],'Category': cat,\n",
    "                            'K0':w[0], 'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "    \n",
    "# load ADNI full data\n",
    "c_vers = 'full'\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ADNI', 'predacc', rep_dir,vers=c_vers)\n",
    "scores_names = ADNI_scores\n",
    "for b in ADNI_log_ind:\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    # find score type\n",
    "    cat = []\n",
    "    if b in adni_cog:\n",
    "        cat = \"Cognition\"\n",
    "    elif b in adni_phy:\n",
    "        cat = \"Physical\"\n",
    "    elif b in adni_pet:\n",
    "        cat = \"PET\"\n",
    "    new_row = pd.DataFrame({'Dataset': 'ADNI', 'Version': c_vers,\n",
    "                            'Phenotype':scores_names[b],'Category': cat,\n",
    "                            'K0':w[0], 'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "    \n",
    "# load ABCD MID data\n",
    "c_vers = 'full_MID'\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir,vers=c_vers)\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "for b in ABCD_MID_log_ind:\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    # find score type\n",
    "    cat = []\n",
    "    if b in abcd_cog:\n",
    "        cat = \"Cognition\"\n",
    "    elif b in abcd_mh:\n",
    "        cat = \"Mental Health\"\n",
    "    elif b in abcd_pers:\n",
    "        cat = \"Personality\"\n",
    "    new_row = pd.DataFrame({'Dataset': 'ABCD', 'Version': c_vers,\n",
    "                            'Phenotype':scores_names[b],'Category': cat,\n",
    "                            'K0':w[0], 'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "    \n",
    "# load ABCD NBACK data\n",
    "c_vers = 'full_NBACK'\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir,vers=c_vers)\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "for b in ABCD_NBACK_log_ind:\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    # find score type\n",
    "    cat = []\n",
    "    if b in abcd_cog:\n",
    "        cat = \"Cognition\"\n",
    "    elif b in abcd_mh:\n",
    "        cat = \"Mental Health\"\n",
    "    elif b in abcd_pers:\n",
    "        cat = \"Personality\"\n",
    "    new_row = pd.DataFrame({'Dataset': 'ABCD', 'Version': c_vers,\n",
    "                            'Phenotype':scores_names[b],'Category': cat,\n",
    "                            'K0':w[0], 'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "    \n",
    "# load ABCD SST data\n",
    "c_vers = 'full_SST'\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir,vers=c_vers)\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "for b in ABCD_SST_log_ind:\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    # find score type\n",
    "    cat = []\n",
    "    if b in abcd_cog:\n",
    "        cat = \"Cognition\"\n",
    "    elif b in abcd_mh:\n",
    "        cat = \"Mental Health\"\n",
    "    elif b in abcd_pers:\n",
    "        cat = \"Personality\"\n",
    "    new_row = pd.DataFrame({'Dataset': 'ABCD', 'Version': c_vers,\n",
    "                            'Phenotype':scores_names[b],'Category': cat,\n",
    "                            'K0':w[0], 'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "    \n",
    "with pd.ExcelWriter(xlsx_path,mode='w') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'Theoretical Model Params', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ABCD reliability data\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'tstats', rep_dir)\n",
    "full_df = pd.DataFrame()\n",
    "for b in np.append(ABCD_log_ind, 36):\n",
    "    w = w_r_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'ABCD univariate BWAS param', index=False)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'Haufe', rep_dir)\n",
    "full_df = pd.DataFrame()\n",
    "for b in np.append(ABCD_log_ind, 36):\n",
    "    w = w_r_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'ABCD multivariate BWAS param', index=False)\n",
    "\n",
    "# load HCP predacc data\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir)\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "full_df = pd.DataFrame()\n",
    "#HCP_behav_ind = [1, 2, 3, 4, 5, 6, 7, 8, 22, 23, 24, 25, 26, 29, 32, 47, 59]\n",
    "for b in np.append(HCP_log_ind, 59):\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'HCP pred acc param', index=False)\n",
    "\n",
    "# load HCP reliability data\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'tstats', rep_dir)\n",
    "full_df = pd.DataFrame()\n",
    "for b in np.append(HCP_log_ind, 59):\n",
    "    w = w_r_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'HCP univariate BWAS param', index=False)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'Haufe', rep_dir)\n",
    "full_df = pd.DataFrame()\n",
    "for b in np.append(HCP_log_ind, 59):\n",
    "    w = w_r_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'HCP multivariate BWAS param', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c89c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save prediction accuracy results\n",
    "xlsx_path = os.path.join(img_dir,'PredAcc_randomized.xlsx')\n",
    "create_file = 1\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir, vers='random')\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "for b in np.append(range(0,36),36):\n",
    "    behav = ABCD_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=1800','N=1600','N=1400','N=1200','N=1000',\n",
    "                'N=800','N=600','N=400','N=200']\n",
    "    df.columns = ['T=2min','T=4min','T=6min','T=8min','T=10min',\n",
    "                       'T=12min','T=14min','T=16min','T=18min','T=20min']\n",
    "    if create_file:\n",
    "        mode = 'w'\n",
    "    else:\n",
    "        mode = 'a'\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'ABCD score '+str(b+1))\n",
    "    create_file = 0\n",
    "    \n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir, vers='random')\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "for b in np.append(range(0,58),59):\n",
    "    behav = HCP_res['acc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=700','N=600','N=500',\n",
    "                'N=400','N=300','N=200']\n",
    "    df.columns = ['T=2min','T=4min','T=6min','T=8min','T=10min',\n",
    "                       'T=12min','T=14min','T=16min','T=18min','T=20min',\n",
    "                       'T=22min','T=24min','T=26min','T=28min','T=30min',\n",
    "                       'T=32min','T=34min','T=36min','T=38min','T=40min',\n",
    "                       'T=42min','T=44min','T=46min','T=48min','T=50min',\n",
    "                       'T=52min','T=54min','T=56min','T=58min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        if b == 59:\n",
    "            df.to_excel(writer, sheet_name = 'HCP score '+str(59))\n",
    "        else:\n",
    "            df.to_excel(writer, sheet_name = 'HCP score '+str(b+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save prediction accuracy results\n",
    "xlsx_path = os.path.join(img_dir,'univariate_BWAS.xlsx')\n",
    "create_file = 1\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'tstats', rep_dir)\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "for b in np.append(range(0,36),36):\n",
    "    behav = ABCD_res['tstats_icc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=1200','N=1000','N=800',\n",
    "                'N=600','N=400','N=200']\n",
    "    df.columns = ['T=2min','T=4min','T=6min','T=8min','T=10min',\n",
    "                       'T=12min','T=14min','T=16min','T=18min','T=20min']\n",
    "    if create_file:\n",
    "        mode = 'w'\n",
    "    else:\n",
    "        mode = 'a'\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'ABCD score '+str(b+1))\n",
    "    create_file = 0\n",
    "    \n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'tstats', rep_dir)\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "for b in np.append(range(0,58),59):\n",
    "    behav = HCP_res['tstats_icc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=400','N=350','N=300',\n",
    "                'N=250','N=200','N=150']\n",
    "    df.columns = ['T=2min','T=4min','T=6min','T=8min','T=10min',\n",
    "                       'T=12min','T=14min','T=16min','T=18min','T=20min',\n",
    "                       'T=22min','T=24min','T=26min','T=28min','T=30min',\n",
    "                       'T=32min','T=34min','T=36min','T=38min','T=40min',\n",
    "                       'T=42min','T=44min','T=46min','T=48min','T=50min',\n",
    "                       'T=52min','T=54min','T=56min','T=58min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        if b == 59:\n",
    "            df.to_excel(writer, sheet_name = 'HCP score '+str(59))\n",
    "        else:\n",
    "            df.to_excel(writer, sheet_name = 'HCP score '+str(b+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64fa4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save prediction accuracy results\n",
    "xlsx_path = os.path.join(img_dir,'multivariate_BWAS.xlsx')\n",
    "create_file = 1\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'Haufe', rep_dir)\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "for b in np.append(range(0,36),36):\n",
    "    behav = ABCD_res['fi_icc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=1200','N=1000','N=800',\n",
    "                'N=600','N=400','N=200']\n",
    "    df.columns = ['T=2min','T=4min','T=6min','T=8min','T=10min',\n",
    "                       'T=12min','T=14min','T=16min','T=18min','T=20min']\n",
    "    if create_file:\n",
    "        mode = 'w'\n",
    "    else:\n",
    "        mode = 'a'\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        df.to_excel(writer, sheet_name = 'ABCD score '+str(b+1))\n",
    "    create_file = 0\n",
    "    \n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'Haufe', rep_dir)\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "for b in np.append(range(0,58),59):\n",
    "    behav = HCP_res['fi_icc_landscape'][:,:,b].T\n",
    "    df = pd.DataFrame(behav)\n",
    "    df.index = ['N=400','N=350','N=300',\n",
    "                'N=250','N=200','N=150']\n",
    "    df.columns = ['T=2min','T=4min','T=6min','T=8min','T=10min',\n",
    "                       'T=12min','T=14min','T=16min','T=18min','T=20min',\n",
    "                       'T=22min','T=24min','T=26min','T=28min','T=30min',\n",
    "                       'T=32min','T=34min','T=36min','T=38min','T=40min',\n",
    "                       'T=42min','T=44min','T=46min','T=48min','T=50min',\n",
    "                       'T=52min','T=54min','T=56min','T=58min']\n",
    "    with pd.ExcelWriter(xlsx_path,mode=mode) as writer: \n",
    "        if b == 59:\n",
    "            df.to_excel(writer, sheet_name = 'HCP score '+str(59))\n",
    "        else:\n",
    "            df.to_excel(writer, sheet_name = 'HCP score '+str(b+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d792aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save prediction accuracy results\n",
    "xlsx_path = os.path.join(img_dir,'Theoretical_Calculator_randomized.xlsx')\n",
    "\n",
    "# load ABCD predacc data\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='random')\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "full_df = pd.DataFrame()\n",
    "ABCD_behav_ind = [8, 10, 11, 13, 14, 15, 16, 17, 29, 30, 31, 32, 33, 36]\n",
    "for b in np.append(ABCD_log_ind, 36):\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='w') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'ABCD pred acc param', index=False)\n",
    "    \n",
    "# load ABCD reliability data\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'tstats', rep_dir, vers='random')\n",
    "full_df = pd.DataFrame()\n",
    "for b in np.append(ABCD_log_ind, 36):\n",
    "    w = w_r_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'ABCD univariate BWAS param', index=False)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'Haufe', rep_dir, vers='random')\n",
    "full_df = pd.DataFrame()\n",
    "for b in np.append(ABCD_log_ind, 36):\n",
    "    w = w_r_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'ABCD multivariate BWAS param', index=False)\n",
    "\n",
    "# load HCP predacc data\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir, vers='random')\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "full_df = pd.DataFrame()\n",
    "#HCP_behav_ind = [1, 2, 3, 4, 5, 6, 7, 8, 22, 23, 24, 25, 26, 29, 32, 47, 59]\n",
    "for b in np.append(HCP_log_ind, 59):\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'HCP pred acc param', index=False)\n",
    "\n",
    "# load HCP reliability data\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'tstats', rep_dir, vers='random')\n",
    "full_df = pd.DataFrame()\n",
    "for b in np.append(HCP_log_ind, 59):\n",
    "    w = w_r_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'HCP univariate BWAS param', index=False)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'Haufe', rep_dir)\n",
    "full_df = pd.DataFrame()\n",
    "for b in np.append(HCP_log_ind, 59):\n",
    "    w = w_r_all[b,-1,:]\n",
    "    new_row = pd.DataFrame({'Phenotype':scores_names[b], 'K0':w[0], \n",
    "                            'K1':w[1], 'K2':w[2]}, index=[0])\n",
    "    full_df = pd.concat([full_df, new_row]).reset_index(drop=True)\n",
    "with pd.ExcelWriter(xlsx_path,mode='a') as writer: \n",
    "    full_df.to_excel(writer, sheet_name = 'HCP multivariate BWAS param', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5ff1fb",
   "metadata": {},
   "source": [
    "# Fig S1-S5: Contour Plots (HCP & ABCD different preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e0b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(8.5,4.5))\n",
    "fig.tight_layout(pad=7)\n",
    "\n",
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir,\n",
    "                                                             vers='full', reg='KRR', metric='COD')\n",
    "# Cognition\n",
    "con_lines = [0.05, 0.1, 0.2]\n",
    "manual_locations = [(1.5,0.3),(6.5,1.5), (11,2.5)]\n",
    "behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, HCP_extent, \n",
    "                      fig, axs[1], Ax_Ttl='HCP')\n",
    "\n",
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir,\n",
    "                                                             vers='full', reg='KRR', metric='COD')\n",
    "# Cognition\n",
    "con_lines = [0.05, 0.15, 0.2]\n",
    "manual_locations = [(1,0.3),(4,1.5),(8.5,3)]\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, ABCD_extent, \n",
    "                      fig, axs[0], Ax_Ttl='ABCD')\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS1_' +\n",
    "                    'KRR_full_acc_COD_contour.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863df6b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(8.5,4.5))\n",
    "fig.tight_layout(pad=7)\n",
    "\n",
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir,\n",
    "                                                             vers='uncensored_only', reg='KRR', metric='corr')\n",
    "# Cognition\n",
    "con_lines = [0.3, 0.4, 0.5]\n",
    "manual_locations = [(1.5,0.3),(6.5,1.5),(20,5)]\n",
    "behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, HCP_extent, \n",
    "                      fig, axs[1], Ax_Ttl='HCP')\n",
    "\n",
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir,\n",
    "                                                             vers='uncensored_only', reg='KRR', metric='corr')\n",
    "# Cognition\n",
    "con_lines = [0.3, 0.4, 0.45]\n",
    "manual_locations = [(1,0.3),(4,1.5),(5,3)]\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, ABCD_extent, \n",
    "                      fig, axs[0], Ax_Ttl='ABCD')\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS2_' +\n",
    "                    'KRR_uncensored_only_acc_corr_contour.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9547e2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(8.5,4.5))\n",
    "fig.tight_layout(pad=7)\n",
    "\n",
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir,\n",
    "                                                             vers='no_censoring', reg='KRR', metric='corr')\n",
    "# Cognition\n",
    "con_lines = [0.3, 0.4, 0.5]\n",
    "manual_locations = [(1.5,0.3),(6.5,1.5),(12.5,3)]\n",
    "behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, HCP_extent, \n",
    "                      fig, axs[1], Ax_Ttl='HCP')\n",
    "\n",
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir,\n",
    "                                                             vers='no_censoring', reg='KRR', metric='corr')\n",
    "# Cognition\n",
    "con_lines = [0.3, 0.4, 0.5]\n",
    "manual_locations = [(1,0.3),(4,1.5),(8.5,8)]\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, ABCD_extent, \n",
    "                      fig, axs[0], Ax_Ttl='ABCD')\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS3_' +\n",
    "                    'KRR_no_censoring_acc_corr_contour.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e2ff12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(8.5,4.5))\n",
    "fig.tight_layout(pad=7)\n",
    "\n",
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir,\n",
    "                                                             vers='full', reg='LRR', metric='corr')\n",
    "# Cognition\n",
    "con_lines = [0.3, 0.4, 0.5]\n",
    "manual_locations = [(1.5,0.3),(6.5,1.5),(18,5)]\n",
    "behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, HCP_extent, \n",
    "                      fig, axs[1], Ax_Ttl='HCP')\n",
    "\n",
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir,\n",
    "                                                             vers='full', reg='LRR', metric='corr')\n",
    "# Cognition\n",
    "con_lines = [0.3, 0.4]\n",
    "manual_locations = [(1,0.3),(4,1.5)]\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, ABCD_extent, \n",
    "                      fig, axs[0], Ax_Ttl='ABCD')\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS4_' +\n",
    "                    'LRR_full_acc_corr_contour.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b09cbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(8.5,4.5))\n",
    "fig.tight_layout(pad=7)\n",
    "\n",
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir,\n",
    "                                                             vers='full', reg='LRR', metric='COD')\n",
    "# Cognition\n",
    "con_lines = [0.05, 0.2]\n",
    "manual_locations = [(1.5,0.3),(18,5)]\n",
    "behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, HCP_extent, \n",
    "                      fig, axs[1], Ax_Ttl='HCP')\n",
    "\n",
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir,\n",
    "                                                             vers='full', reg='LRR', metric='COD')\n",
    "# Cognition\n",
    "con_lines = [0.05, 0.15]\n",
    "manual_locations = [(1,0.3),(8,4)]\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, ABCD_extent, \n",
    "                      fig, axs[0], Ax_Ttl='ABCD')\n",
    "fig.savefig(os.path.join(img_dir, 'FigS5_' +\n",
    "                    'LRR_full_acc_COD_contour.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e1f6d",
   "metadata": {},
   "source": [
    "# Fig S6: Correlation between common points in ABCD and HCP contour plots (pred acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98241e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir)\n",
    "behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "hcp_behav = behav[[0,2,4],:10].ravel()\n",
    "\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'predacc', rep_dir)\n",
    "behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "abcd_behav = behav[:3,:].ravel()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6, 6))\n",
    "plt.scatter(abcd_behav,hcp_behav)\n",
    "res = scipy.stats.linregress(abcd_behav,hcp_behav)\n",
    "xy_line = np.linspace(0.2,0.5,100)\n",
    "plt.plot(xy_line , res.intercept + res.slope*xy_line , 'k', linestyle='--')\n",
    "orsp.format_scatter_plot('ABCD Prediction Accruacy (r)',\n",
    "                    'HCP Prediction Accruacy (r)', ax)\n",
    "corr_val = np.corrcoef(abcd_behav,hcp_behav)\n",
    "ax.text(0.8,0.1,'r = ' + str(np.round(corr_val[0][1],2)), transform=ax.transAxes, size=12)\n",
    "np.corrcoef(abcd_behav,hcp_behav)\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS6_ABCD_HCP_KRR_commonpts_predacc_correlation.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d8721",
   "metadata": {},
   "source": [
    "# Fig S7: Scatter plots for ABCD behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ba78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = ABCD_rs_log_ind\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for n in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,n].T),1)\n",
    "    for limit in [10]:\n",
    "        orsp.plot_scatter(9,behav,scan_duration,ABCD_subcolors,limit,axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].legend(ABCD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "        orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                            'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "        #axs[plot_y][plot_x].set_xlim(0,40)\n",
    "        axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "        axs[plot_y][plot_x].set_title(scores_names[n],fontname='Arial')\n",
    "        \n",
    "        # move to next plot\n",
    "        if plot_x == 0:\n",
    "            plot_x += 1\n",
    "        else:\n",
    "            plot_x = 0\n",
    "            if plot_y != 2:\n",
    "                plot_y += 1\n",
    "            else: \n",
    "                plot_y = 0\n",
    "        # move to next figure\n",
    "        if (behav_count % 6) == 0:\n",
    "            fig.savefig(os.path.join(img_dir, 'FigS7.' + str(plot_num) +\n",
    "                    '_ABCD_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "            fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "            fig.tight_layout(h_pad=5, w_pad=7)\n",
    "            plot_num += 1\n",
    "        # continue behavior count\n",
    "        # turn off remaining subplots if last behavior\n",
    "        if behav_count == len(behav_ind):\n",
    "            while plot_y != 3:\n",
    "                axs[plot_y][plot_x].axis('off')\n",
    "                if plot_x == 0:\n",
    "                    plot_x += 1\n",
    "                else:\n",
    "                    plot_x = 0\n",
    "                    if plot_y != 3:\n",
    "                        plot_y += 1\n",
    "            fig.savefig(os.path.join(img_dir, 'FigS7.' + str(plot_num) +\n",
    "                    '_ABCD_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        else:\n",
    "            behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f65d1b",
   "metadata": {},
   "source": [
    "# Fig S8: Scatter plots for HCP behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04937e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = HCP_rs_log_ind\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for n in behav_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    for limit in [29,10]:\n",
    "        orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,limit,axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].legend(HCP_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "        orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                            'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].set_xlim(0,40000)\n",
    "        axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "        axs[plot_y][plot_x].set_title(scores_names[n] + ' (' + str(limit*2) + 'mins)', fontname='Arial')\n",
    "        \n",
    "        # move to next plot\n",
    "        if plot_x == 0:\n",
    "            plot_x += 1\n",
    "        else:\n",
    "            plot_x = 0\n",
    "            if plot_y != 2:\n",
    "                plot_y += 1\n",
    "            else: \n",
    "                plot_y = 0\n",
    "        # move to next figure\n",
    "        if (behav_count % 3) == 0 and limit == 10:\n",
    "            fig.savefig(os.path.join(img_dir, 'FigS8.' + str(plot_num) +\n",
    "                    '_HCP_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "            fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "            fig.tight_layout(h_pad=5, w_pad=7)\n",
    "            plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS8.' + str(plot_num) +\n",
    "                '_HCP_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c4f31",
   "metadata": {},
   "source": [
    "# Fig S9: Log Plot (Cog Factors / Different regressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b706461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### plot for both HCP and ABCD\n",
    "fig,ax = plt.subplots(figsize=(8.5, 4.5))\n",
    "\n",
    "### settings\n",
    "output_vers = 'output'\n",
    "vers = 'full'\n",
    "regs = ['LRR', 'KRR']\n",
    "metrics = ['COD', 'corr']\n",
    "\n",
    "hcp_cp = sns.color_palette(\"blend:paleturquoise,teal\",n_colors=4)\n",
    "abcd_cp = sns.color_palette(\"blend:mistyrose,crimson\",n_colors=4)\n",
    "reg_lgd = [plt.Line2D([], [], marker='.', color=hcp_cp[0], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=hcp_cp[1], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=hcp_cp[2], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=hcp_cp[3], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=abcd_cp[0], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=abcd_cp[1], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=abcd_cp[2], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=abcd_cp[3], linestyle='None')]\n",
    "\n",
    "\n",
    "n_c = 0\n",
    "for reg in regs:\n",
    "    for metric in metrics:\n",
    "        # read output files\n",
    "        HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data(\n",
    "            'HCP','predacc', rep_dir,reg=reg,metric=metric)\n",
    "\n",
    "        # HCP scan parameters\n",
    "        cog = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "        limit = 15\n",
    "        cog = cog[:,:limit]\n",
    "        curr_scan = scan_duration[:,:limit]\n",
    "\n",
    "        # fit curve\n",
    "        z,k = orsp.lst_sq_log(curr_scan.flatten(), cog.flatten())\n",
    "        norm_acc = (cog - k) / z \n",
    "        sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=hcp_cp[n_c])\n",
    "        \n",
    "        #################################################\n",
    "\n",
    "        # read output files\n",
    "        ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data(\n",
    "            'ABCD', 'predacc', rep_dir,reg=reg,metric=metric)\n",
    "\n",
    "        # ABCD scan parameters\n",
    "        cog = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "        curr_scan = scan_duration\n",
    "        # fit curve\n",
    "        z,k = orsp.lst_sq_log(curr_scan.flatten(), cog.flatten())\n",
    "        norm_acc = (cog - k) / z \n",
    "        sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=abcd_cp[n_c])\n",
    "        n_c += 1\n",
    "\n",
    "labels = ['HCP: LRR (COD)', 'HCP: LRR (r)', 'HCP: KRR (COD)', 'HCP: KRR (r)', \n",
    "         'ABCD: LRR (COD)', 'ABCD: LRR (r)', 'ABCD: KRR (COD)', 'ABCD: KRR (r)' ]\n",
    "lgd = plt.legend(reg_lgd, labels, markerscale=2, loc='lower right', \n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "# plot fitted curve\n",
    "orsp.plot_curve(200, 37000)\n",
    "\n",
    "# set custom limits\n",
    "ax.set_ylim([7.5, 16.5])\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants x scan time per participant)',\n",
    "                    'Norm. prediction performance', ax)\n",
    "fig.savefig(os.path.join(img_dir, 'FigS9_ScanTime_AllReg_AllMetric.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393099f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot for both HCP and ABCD\n",
    "fig,ax = plt.subplots(figsize=(8.5, 4.5))\n",
    "### settings\n",
    "output_vers = 'output'\n",
    "vers = 'full'\n",
    "regs = ['LRR', 'KRR']\n",
    "metrics = ['COD', 'corr']\n",
    "\n",
    "hcp_cp = sns.color_palette(\"blend:paleturquoise,teal\",n_colors=4)\n",
    "abcd_cp = sns.color_palette(\"blend:mistyrose,crimson\",n_colors=4)\n",
    "reg_lgd = [plt.Line2D([], [], marker='.', color=hcp_cp[0], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=hcp_cp[1], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=hcp_cp[2], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=hcp_cp[3], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=abcd_cp[0], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=abcd_cp[1], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=abcd_cp[2], linestyle='None'),\n",
    "          plt.Line2D([], [], marker='.', color=abcd_cp[3], linestyle='None')]\n",
    "\n",
    "\n",
    "n_c = 0\n",
    "for reg in regs:\n",
    "    for metric in metrics:\n",
    "        # read output files\n",
    "        HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data(\n",
    "            'HCP','predacc', rep_dir,reg=reg,metric=metric)\n",
    "\n",
    "        # HCP scan parameters\n",
    "        cog = np.flip(np.flip(HCP_res['acc_landscape'][:,:,59].T),1)\n",
    "        limit = 15\n",
    "        cog = cog[:,:limit]\n",
    "        curr_scan = scan_duration[:,:limit]\n",
    "\n",
    "        # fit curve\n",
    "        z,k = orsp.lst_sq_log(curr_scan.flatten(), cog.flatten())\n",
    "        norm_acc = (cog - k) / z \n",
    "        sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=hcp_cp[n_c])\n",
    "        \n",
    "        #################################################\n",
    "\n",
    "        # read output files\n",
    "        ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data(\n",
    "            'ABCD', 'predacc', rep_dir,reg=reg,metric=metric)\n",
    "\n",
    "        # ABCD scan parameters\n",
    "        cog = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,36].T),1)\n",
    "        curr_scan = scan_duration\n",
    "        # fit curve\n",
    "        z,k = orsp.lst_sq_log(curr_scan.flatten(), cog.flatten())\n",
    "        norm_acc = (cog - k) / z \n",
    "        sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=abcd_cp[n_c])\n",
    "        n_c += 1\n",
    "\n",
    "labels = ['HCP: LRR (COD)', 'HCP: LRR (r)', 'HCP: KRR (COD)', 'HCP: KRR (r)', \n",
    "         'ABCD: LRR (COD)', 'ABCD: LRR (r)', 'ABCD: KRR (COD)', 'ABCD: KRR (r)' ]\n",
    "lgd = plt.legend(reg_lgd, labels, markerscale=2, loc='lower right', \n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "\n",
    "# plot log curve\n",
    "X_fit = np.linspace(350, 38000, num=100, dtype=int)\n",
    "curve_val = np.log(X_fit) / np.log(2)\n",
    "plt.plot(np.log(X_fit)/ np.log(2), curve_val, color='k')\n",
    "\n",
    "# set custom limits\n",
    "ax.set_ylim([6.5, 16.5])\n",
    "orsp.format_scatter_plot('log\\N{SUBSCRIPT TWO}(Total Scan Duration)',\n",
    "                    'Norm. prediction performance', ax)\n",
    "fig.savefig(os.path.join(img_dir, 'FigS9_ScanTime_AllReg_AllMetric_Log.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2bb8b6",
   "metadata": {},
   "source": [
    "# Fig S10: Log plot (All scores, 30m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot individual scores\n",
    "#################################################\n",
    "fig,ax = plt.subplots(figsize=(8.5, 3.5))\n",
    "all_scores = []\n",
    "legend_handle = []\n",
    "lgd_handles = []\n",
    "HCP_cog_ind = [1,2,3,4,5,6,8,10,25,26,29,59]\n",
    "HCP_emo_ind = [23]\n",
    "HCP_pers_ind = [7,31,32,34]\n",
    "HCP_phy_ind = [14]\n",
    "HCP_wb_ind = [47]\n",
    "ABCD_cog_ind = [8,10,11,13,14,15,16,17,30,31,32,33,36]\n",
    "ABCD_mh_ind = [5,29,6,3]\n",
    "    \n",
    "### cognition\n",
    "## ABCD\n",
    "limit = 10\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "for n in ABCD_cog_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(),color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_cog_ind[:-1]], ['ABCD Cog. Factor']))\n",
    "\n",
    "## HCP\n",
    "limit = 15\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "for n in HCP_cog_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_cog_ind[:-1]], ['HCP Cog. Factor']))\n",
    "\n",
    "### mental health\n",
    "limit = 10\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:lightgrey,darkgrey\", n_colors=4)\n",
    "for n in ABCD_mh_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(),color=custom_colors[n_c], zorder=-1)\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_mh_ind]))\n",
    "\n",
    "### personality\n",
    "## HCP\n",
    "limit = 15\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:powderblue,darkslateblue\", n_colors=4)\n",
    "for n in HCP_pers_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_pers_ind]))\n",
    "\n",
    "\n",
    "### physical\n",
    "limit = 15\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:gold,gold\", n_colors=2)\n",
    "for n in HCP_phy_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_phy_ind]))\n",
    "\n",
    "### emotion\n",
    "## HCP\n",
    "limit = 15\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:forestgreen,forestgreen\", n_colors=2)\n",
    "for n in HCP_emo_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_emo_ind]))\n",
    "\n",
    "### well being\n",
    "limit = 10\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:magenta,magenta\", n_colors=2)\n",
    "for n in HCP_wb_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_wb_ind]))\n",
    "\n",
    "# plot fitted curve\n",
    "orsp.plot_curve(200, 38000)\n",
    "\n",
    "# figure parameters\n",
    "ax.set_ylim([7, 16])\n",
    "orsp.format_scatter_plot('Total scan duration (# training participants x scan time per participant)',\n",
    "                    'Norm. prediction performance', ax)\n",
    "fig.savefig(os.path.join(img_dir, 'FigS10_ScanTime_AllBehavCurves_30m.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c3d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot individual scores\n",
    "#################################################\n",
    "fig,ax = plt.subplots(figsize=(8.5, 2.5))\n",
    "all_scores = []\n",
    "legend_handle = []\n",
    "lgd_handles = []\n",
    "HCP_cog_ind = [1,2,3,4,5,6,8,10,25,26,29,59]\n",
    "HCP_emo_ind = [23]\n",
    "HCP_pers_ind = [7,31,32,34]\n",
    "HCP_phy_ind = [14]\n",
    "HCP_wb_ind = [47]\n",
    "ABCD_cog_ind = [8,10,11,13,14,15,16,17,30,31,32,33,36]\n",
    "ABCD_mh_ind = [5,29,6,3]\n",
    "    \n",
    "### cognition\n",
    "## ABCD\n",
    "limit = 10\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "for n in ABCD_cog_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(),color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_cog_ind[:-1]], ['Cog Factor (A)']))\n",
    "\n",
    "## HCP\n",
    "limit = 15\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "for n in HCP_cog_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_cog_ind[:-1]], ['Cog Factor (H)']))\n",
    "\n",
    "### mental health\n",
    "limit = 10\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:lightgrey,darkgrey\", n_colors=4)\n",
    "for n in ABCD_mh_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(),color=custom_colors[n_c], zorder=-1)\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_mh_ind]))\n",
    "\n",
    "### personality\n",
    "## HCP\n",
    "limit = 15\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:powderblue,darkslateblue\", n_colors=4)\n",
    "for n in HCP_pers_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_pers_ind]))\n",
    "\n",
    "\n",
    "### physical\n",
    "limit = 15\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:gold,gold\", n_colors=2)\n",
    "for n in HCP_phy_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_phy_ind]))\n",
    "\n",
    "### emotion\n",
    "## HCP\n",
    "limit = 15\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:forestgreen,forestgreen\", n_colors=2)\n",
    "for n in HCP_emo_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_emo_ind]))\n",
    "\n",
    "### well being\n",
    "limit = 15\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:magenta,magenta\", n_colors=2)\n",
    "for n in HCP_wb_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_wb_ind]))\n",
    "\n",
    "## Add legend\n",
    "# Add the custom legend handle to the legend\n",
    "lgd = plt.legend(all_scores, handletextpad=0.01, bbox_to_anchor=[1.06, -0.27],\n",
    "           fontsize=9, ncol=6, columnspacing=0.5, frameon=False)\n",
    "\n",
    "# plot log curve\n",
    "X_fit = np.linspace(350, 38000, num=100, dtype=int)\n",
    "curve_val = np.log(X_fit) / np.log(2)\n",
    "plt.plot(np.log(X_fit)/ np.log(2), curve_val, color='k')\n",
    "\n",
    "# figure parameters\n",
    "ax.set_ylim([6, 16])\n",
    "ax.set_xlim([8, 15.5])\n",
    "orsp.format_scatter_plot('log\\N{SUBSCRIPT TWO}(Total Scan Duration)',\n",
    "                    'Norm. prediction performance', ax)\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS10_ScanTime_Log_AllBehavCurves_30m.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea913b",
   "metadata": {},
   "source": [
    "# Fig S11: ABCD/HCP - N and T are not equivalent (all phenotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a135108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Violin plot comparing same total scan time\n",
    "#################################################\n",
    "# ABCD: 4000 total scan time but different N and T\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir)\n",
    "mat = os.path.join(ABCD_img_dir,'acc_KRR_indiv_corr_landscape.mat')\n",
    "res = scipy.io.loadmat(mat)\n",
    "\n",
    "# extract points with 4000m of total scan time\n",
    "full_df = pd.DataFrame()\n",
    "fourm_vals = []\n",
    "tenm_vals = []\n",
    "twenm_vals = []\n",
    "for b in np.append(ABCD_log_ind,36):\n",
    "    behav = np.mean(res['acc_landscape'][:,:,:,b],2)\n",
    "    dfour = pd.DataFrame(data={'acc': [behav[4,1]]})\n",
    "    dfour['Time'] = '4'\n",
    "    dfour['Subs'] = '1000subs'\n",
    "    fourm_vals.append(behav[4,1])\n",
    "    dten = pd.DataFrame(data={'acc': [behav[1,4]]})\n",
    "    dten['Time'] = '10'\n",
    "    dten['Subs'] = '400subs'\n",
    "    tenm_vals.append(behav[1,4])\n",
    "    dtwen = pd.DataFrame(data={'acc': [behav[0,8]]})\n",
    "    dtwen['Time'] = '20'\n",
    "    dtwen['Subs'] = '200subs'\n",
    "    twenm_vals.append(behav[0,8])\n",
    "    full_df = pd.concat([full_df, dfour, dten, dtwen])\n",
    "\n",
    "# plot violin plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "vp = sns.violinplot(data=full_df, x=\"Time\", y=\"acc\", palette=\"Reds_r\",orient='v')\n",
    "orsp.format_scatter_plot('', 'Prediction accuracy (r)', ax)\n",
    "ax.set_title('ABCD')\n",
    "vp.set(xticklabels=[])\n",
    "ax.set_ylim([-0.15,0.8])\n",
    "fig.savefig(os.path.join(img_dir,'FigS11_ABCD_not1to1_violin.svg'), bbox_inches='tight')\n",
    "\n",
    "# mean accuracy\n",
    "print('4m mean:', np.mean(fourm_vals))\n",
    "print('10m mean:', np.mean(tenm_vals))\n",
    "print('20m mean:', np.mean(twenm_vals))\n",
    "\n",
    "# stats\n",
    "print('4m vs 10m:', scipy.stats.ttest_rel(fourm_vals, tenm_vals))\n",
    "print('10m vs 20m:', scipy.stats.ttest_rel(tenm_vals, twenm_vals))\n",
    "\n",
    "print('4m vs 10m:', orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, tenm_vals)], 3/7, 0))\n",
    "print('10m vs 20m:', orsp.corrected_resample_ttest([a - b for a, b in zip(tenm_vals, twenm_vals)], 3/7, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, tenm_vals)], 3/7, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(tenm_vals, twenm_vals)], 3/7, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ecbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Violin plot comparing same total scan time\n",
    "#################################################\n",
    "# HCP: 6000 total scan time but different N and T\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "mat = os.path.join(HCP_img_dir,'acc_KRR_avg_indiv_corr_landscape.mat')\n",
    "res = scipy.io.loadmat(mat)\n",
    "\n",
    "# extract points with 6000m of total scan time\n",
    "full_df = pd.DataFrame()\n",
    "tenm_vals = []\n",
    "twenm_vals = []\n",
    "thirm_vals = []\n",
    "fourm_vals = []\n",
    "fiftm_vals = []\n",
    "sixtm_vals = []\n",
    "for b in np.append(HCP_log_ind,59):\n",
    "    behav = np.mean(res['acc_landscape'][:,:,:,b],2)\n",
    "    dten = pd.DataFrame(data={'acc': [behav[4,1]]})\n",
    "    dten['Time'] = '10'\n",
    "    dten['Subs'] = '600subs'\n",
    "    tenm_vals.append(behav[4,1])\n",
    "    dtwen = pd.DataFrame(data={'acc': [behav[9,4]]})\n",
    "    dtwen['Time'] = '20'\n",
    "    dtwen['Subs'] = '300subs'\n",
    "    twenm_vals.append(behav[9,4])\n",
    "    dthir = pd.DataFrame(data={'acc': [behav[14,5]]})\n",
    "    dthir['Time'] = '30'\n",
    "    dthir['Subs'] = '200subs'\n",
    "    thirm_vals.append(behav[14,5])\n",
    "    dfour = pd.DataFrame(data={'acc': [behav[19,6]]})\n",
    "    dfour['Time'] = '40'\n",
    "    dfour['Subs'] = '150subs'\n",
    "    fourm_vals.append(behav[19,6])\n",
    "    dfift = pd.DataFrame(data={'acc': [behav[24,7]]})\n",
    "    dfift['Time'] = '50'\n",
    "    dfift['Subs'] = '120subs'\n",
    "    fiftm_vals.append(behav[24,7])\n",
    "    dsixt = pd.DataFrame(data={'acc': [behav[28,8]]})\n",
    "    dsixt['Time'] = '~60'\n",
    "    dsixt['Subs'] = '100subs'\n",
    "    sixtm_vals.append(behav[28,8])\n",
    "    full_df = pd.concat([full_df, dten, dtwen, dthir, dfour, dfift, dsixt])\n",
    "\n",
    "# plot violin plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "vp=sns.violinplot(data=full_df, x=\"Time\", y=\"acc\", palette=\"Blues_r\",orient='v')\n",
    "orsp.format_scatter_plot('', 'Prediction accuracy (r)', ax)\n",
    "ax.set_title('HCP')\n",
    "vp.set(xticklabels=[])\n",
    "ax.set_ylim([-0.15,0.7])\n",
    "fig.savefig(os.path.join(img_dir,'FigS11_HCP_not1to1_violin.svg'), bbox_inches='tight')\n",
    "\n",
    "# mean accuracy\n",
    "print('10m mean:', np.mean(tenm_vals))\n",
    "print('20m mean:', np.mean(twenm_vals))\n",
    "print('30m mean:', np.mean(thirm_vals))\n",
    "print('40m mean:', np.mean(fourm_vals))\n",
    "print('50m mean:', np.mean(fiftm_vals))\n",
    "print('60m mean:', np.mean(sixtm_vals))\n",
    "\n",
    "# stats) \n",
    "print('10m vs 20m:', orsp.corrected_resample_ttest([a - b for a, b in zip(tenm_vals, twenm_vals)], 1/9, 0))\n",
    "print('20m vs 30m:', orsp.corrected_resample_ttest([a - b for a, b in zip(twenm_vals, thirm_vals)], 1/9, 0))\n",
    "print('30m vs 40m:', orsp.corrected_resample_ttest([a - b for a, b in zip(thirm_vals, fourm_vals)], 1/9, 0))\n",
    "print('40m vs 50m:', orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, fiftm_vals)], 1/9, 0))\n",
    "print('50m vs 58m:', orsp.corrected_resample_ttest([a - b for a, b in zip(fiftm_vals, sixtm_vals)], 1/9, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(tenm_vals, twenm_vals)], 1/9, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(twenm_vals, thirm_vals)], 1/9, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(thirm_vals, fourm_vals)], 1/9, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, fiftm_vals)], 1/9, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(fiftm_vals, sixtm_vals)], 1/9, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c267a75",
   "metadata": {},
   "source": [
    "# Fig S12: Theoretical fit for ABCD scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = ABCD_rs_log_ind\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(9,behav,scan_duration,ABCD_subcolors,10,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(ABCD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "             ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                        'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    X_fit = np.linspace(2, 20, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=ABCD_theor_subcolors[sub_lvl])\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS12.' + str(plot_num) +\n",
    "                '_ABCD_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS12.' + str(plot_num) +\n",
    "                '_ABCD_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145f4b3",
   "metadata": {},
   "source": [
    "# Fig S13: Theoretical fit for HCP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir,)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = HCP_rs_log_ind\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,29,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(HCP_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "             ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                        'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    X_fit = np.linspace(2, 58, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=HCP_theor_subcolors[sub_lvl])\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS13.' + str(plot_num) +\n",
    "                '_HCP_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS13.' + str(plot_num) +\n",
    "                '_HCP_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150223a",
   "metadata": {},
   "source": [
    "# Fig S14: HCP log model vs theoretical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b4f77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'predacc', rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir)\n",
    "\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = [59,8,47]\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "\n",
    "plot_y = 0\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,b].T),1)\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    zk = zk_all[b,-1,:]\n",
    "    \n",
    "    # scatter plot with log equation fit\n",
    "    plot_x = 0\n",
    "    curr_ax = axs[plot_y][plot_x]\n",
    "    orsp.plot_scatter(len(Y),behav,scan_duration,HCP_subcolors,len(X),curr_ax)\n",
    "    # 58 min log model fit to full equation\n",
    "    X_fit = np.linspace(2, 60, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        log_val = zk[0] * np.log(Y[sub_lvl]*X_fit)/np.log(2) + zk[1]\n",
    "        curr_ax.plot(Y[sub_lvl]*X_fit, log_val, color='k')\n",
    "    curr_ax.legend(HCP_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,loc='lower right',\n",
    "                     handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                        'Prediction accuracy (r)', curr_ax)\n",
    "\n",
    "    curr_ax.set_xlim(0,40000)\n",
    "    curr_ax.set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    curr_ax.set_title(scores_names[b] + ' (Log)', fontname='Arial')\n",
    "    \n",
    "    # scatter plot with theoretical equation fit\n",
    "    plot_x = 1\n",
    "    curr_ax = axs[plot_y][plot_x]\n",
    "    orsp.plot_scatter(len(Y),behav,scan_duration,HCP_subcolors,len(X),curr_ax)\n",
    "    # Tom's equation fit to full duration\n",
    "    X_fit = np.linspace(2, 60, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        theor_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        curr_ax.plot(Y[sub_lvl]*X_fit, theor_val, color=HCP_theor_subcolors[sub_lvl])\n",
    "    curr_ax.legend(HCP_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,loc='lower right',\n",
    "                     handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                    'Prediction accuracy (r)', curr_ax)\n",
    "    curr_ax.set_xlim(0,40000)\n",
    "    curr_ax.set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    curr_ax.set_title(scores_names[b] + ' (Theoretical)', fontname='Arial')\n",
    "        \n",
    "    # move to next plot\n",
    "    plot_y += 1\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS14.HCP_LogVSTheor.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e5ebe",
   "metadata": {},
   "source": [
    "# Fig S15: ABCD scores after randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a946c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir, vers='random')\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir, vers='random')\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = ABCD_rs_log_ind\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(9,behav,scan_duration,ABCD_subcolors,10,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(ABCD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "             ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                        'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    \n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    X_fit = np.linspace(2, 20, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=ABCD_subcolors[sub_lvl])\n",
    "        \n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS15.' + str(plot_num) +\n",
    "                '_ABCD_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS15.' + str(plot_num) +\n",
    "                '_ABCD_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b60e15",
   "metadata": {},
   "source": [
    "# Fig S16: HCP scores after randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a73215",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir, vers='random')\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','predacc',rep_dir,vers='random')\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = HCP_rs_log_ind\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,29,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(HCP_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "             ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                        'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    X_fit = np.linspace(2, 58, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=HCP_subcolors[sub_lvl])\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS16.' + str(plot_num) +\n",
    "                '_HCP_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS16.' + str(plot_num) +\n",
    "                '_HCP_KRR_full_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce41fa",
   "metadata": {},
   "source": [
    "# Fig S17: SINGER scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c1684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load SINGER data\n",
    "SINGER_img_dir,SINGER_res,X,Y,SINGER_extent,scan_duration = orsp.load_data('SINGER','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('SINGER','predacc',rep_dir)\n",
    "\n",
    "# count how many scores r > 0.1\n",
    "behav_ind = range(0,19)\n",
    "abv01 = 0\n",
    "avg_acc = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(SINGER_res['acc_landscape'][:,:,b].T),1)\n",
    "    if behav[-1,-1] > 0.1:\n",
    "        avg_acc.append(behav[-1,-1])\n",
    "        abv01 += 1\n",
    "print(\"r > 0.1 = \", str(abv01))\n",
    "print(np.mean(avg_acc))\n",
    "\n",
    "# initialize scores\n",
    "behav_ind = SINGER_log_ind\n",
    "scores_names = SINGER_scores\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "meanCOD = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(SINGER_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(6,behav,scan_duration,SINGER_subcolors,9,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(SINGER_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "            ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)', \\\n",
    "            'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    \n",
    "\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    meanCOD.append(loss_pa_all[b,-1])\n",
    "    print(behav[-1,-1] > 0.1, '-', loss_pa_all[b,-1])\n",
    "    X_fit = np.linspace(2, 10, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=SINGER_theor_subcolors[sub_lvl])\n",
    "    # additional settings\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS17.' + str(plot_num) +\n",
    "                '_SINGER_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS17.' + str(plot_num) +\n",
    "                '_SINGER_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n",
    "print(\"Mean COD = \", str(np.mean(meanCOD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f3258",
   "metadata": {},
   "source": [
    "# Fig S18: TCP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8579b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load TCP data\n",
    "TCP_img_dir,TCP_res,X,Y,TCP_extent,scan_duration = orsp.load_data('TCP','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('TCP','predacc',rep_dir)\n",
    "\n",
    "# count how many scores r > 0.1\n",
    "behav_ind = range(0,19)\n",
    "abv01 = 0\n",
    "avg_acc = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(TCP_res['acc_landscape'][:,:,b].T),1)\n",
    "    if behav[-1,-1] > 0.1:\n",
    "        avg_acc.append(behav[-1,-1])\n",
    "        abv01 += 1\n",
    "print(\"r > 0.1 = \", str(abv01))\n",
    "print(np.mean(avg_acc))\n",
    "\n",
    "# initialize scores\n",
    "behav_ind = TCP_log_ind\n",
    "scores_names = TCP_scores\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "meanCOD = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(TCP_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(6,behav,scan_duration,TCP_subcolors,13,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(TCP_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "            ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)', \\\n",
    "            'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    \n",
    "\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    meanCOD.append(loss_pa_all[b,-1])\n",
    "    print(behav[-1,-1] > 0.1, '-', loss_pa_all[b,-1])\n",
    "    X_fit = np.linspace(2, 26, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=TCP_theor_subcolors[sub_lvl])\n",
    "\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS18.' + str(plot_num) +\n",
    "                '_TCP_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS18.' + str(plot_num) +\n",
    "                '_TCP_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n",
    "print(\"Mean COD = \", str(np.mean(meanCOD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e0483",
   "metadata": {},
   "source": [
    "# Fig S19: MDD scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4138b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load MDD data\n",
    "MDD_img_dir,MDD_res,X,Y,MDD_extent,scan_duration = orsp.load_data('MDD','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('MDD','predacc',rep_dir)\n",
    "\n",
    "\n",
    "# count how many scores r > 0.1\n",
    "behav_ind = range(0,20)\n",
    "abv01 = 0\n",
    "avg_acc = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(MDD_res['acc_landscape'][:,:,b].T),1)\n",
    "    if behav[-1,-1] > 0.1:\n",
    "        avg_acc.append(behav[-1,-1])\n",
    "        abv01 += 1\n",
    "print(\"r > 0.1 = \", str(abv01))\n",
    "print(np.mean(avg_acc))\n",
    "\n",
    "# initialize scores\n",
    "behav_ind = MDD_log_ind\n",
    "scores_names = MDD_scores\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "meanCOD = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(MDD_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(10,behav,scan_duration,MDD_subcolors,11,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(MDD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "            ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)', \\\n",
    "            'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    \n",
    "\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    meanCOD.append(loss_pa_all[b,-1])\n",
    "    print(behav[-1,-1] > 0.1, '-', loss_pa_all[b,-1])\n",
    "    X_fit = np.linspace(3, 23, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=MDD_theor_subcolors[sub_lvl])\n",
    "\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS19.' + str(plot_num) +\n",
    "                '_MDD_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS19.' + str(plot_num) +\n",
    "                '_MDD_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n",
    "print(\"Mean COD = \", str(np.mean(meanCOD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a25f57",
   "metadata": {},
   "source": [
    "# Fig S20: ADNI scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e17bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load ADNI data\n",
    "ADNI_img_dir,ADNI_res,X,Y,ADNI_extent,scan_duration = orsp.load_data('ADNI','predacc',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ADNI','predacc',rep_dir)\n",
    "\n",
    "\n",
    "# count how many scores r > 0.1\n",
    "behav_ind = range(0,6)\n",
    "abv01 = 0\n",
    "avg_acc = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ADNI_res['acc_landscape'][:,:,b].T),1)\n",
    "    if behav[-1,-1] > 0.1:\n",
    "        avg_acc.append(behav[-1,-1])\n",
    "        abv01 += 1\n",
    "print(\"r > 0.1 = \", str(abv01))\n",
    "print(np.mean(avg_acc))\n",
    "\n",
    "# initialize scores\n",
    "behav_ind = ADNI_log_ind\n",
    "scores_names = ADNI_scores\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "meanCOD = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ADNI_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(5,behav,scan_duration,ADNI_subcolors,8,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(ADNI_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "            ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)', \\\n",
    "            'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    \n",
    "\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    meanCOD.append(loss_pa_all[b,-1])\n",
    "    print(behav[-1,-1] > 0.1, '-', loss_pa_all[b,-1])\n",
    "    X_fit = np.linspace(2, 9, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=ADNI_theor_subcolors[sub_lvl])\n",
    "\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS20.' + str(plot_num) +\n",
    "                '_ADNI_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS20.' + str(plot_num) +\n",
    "                '_ADNI_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n",
    "print(\"Mean COD = \", str(np.mean(meanCOD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9248a194",
   "metadata": {},
   "source": [
    "# Fig S21: ABCD Task MID scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57afd8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "c_vers = 'full_MID'\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir, vers=c_vers)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir, vers=c_vers)\n",
    "\n",
    "# count how many scores r > 0.1\n",
    "behav_ind = np.append(range(0,36), 36)\n",
    "abv01 = 0\n",
    "avg_acc = []\n",
    "abv01_beh = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "    if behav[-1,-1] > 0.1:\n",
    "        abv01_beh.append(b)\n",
    "        avg_acc.append(behav[-1,-1])\n",
    "        abv01 += 1\n",
    "print(\"r > 0.1 = \", str(abv01))\n",
    "print(np.mean(avg_acc))\n",
    "    \n",
    "# initializez scores\n",
    "num_pts = 10\n",
    "behav_ind = ABCD_MID_log_ind\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "meanCOD = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(8,behav,scan_duration,ABCD_subcolors,num_pts,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(ABCD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "             ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                        'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    print(b,loss_pa_all[b,-1])\n",
    "    meanCOD.append(loss_pa_all[b,-1])\n",
    "    X_fit = np.linspace(2, num_pts+1, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=ABCD_theor_subcolors[sub_lvl])\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS21.' + str(plot_num) +\n",
    "                '_ABCD_MID_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS21.' + str(plot_num) +\n",
    "                '_ABCD_MID_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n",
    "        \n",
    "print(\"Mean COD = \", str(np.mean(meanCOD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcca622",
   "metadata": {},
   "source": [
    "# Fig S22: ABCD Task NBACK scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "c_vers = 'full_NBACK'\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir, vers=c_vers)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir, vers=c_vers)\n",
    "\n",
    "# count how many scores r > 0.1\n",
    "behav_ind = np.append(range(0,36), 36)\n",
    "abv01 = 0\n",
    "avg_acc = []\n",
    "abv01_beh = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "    if behav[-1,-1] > 0.1:\n",
    "        abv01_beh.append(b)\n",
    "        avg_acc.append(behav[-1,-1])\n",
    "        abv01 += 1\n",
    "print(\"r > 0.1 = \", str(abv01))\n",
    "print(np.mean(avg_acc))\n",
    "    \n",
    "# initializez scores\n",
    "num_pts = 9\n",
    "behav_ind = ABCD_NBACK_log_ind\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "meanCOD = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(8,behav,scan_duration,ABCD_subcolors,num_pts,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(ABCD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "             ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                        'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    print(b,loss_pa_all[b,-1])\n",
    "    meanCOD.append(loss_pa_all[b,-1])\n",
    "    X_fit = np.linspace(2, num_pts+1, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=ABCD_theor_subcolors[sub_lvl])\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS22.' + str(plot_num) +\n",
    "                '_ABCD_NBACK_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS22.' + str(plot_num) +\n",
    "                '_ABCD_NBACK_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n",
    "        \n",
    "print(\"Mean COD = \", str(np.mean(meanCOD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9445c050",
   "metadata": {},
   "source": [
    "# Fig S23: ABCD Task SST scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8944b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "c_vers = 'full_SST'\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir, vers=c_vers)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','predacc',rep_dir, vers=c_vers)\n",
    "\n",
    "# count how many scores r > 0.1\n",
    "behav_ind = np.append(range(0,36), 36)\n",
    "abv01 = 0\n",
    "avg_acc = []\n",
    "abv01_beh = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "    if behav[-1,-1] > 0.1:\n",
    "        abv01_beh.append(b)\n",
    "        avg_acc.append(behav[-1,-1])\n",
    "        abv01 += 1\n",
    "print(\"r > 0.1 = \", str(abv01))\n",
    "print(np.mean(avg_acc))\n",
    "    \n",
    "# initializez scores\n",
    "num_pts = 11\n",
    "behav_ind = ABCD_SST_log_ind\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "meanCOD = []\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(8,behav,scan_duration,ABCD_subcolors,num_pts,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(ABCD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "             ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# training participants \\nx scan time per participant)',\n",
    "                        'Prediction accuracy (r)', axs[plot_y][plot_x])\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_pa_all[b,-1,:]\n",
    "    print(b,loss_pa_all[b,-1])\n",
    "    meanCOD.append(loss_pa_all[b,-1])\n",
    "    X_fit = np.linspace(2, num_pts+1, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] * np.sqrt(1/(1 + (w[1]/Y[sub_lvl]) + (w[2]/(Y[sub_lvl]*X_fit)))) \n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=ABCD_theor_subcolors[sub_lvl])\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS23.' + str(plot_num) +\n",
    "                '_ABCD_SST_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS23.' + str(plot_num) +\n",
    "                '_ABCD_SST_KRR_acc_corr_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n",
    "        \n",
    "print(\"Mean COD = \", str(np.mean(meanCOD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c992c774",
   "metadata": {},
   "source": [
    "# Fig S24: Overhead cost for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b853f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Optimal accuracy including overhead (all datasets)\n",
    "#################################################    \n",
    "budgets = [10000000, 1000000, 100000]\n",
    "scanner_costs = np.array([500, 1000, 2000]) / 60\n",
    "recruitment_costs = [500, 1000, 2000, 5000]\n",
    "max_T = 200\n",
    "theoretical_X = np.linspace(1, max_T, num=1000)\n",
    "perc = 1\n",
    "y_bottom_lim = [0.65, 0.25, 0.05]\n",
    "\n",
    "### Iterate over plots\n",
    "for recruitment_cost in recruitment_costs:\n",
    "    curr_y = 0\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    for budget in budgets:\n",
    "        curr_x = 0\n",
    "        for scanner_cost in scanner_costs:\n",
    "            ax = plt.subplot(gspec[curr_y,curr_x])\n",
    "\n",
    "            ## ABCD\n",
    "            c = 'red'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rs_log_ind,'ABCD', rep_dir,'full',rd=None)\n",
    "            l1,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rs_log_ind,'ABCD',rep_dir,'full',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "\n",
    "            ## HCP\n",
    "            c = 'blue'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_rs_log_ind,'HCP',rep_dir,'full',rd=None)\n",
    "            l2,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_rs_log_ind,'HCP',rep_dir,'full',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # SINGER\n",
    "            c = 'purple'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,SINGER_log_ind,'SINGER',rep_dir,'full',rd=None)\n",
    "            l3,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,SINGER_log_ind,'SINGER',rep_dir,'full',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # TCP\n",
    "            c = 'goldenrod'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget, scanner_cost, recruitment_cost,\n",
    "                                       theoretical_X,TCP_log_ind,'TCP',rep_dir,'full',rd=None)\n",
    "            l4,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget, scanner_cost, recruitment_cost,\n",
    "                                       theoretical_X,TCP_log_ind,'TCP',rep_dir,'full',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # MDD\n",
    "            c = 'orange'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget, scanner_cost, recruitment_cost,\n",
    "                                       theoretical_X,MDD_log_ind,'MDD',rep_dir,'full',rd=None)\n",
    "            l5,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget, scanner_cost, recruitment_cost,\n",
    "                                       theoretical_X,MDD_log_ind,'MDD',rep_dir,'full',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # ADNI\n",
    "            c = 'green'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget, scanner_cost, recruitment_cost,\n",
    "                                       theoretical_X,ADNI_log_ind,'ADNI',rep_dir,'full',rd=None)\n",
    "            l6,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget, scanner_cost, recruitment_cost,\n",
    "                                       theoretical_X,ADNI_log_ind,'ADNI',rep_dir,'full',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # format plot\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_xlabel('')\n",
    "            ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "            ax.set_ylim([y_bottom_lim[curr_y],1.03])\n",
    "            ax.set_xlim([-3,max_T])\n",
    "            ax.spines[['right', 'top']].set_visible(False)\n",
    "            # move to next plot\n",
    "            curr_x += 1\n",
    "        # move to next plot\n",
    "        curr_y += 1\n",
    "\n",
    "    # set legend\n",
    "    # Create new legend handles with alpha=1 (no transparency)\n",
    "    legend_handles = [plt.Line2D([0], [0], color='red', alpha=1, label='ABCD'),\n",
    "                      plt.Line2D([0], [0], color='blue', alpha=1, label='HCP'),\n",
    "                      plt.Line2D([0], [0], color='purple', alpha=1, label='SINGER'),\n",
    "                      plt.Line2D([0], [0], color='goldenrod', alpha=1, label='TCP'),\n",
    "                      plt.Line2D([0], [0], color='orange', alpha=1, label='MDD'),\n",
    "                      plt.Line2D([0], [0], color='green', alpha=1, label='ADNI')]\n",
    "    plt.legend(handles=legend_handles, loc='lower right',\n",
    "               title=\"Dataset\", title_fontproperties={'family': 'Arial', 'weight': 'bold', 'size': 11},\n",
    "               frameon=False, bbox_to_anchor=[1.00, -0.9], ncol=6)\n",
    "    fig.savefig(os.path.join(img_dir, 'FigS24_ALLdatasets_OptimalAcc'+str(recruitment_cost)+'.svg'), bbox_inches='tight')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b2bff",
   "metadata": {},
   "source": [
    "# Fig S25: Overhead cost for different phenotypic domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_domainAcc(N,T):\n",
    "    # create empty lists\n",
    "    cog_vals = []\n",
    "    phy_vals = []\n",
    "    emo_vals = []\n",
    "    pers_vals = []\n",
    "    wb_vals = []\n",
    "    mh_vals = []\n",
    "    pet_vals = []\n",
    "    training_N = np.floor(0.9 * N)\n",
    "    abcd_all_mh = []\n",
    "    abcd_all_cog = []\n",
    "    abcd_all_pers = []\n",
    "    nonabcd_mh = []\n",
    "    nonabcd_cog = []\n",
    "    nonabcd_pers = []\n",
    "    \n",
    "    \n",
    "    # categories\n",
    "    # ABCD\n",
    "    abcd_mh = [0,1,2,3,4,5,6,7,27,28,29]\n",
    "    abcd_cog = [8,9,10,11,12,13,14,15,16,17,30,31,32,33,34,35,36]\n",
    "    abcd_pers=[18,19,20,21,22,23,24,25,26]\n",
    "    # HCP\n",
    "    hcp_cog = [0,1,2,3,4,5,6,8,9,10,11,12,13,24,25,26,27,28,29,59]\n",
    "    hcp_pers = [7,30,31,32,33,34]\n",
    "    hcp_phy = [14,15,16,17,18,19,20,21,22]\n",
    "    hcp_emo = [23,35,36,37,38,39,40,41,42,43,44,45,46]\n",
    "    hcp_wb = [47,48,49,50,51,52,53,54,55,56,57]\n",
    "    # SINGER\n",
    "    singer_phy = [0,3,4,5]\n",
    "    singer_cog = [1,2,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "    # TCP\n",
    "    tcp_phy = [0,18]\n",
    "    tcp_mh = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "    # MDD\n",
    "    mdd_phy = [0,18]\n",
    "    mdd_mh = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,19]\n",
    "    # ADNI\n",
    "    adni_phy = [0,1]\n",
    "    adni_cog = [3,4]\n",
    "    adni_pet = [5,6]\n",
    "    \n",
    "    # load HCP results\n",
    "    HCP_behav_ind = HCP_rs_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'predacc', rep_dir)\n",
    "    for b in HCP_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T)))) \n",
    "        if b in hcp_cog:\n",
    "            cog_vals.append(b_acc)\n",
    "            nonabcd_cog.append(b)\n",
    "        if b in hcp_pers:\n",
    "            pers_vals.append(b_acc)\n",
    "            nonabcd_pers.append(b)\n",
    "        if b in hcp_phy:\n",
    "            phy_vals.append(b_acc)\n",
    "        if b in hcp_emo:\n",
    "            emo_vals.append(b_acc)\n",
    "        if b in hcp_wb:\n",
    "            wb_vals.append(b_acc)\n",
    "\n",
    "    # load ABCD results\n",
    "    ABCD_behav_ind = ABCD_rs_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir)\n",
    "    for b in ABCD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        if b in abcd_cog:\n",
    "            cog_vals.append(b_acc)\n",
    "            abcd_all_cog.append(b)\n",
    "        if b in abcd_pers:\n",
    "            pers_vals.append(b_acc)\n",
    "            abcd_all_pers.append(b)\n",
    "        if b in abcd_mh:\n",
    "            mh_vals.append(b_acc)\n",
    "            abcd_all_mh.append(b)\n",
    "    \n",
    "    # load SINGER results\n",
    "    SINGER_behav_ind = SINGER_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('SINGER', 'predacc', rep_dir)\n",
    "    for b in SINGER_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        if b in singer_cog:\n",
    "            cog_vals.append(b_acc)\n",
    "            nonabcd_cog.append(b)\n",
    "        if b in singer_phy:\n",
    "            phy_vals.append(b_acc)\n",
    "        \n",
    "        \n",
    "    # load TCP results\n",
    "    TCP_behav_ind = TCP_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('TCP', 'predacc', rep_dir)\n",
    "    count = 0\n",
    "    for b in TCP_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        if b in tcp_phy:\n",
    "            phy_vals.append(b_acc)\n",
    "        if b in tcp_mh:\n",
    "            mh_vals.append(b_acc)\n",
    "            nonabcd_mh.append(b)\n",
    "        \n",
    "    # load MDD results\n",
    "    MDD_behav_ind = MDD_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('MDD', 'predacc', rep_dir)\n",
    "    count = 0\n",
    "    for b in MDD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        if b in mdd_phy:\n",
    "            phy_vals.append(b_acc)\n",
    "        if b in mdd_mh:\n",
    "            mh_vals.append(b_acc)\n",
    "            nonabcd_mh.append(b)\n",
    "        \n",
    "    # load ADNI results\n",
    "    ADNI_behav_ind = ADNI_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ADNI', 'predacc', rep_dir)\n",
    "    count = 0 \n",
    "    for b in ADNI_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        if b in adni_phy:\n",
    "            phy_vals.append(b_acc)\n",
    "            count += 1\n",
    "        if b in adni_cog:\n",
    "            cog_vals.append(b_acc)\n",
    "            nonabcd_cog.append(b)\n",
    "        if b in adni_pet:\n",
    "            pet_vals.append(b_acc)\n",
    "        \n",
    "    # load ABCD results\n",
    "    ABCD_behav_ind = ABCD_MID_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='full_MID')\n",
    "    for b in ABCD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        if b in abcd_cog:\n",
    "            cog_vals.append(b_acc)\n",
    "            abcd_all_cog.append(b)\n",
    "        if b in abcd_pers:\n",
    "            pers_vals.append(b_acc)\n",
    "            abcd_all_pers.append(b)\n",
    "        if b in abcd_mh:\n",
    "            mh_vals.append(b_acc)\n",
    "            abcd_all_mh.append(b)\n",
    "        \n",
    "    # load ABCD results\n",
    "    ABCD_behav_ind = ABCD_NBACK_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='full_NBACK')\n",
    "    for b in ABCD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        if b in abcd_cog:\n",
    "            cog_vals.append(b_acc)\n",
    "            abcd_all_cog.append(b)\n",
    "        if b in abcd_pers:\n",
    "            pers_vals.append(b_acc)\n",
    "            abcd_all_pers.append(b)\n",
    "        if b in abcd_mh:\n",
    "            mh_vals.append(b_acc)\n",
    "            abcd_all_mh.append(b)\n",
    "        \n",
    "    # load ABCD results\n",
    "    ABCD_behav_ind = ABCD_SST_log_ind\n",
    "    w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'predacc', rep_dir, vers='full_SST')\n",
    "    for b in ABCD_behav_ind:\n",
    "        # Tom's equation fit to full duration\n",
    "        w = w_pa_all[b,-1,:]\n",
    "        b_acc = np.sqrt(1/(1 + (w[1]/training_N) + (w[2]/(training_N*T))))\n",
    "        if b in abcd_cog:\n",
    "            cog_vals.append(b_acc)\n",
    "            abcd_all_cog.append(b)\n",
    "        if b in abcd_pers:\n",
    "            pers_vals.append(b_acc)\n",
    "            abcd_all_pers.append(b)\n",
    "        if b in abcd_mh:\n",
    "            mh_vals.append(b_acc)\n",
    "            abcd_all_mh.append(b)\n",
    "    # Absolute counts        \n",
    "    #print(len(cog_vals),len(phy_vals),len(emo_vals),len(pers_vals),len(wb_vals),len(mh_vals), len(pet_vals))\n",
    "    # Unique counts\n",
    "    #print(\"Cog:\", len(nonabcd_cog)+len(np.unique(abcd_all_cog)),\n",
    "    #      \"Phy:\", len(phy_vals),\n",
    "    #      \"Emo:\", len(emo_vals),\n",
    "    #      \"Pers:\", len(nonabcd_pers)+len(np.unique(abcd_all_pers)),\n",
    "    #      \"WB:\", len(wb_vals),\n",
    "    #      \"Mh:\", len(nonabcd_mh)+len(np.unique(abcd_all_mh)),\n",
    "    #      \"PET:\", len(pet_vals)\n",
    "    #     )\n",
    "    \n",
    "    return np.mean(cog_vals,0), np.mean(phy_vals,0), np.mean(emo_vals,0), np.mean(pers_vals,0), np.mean(wb_vals,0), np.mean(mh_vals,0), np.mean(pet_vals,0)\n",
    "\n",
    "#################################################\n",
    "# Tom's theoretical equations\n",
    "#################################################\n",
    "budgets = [10000000, 1000000, 100000]\n",
    "scanner_costs = np.array([500, 1000, 2000]) / 60\n",
    "recruitment_costs = [500, 1000, 2000, 5000]\n",
    "max_T = 200\n",
    "theoretical_X = np.linspace(1, max_T, num=1000)\n",
    "y_bottom_lim = [0.55, 0.15, 0.05]\n",
    "perc = 1\n",
    "\n",
    "### Iterate over plots\n",
    "for recruitment_cost in recruitment_costs:\n",
    "    curr_y = 0\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    gspec = gridspec.GridSpec(3,3,hspace=0.22,wspace=0.25)\n",
    "    for budget in budgets:\n",
    "        curr_x = 0\n",
    "        for scanner_cost in scanner_costs:\n",
    "\n",
    "            ax = plt.subplot(gspec[curr_y,curr_x])\n",
    "\n",
    "            # cognition\n",
    "            c = 'blue'\n",
    "            # smooth curve\n",
    "            remaining_Y = budget / (theoretical_X*scanner_cost + recruitment_costs[1])\n",
    "            cog_vals,phy_vals,emo_vals,pers_vals,wb_vals,mh_vals,pet_vals = calc_domainAcc(remaining_Y,theoretical_X)\n",
    "            l1,=ax.plot(theoretical_X,cog_vals, color='blue', zorder=0, alpha=0.5)\n",
    "            l2,=ax.plot(theoretical_X,phy_vals, color='green', zorder=0, alpha=0.5)\n",
    "            l3,=ax.plot(theoretical_X,emo_vals, color='red', zorder=0, alpha=0.5)\n",
    "            l4,=ax.plot(theoretical_X,pers_vals, color='orange', zorder=0, alpha=0.5)\n",
    "            l5,=ax.plot(theoretical_X,wb_vals, color='purple', zorder=0, alpha=0.5)\n",
    "            l6,=ax.plot(theoretical_X,mh_vals, color='black', zorder=0, alpha=0.5)\n",
    "            l7,=ax.plot(theoretical_X,pet_vals, color='olive', zorder=0, alpha=0.5)\n",
    "            # limits using rounded down sample size\n",
    "            remaining_Y = np.floor(budget / (theoretical_X*scanner_cost + recruitment_costs[1]))\n",
    "            cog_vals,phy_vals,emo_vals,pers_vals,wb_vals,mh_vals,pet_vals = calc_domainAcc(remaining_Y,theoretical_X)\n",
    "            orsp.plot_max_range(cog_vals,perc,theoretical_X,'blue',ax)\n",
    "            orsp.plot_max_range(phy_vals,perc,theoretical_X,'green',ax)\n",
    "            orsp.plot_max_range(emo_vals,perc,theoretical_X,'red',ax)\n",
    "            orsp.plot_max_range(pers_vals,perc,theoretical_X,'orange',ax)\n",
    "            orsp.plot_max_range(wb_vals,perc,theoretical_X,'purple',ax)\n",
    "            orsp.plot_max_range(mh_vals,perc,theoretical_X,'black',ax)\n",
    "            orsp.plot_max_range(pet_vals,perc,theoretical_X,'olive',ax)\n",
    "\n",
    "\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_xlabel('')\n",
    "            ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "            ax.set_ylim([y_bottom_lim[curr_y],1.03])\n",
    "            ax.set_xlim([-3,max_T])\n",
    "            ax.spines[['right', 'top']].set_visible(False)\n",
    "            # move to next plot\n",
    "            curr_x += 1\n",
    "\n",
    "        # move to next plot\n",
    "        curr_y += 1\n",
    "\n",
    "    legend_handles = [plt.Line2D([0], [0], color='blue', alpha=1, label='Cognition (39)'),\n",
    "                          plt.Line2D([0], [0], color='green', alpha=1, label='Physical (10)'),\n",
    "                          plt.Line2D([0], [0], color='red', alpha=1, label='Emotion (1)'),\n",
    "                          plt.Line2D([0], [0], color='orange', alpha=1, label='Personality (6)'),\n",
    "                          plt.Line2D([0], [0], color='purple', alpha=1, label='Well-Being (1)'),\n",
    "                          plt.Line2D([0], [0], color='black', alpha=1, label='Mental Health (17)'),\n",
    "                          plt.Line2D([0], [0], color='olive', alpha=1, label='PET (2)')]\n",
    "    plt.legend(handles=legend_handles, \n",
    "               title=\"Domain\",title_fontproperties={'family' : 'Arial', 'weight':'bold', 'size': 11},\n",
    "               frameon=False, bbox_to_anchor=[1.05, -0.5], ncol=4)\n",
    "    fig.savefig(os.path.join(img_dir, 'FigS25_ALLdomains_OptimalAcc'+str(recruitment_cost)+'.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77a9f2",
   "metadata": {},
   "source": [
    "# Fig S26: Overhead cost for task vs rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3007f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Optimal accuracy including overhead (ABCD tasks)\n",
    "#################################################\n",
    "budgets = [10000000, 1000000, 100000]\n",
    "scanner_costs = np.array([500, 1000, 2000]) / 60\n",
    "recruitment_costs = [500, 1000, 2000, 5000]\n",
    "max_T = 200\n",
    "theoretical_X = np.linspace(1, max_T, num=1000)\n",
    "perc = 1\n",
    "y_bottom_lim = [0.65, 0.25, 0.1]\n",
    "\n",
    "### Iterate over plots\n",
    "for recruitment_cost in recruitment_costs:\n",
    "    curr_y = 0\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    for budget in budgets:\n",
    "        curr_x = 0\n",
    "        for scanner_cost in scanner_costs:\n",
    "            ax = plt.subplot(gspec[curr_y,curr_x])\n",
    "\n",
    "            ## ABCD only - 400 parcels\n",
    "            c = 'black'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rst_intersect,'ABCD',rep_dir,'full',rd=None)\n",
    "            l1,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rst_intersect,'ABCD',rep_dir,'full',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            ## ABCD only - MID\n",
    "            c='blue'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rst_intersect,'ABCD',rep_dir,'full_MID',rd=None)\n",
    "            l2,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rst_intersect,'ABCD',rep_dir,'full_MID',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            ## ABCD only - nback\n",
    "            c='green'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rst_intersect,'ABCD',rep_dir,'full_NBACK',rd=None)\n",
    "            l3,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rst_intersect,'ABCD',rep_dir,'full_NBACK',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            ## ABCD only - SST\n",
    "            c = 'purple'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rst_intersect,'ABCD',rep_dir,'full_SST',rd=None)\n",
    "            l4,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_rst_intersect,'ABCD',rep_dir,'full_SST',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # format plot\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_xlabel('')\n",
    "            ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "            ax.set_ylim([y_bottom_lim[curr_y],1.03])\n",
    "            ax.set_xlim([-3,max_T])\n",
    "            ax.spines[['right', 'top']].set_visible(False)\n",
    "            # move to next plot\n",
    "            curr_x += 1\n",
    "        # move to next plot\n",
    "        curr_y += 1\n",
    "\n",
    "    # set legend\n",
    "    # Create new legend handles with alpha=1 (no transparency)\n",
    "    legend_handles = [plt.Line2D([0], [0], color='black', alpha=1, label='Rest'),\n",
    "                      plt.Line2D([0], [0], color='blue', alpha=1, label='Task: MID'),\n",
    "                      plt.Line2D([0], [0], color='green', alpha=1, label='Task: NBACK'),\n",
    "                      plt.Line2D([0], [0], color='purple', alpha=1, label='Task: SST')]\n",
    "    plt.legend(handles=legend_handles, loc='lower right',\n",
    "               title=\"Condition\", title_fontproperties={'family': 'Arial', 'weight': 'bold', 'size': 11},\n",
    "               frameon=False, bbox_to_anchor=[0.7, -0.9], ncol=4)\n",
    "    fig.savefig(os.path.join(img_dir, 'FigS26_ABCD_RS_Task_OptimalAcc'+str(recruitment_cost)+'.svg'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474362c9",
   "metadata": {},
   "source": [
    "# Fig S27: Strict set ABCD and HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fd0b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Optimal accuracy for ABCD and HCP (controlling for fit to theoretical model)\n",
    "#################################################\n",
    "budgets = [10000000, 1000000, 100000]\n",
    "scanner_costs = np.array([500, 1000, 2000]) / 60\n",
    "recruitment_costs = [500, 1000, 2000, 5000]\n",
    "max_T = 200\n",
    "theoretical_X = np.linspace(1, max_T, num=1000)\n",
    "perc = 1\n",
    "y_bottom_lim = [0.65, 0.25, 0.1]\n",
    "\n",
    "### Iterate over plots\n",
    "for recruitment_cost in recruitment_costs:\n",
    "    curr_y = 0\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    gspec = gridspec.GridSpec(3,3,hspace=0.22,wspace=0.25)\n",
    "    for budget in budgets:\n",
    "        curr_x = 0\n",
    "        for scanner_cost in scanner_costs:\n",
    "            ax = plt.subplot(gspec[curr_y,curr_x])\n",
    "            \n",
    "            ## original - full set\n",
    "            c = 'black'\n",
    "            # smooth curve\n",
    "            remaining_Y = budget / (theoretical_X*scanner_cost + recruitment_cost)\n",
    "            final_predacc, c_int = orsp.calc_avgHCPABCDAcc(remaining_Y,theoretical_X,'full',\n",
    "                                                      rep_dir,HCP_rs_log_ind,ABCD_rs_log_ind)\n",
    "            l1, = ax.plot(theoretical_X,final_predacc, c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            remaining_Y = np.floor(budget / (theoretical_X*scanner_cost + recruitment_cost))\n",
    "            final_predacc, c_int = orsp.calc_avgHCPABCDAcc(remaining_Y,theoretical_X,'full',\n",
    "                                                      rep_dir,HCP_rs_log_ind,ABCD_rs_log_ind,rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "            \n",
    "            ## original - strict set\n",
    "            c = 'blue'\n",
    "            # smooth curve\n",
    "            remaining_Y = budget / (theoretical_X*scanner_cost + recruitment_cost)\n",
    "            final_predacc, c_int = orsp.calc_avgHCPABCDAcc(remaining_Y,theoretical_X,'full', rep_dir,\n",
    "                                                      HCP_behav_ind_fullstrict,ABCD_behav_ind_fullstrict)\n",
    "            l2, = ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            ax.scatter(theoretical_X[np.argmax(final_predacc)],np.max(final_predacc), color=c, zorder=1, clip_on=True)\n",
    "            # limits using rounded down sample size\n",
    "            remaining_Y = np.floor(budget / (theoretical_X*scanner_cost + recruitment_cost))\n",
    "            final_predacc, c_int = orsp.calc_avgHCPABCDAcc(remaining_Y,theoretical_X,'full', rep_dir,\n",
    "                                                      HCP_behav_ind_fullstrict,ABCD_behav_ind_fullstrict, rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            ## randomized - full set\n",
    "            c = 'red'\n",
    "            # smooth curve\n",
    "            remaining_Y = budget / (theoretical_X*scanner_cost + recruitment_cost)\n",
    "            final_predacc, c_int = orsp.calc_avgHCPABCDAcc(remaining_Y,theoretical_X,'random',\n",
    "                                                      rep_dir,HCP_rs_log_ind,ABCD_rs_log_ind)\n",
    "            l3, = ax.plot(theoretical_X,final_predacc, color=c, zorder=0,alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            remaining_Y = np.floor(budget / (theoretical_X*scanner_cost + recruitment_cost))\n",
    "            final_predacc, c_int = orsp.calc_avgHCPABCDAcc(remaining_Y,theoretical_X,'random',\n",
    "                                                      rep_dir,HCP_rs_log_ind,ABCD_rs_log_ind, rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "   \n",
    "            ## randomized - strict set\n",
    "            c = 'purple'\n",
    "            # smooth curve\n",
    "            remaining_Y = budget / (theoretical_X*scanner_cost + recruitment_cost)\n",
    "            final_predacc, c_int = orsp.calc_avgHCPABCDAcc(remaining_Y,theoretical_X,'random',rep_dir,\n",
    "                                                      HCP_behav_ind_randomstrict,ABCD_behav_ind_randomstrict)\n",
    "            l4, = ax.plot(theoretical_X,final_predacc, color=c, zorder=0,alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            remaining_Y = np.floor(budget / (theoretical_X*scanner_cost + recruitment_cost))\n",
    "            final_predacc, c_int = orsp.calc_avgHCPABCDAcc(remaining_Y,theoretical_X,'random',rep_dir,\n",
    "                                                      HCP_behav_ind_randomstrict,ABCD_behav_ind_randomstrict,rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "            \n",
    "            # format plot\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_xlabel('')\n",
    "            ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "            ax.set_ylim([y_bottom_lim[curr_y],1.03])\n",
    "            ax.set_xlim([-3,max_T])\n",
    "            ax.spines[['right', 'top']].set_visible(False)\n",
    "            # move to next plot\n",
    "            curr_x += 1\n",
    "        # move to next plot\n",
    "        curr_y += 1\n",
    "\n",
    "    # set legend\n",
    "    # Create new legend handles with alpha=1 (no transparency)\n",
    "    legend_handles = [plt.Line2D([0], [0], color='black', alpha=1, label='Original run order (36)'),\n",
    "                      plt.Line2D([0], [0], color='blue', alpha=1, label='Original run order strict (13)'),\n",
    "                      plt.Line2D([0], [0], color='red', alpha=1, label='Randomized run order (36)'),\n",
    "                      plt.Line2D([0], [0], color='purple', alpha=1, label='Randomized run order strict (17)')]\n",
    "    plt.legend(handles=legend_handles, loc='lower right',\n",
    "               title=\"Condition\", title_fontproperties={'family': 'Arial', 'weight': 'bold', 'size': 11},\n",
    "               frameon=False, bbox_to_anchor=[0.83, -0.9], ncol=2)\n",
    "    fig.savefig(os.path.join(img_dir, 'FigS27_ABCDHCP_StrictSet_OptimalAcc'+str(recruitment_cost)+'.svg'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59bc2e",
   "metadata": {},
   "source": [
    "# Fig S28: ABCD control analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b899ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Optimal accuracy including overhead (ABCD control)\n",
    "#################################################\n",
    "\n",
    "budgets = [10000000, 1000000, 100000]\n",
    "scanner_costs = np.array([500, 1000, 2000]) / 60\n",
    "recruitment_costs = [500, 1000, 2000, 5000]\n",
    "max_T = 200\n",
    "theoretical_X = np.linspace(1, max_T, num=1000)\n",
    "perc = 1\n",
    "y_bottom_lim = [0.65, 0.25, 0.1]\n",
    "\n",
    "### Iterate over plots\n",
    "for recruitment_cost in recruitment_costs:\n",
    "    curr_y = 0\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    for budget in budgets:\n",
    "        curr_x = 0\n",
    "        for scanner_cost in scanner_costs:\n",
    "            ax = plt.subplot(gspec[curr_y,curr_x])\n",
    "\n",
    "            # ABCD only - 400 parcels\n",
    "            c = 'black'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_intersect,'ABCD',rep_dir,'full',rd=None)\n",
    "            l1,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_intersect,'ABCD',rep_dir,'full',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # ABCD only - subcortical\n",
    "            c = 'red'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_intersect,'ABCD',rep_dir,'full_sc',rd=None)\n",
    "            l2,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_intersect,'ABCD',rep_dir,'full_sc',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "            \n",
    "            # ABCD only - 1000parcels\n",
    "            c = 'orange'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_intersect,'ABCD',rep_dir,'full_1000parcels',rd=None)\n",
    "            l3,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,ABCD_intersect,'ABCD',rep_dir,'full_1000parcels',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "            # format plot\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_xlabel('')\n",
    "            ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "            ax.set_ylim([y_bottom_lim[curr_y],1.03])\n",
    "            ax.set_xlim([-3,max_T])\n",
    "            ax.spines[['right', 'top']].set_visible(False)\n",
    "            # move to next plot\n",
    "            curr_x += 1\n",
    "        # move to next plot\n",
    "        curr_y += 1\n",
    "\n",
    "    # set legend\n",
    "    # Create new legend handles with alpha=1 (no transparency)\n",
    "    legend_handles = [plt.Line2D([0], [0], color='black', alpha=1, label='400+19 parcels (original)'),\n",
    "                      plt.Line2D([0], [0], color='red', alpha=1, label='19 subcortical parcels'),\n",
    "                      plt.Line2D([0], [0], color='orange', alpha=1, label='1000+19 parcels')]\n",
    "    plt.legend(handles=legend_handles, loc='lower right',\n",
    "               title=\"Condition\", title_fontproperties={'family': 'Arial', 'weight': 'bold', 'size': 11},\n",
    "               frameon=False, bbox_to_anchor=[1.05, -0.9], ncol=4)\n",
    "    fig.savefig(os.path.join(img_dir, 'FigS28_ABCD_Control_OptimalAcc'+str(recruitment_cost)+'.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6611687",
   "metadata": {},
   "source": [
    "# Fig S29: HCP control analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c0fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Optimal accuracy including overhead (HCP control)\n",
    "#################################################\n",
    "\n",
    "budgets = [10000000, 1000000, 100000]\n",
    "scanner_costs = np.array([500, 1000, 2000]) / 60\n",
    "recruitment_costs = [500, 1000, 2000, 5000]\n",
    "max_T = 200\n",
    "theoretical_X = np.linspace(1, max_T, num=1000)\n",
    "perc = 1\n",
    "y_bottom_lim = [0.65, 0.25, 0.1]\n",
    "\n",
    "### Iterate over plots\n",
    "for recruitment_cost in recruitment_costs:\n",
    "    curr_y = 0\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    for budget in budgets:\n",
    "        curr_x = 0\n",
    "        for scanner_cost in scanner_costs:\n",
    "            ax = plt.subplot(gspec[curr_y,curr_x])\n",
    "\n",
    "            # HCP only - 400 parcels\n",
    "            c = 'black'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_intersect,'HCP',rep_dir,'full')\n",
    "            l1,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_intersect,'HCP',rep_dir,'full',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # HCP only - subcortical\n",
    "            c = 'red'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_intersect,'HCP',rep_dir,'full_sc')\n",
    "            l2,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_intersect,'HCP',rep_dir,'full_sc',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "\n",
    "            # HCP only - 1000parcels\n",
    "            c = 'orange'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_intersect,'HCP',rep_dir,'full_1000parcels')\n",
    "            l3,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_intersect,'HCP',rep_dir,'full_1000parcels',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # HCP only - mixdays\n",
    "            c = 'blue'\n",
    "            # smooth curve\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_intersect,'HCP',rep_dir,'full_mixdays')\n",
    "            l3,=ax.plot(theoretical_X,final_predacc, color=c, zorder=0, alpha=0.35)\n",
    "            # limits using rounded down sample size\n",
    "            final_predacc, c_int = orsp.calc_datasetAcc(budget,scanner_cost,recruitment_cost,\n",
    "                                       theoretical_X,HCP_intersect,'HCP',rep_dir,'full_mixdays',rd=1)\n",
    "            orsp.plot_max_range(final_predacc,perc,theoretical_X,c,ax)\n",
    "\n",
    "            # format plot\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_xlabel('')\n",
    "            ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "            ax.set_ylim([y_bottom_lim[curr_y],1.03])\n",
    "            ax.set_xlim([-3,max_T])\n",
    "            ax.spines[['right', 'top']].set_visible(False)\n",
    "            # move to next plot\n",
    "            curr_x += 1\n",
    "        # move to next plot\n",
    "        curr_y += 1\n",
    "\n",
    "    # set legend\n",
    "    # Create new legend handles with alpha=1 (no transparency)\n",
    "    legend_handles = [plt.Line2D([0], [0], color='black', alpha=1, label='400+19 parcels (original)'),\n",
    "                      plt.Line2D([0], [0], color='red', alpha=1, label='19 subcortical parcels'),\n",
    "                      plt.Line2D([0], [0], color='orange', alpha=1, label='1000+19 parcels'),\n",
    "                      plt.Line2D([0], [0], color='blue', alpha=1, label='Two Sessions')]\n",
    "    plt.legend(handles=legend_handles, loc='lower right',\n",
    "               title=\"Condition\", title_fontproperties={'family': 'Arial', 'weight': 'bold', 'size': 11},\n",
    "               frameon=False, bbox_to_anchor=[1.55, -0.9], ncol=4)\n",
    "    fig.savefig(os.path.join(img_dir, 'FigS29_HCP_Control_OptimalAcc'+str(recruitment_cost)+'.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d531e",
   "metadata": {},
   "source": [
    "# Fig S30: BWAS Contour plot for ABCD and HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4432dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot contour plots\n",
    "#################################################\n",
    "fig,axs = plt.subplots(1,2,figsize=(8.5,4.5))\n",
    "fig.tight_layout(pad=7)\n",
    "\n",
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "# Cognition\n",
    "con_lines = [0.2, 0.3, 0.4]\n",
    "manual_locations = [(3,0.5),(6.5,1.5),(25,5)]\n",
    "behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,59].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, HCP_extent, \n",
    "                      fig, axs[1], Yax_lbl='ICC', Ax_Ttl='HCP')\n",
    "\n",
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir)\n",
    "# Cognition\n",
    "con_lines = [0.3, 0.55, 0.7]\n",
    "manual_locations = [(1,0.3),(4,2),(8,6)]\n",
    "behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,36].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, ABCD_extent, \n",
    "                      fig, axs[0], Yax_lbl='ICC', Ax_Ttl='ABCD')\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS30_' +\n",
    "                    'KRR_full_rel_BWAS_cog_contour.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd54b36b",
   "metadata": {},
   "source": [
    "# Fig S31: Correlation between common points in ABCD and HCP contour plots (BWAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1523ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'tstats', rep_dir)\n",
    "behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,59].T),1)\n",
    "hcp_behav = behav[[1,5],:10].ravel()\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'tstats', rep_dir)\n",
    "behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,36].T),1)\n",
    "abcd_behav = behav[:2,:].ravel()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6, 6))\n",
    "plt.scatter(abcd_behav,hcp_behav)\n",
    "res = scipy.stats.linregress(abcd_behav,hcp_behav)\n",
    "xy_line = np.linspace(0.05,0.55,100)\n",
    "plt.plot(xy_line , res.intercept + res.slope*xy_line , 'k', linestyle='--')\n",
    "orsp.format_scatter_plot('ABCD Reliability (ICC)',\n",
    "                    'HCP Reliability (ICC)', ax)\n",
    "corr_val = np.corrcoef(abcd_behav,hcp_behav)\n",
    "ax.text(0.8,0.1,'r = ' + str(np.round(corr_val[0][1],2)), transform=ax.transAxes, size=12)\n",
    "plt.yticks(np.arange(0.1, 0.55, step=0.1)) \n",
    "plt.xticks(np.arange(0.1, 0.55, step=0.1)) \n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS31_ABCD_HCP_KRR_commonpts_tstats_correlation.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87a976",
   "metadata": {},
   "source": [
    "# Fig S32: Scatter plots for reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e54f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot scatter plot against total scan time\n",
    "#################################################\n",
    "limit=5\n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'tstats', rep_dir)\n",
    "behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,59].T),1)\n",
    "# plot scatter plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "#orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,58,ax)\n",
    "#orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,limit,ax,outline='Y')\n",
    "limit = 5\n",
    "for n_subs in range(0,6)[::-1]:\n",
    "    beh = behav[n_subs, :limit]\n",
    "    curr_scan = scan_duration[n_subs, :limit]\n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=beh.flatten(), ax=ax,\n",
    "                            color=HCP_subcolors[n_subs],s=40)\n",
    "for n_subs in range(0,6):\n",
    "    beh = behav[n_subs, limit:]\n",
    "    curr_scan = scan_duration[n_subs, limit:]\n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=beh.flatten(), ax=ax,\n",
    "                            color=HCP_subcolors[n_subs], edgecolor=\"k\", linewidth=0.75, s=30)\n",
    "orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                    'Reliability (ICC)', ax)\n",
    "lgd = plt.legend(HCP_lgd, Y, markerscale=2, \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "fig.savefig(os.path.join(img_dir, 'FigS32_HCP_BWA_icc.svg'), bbox_inches='tight')\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'tstats', rep_dir)\n",
    "behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,36].T),1)\n",
    "# Plot scatter\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "#orsp.plot_scatter(6,behav,scan_duration,ABCD_subcolors,10,ax)\n",
    "#orsp.plot_scatter(6,behav,scan_duration,ABCD_subcolors,limit,ax,outline='Y')\n",
    "limit = 5\n",
    "for n_subs in range(0,6)[::-1]:\n",
    "    beh = behav[n_subs, :limit]\n",
    "    curr_scan = scan_duration[n_subs, :limit]\n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=beh.flatten(), ax=ax,\n",
    "                            color=ABCD_subcolors[n_subs],s=40)\n",
    "for n_subs in range(0,6):\n",
    "    beh = behav[n_subs, limit:]\n",
    "    curr_scan = scan_duration[n_subs, limit:]\n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=beh.flatten(), ax=ax,\n",
    "                            color=ABCD_subcolors[n_subs], edgecolor=\"k\", linewidth=0.75, s=30)\n",
    "orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                    'Reliability (ICC)', ax)\n",
    "lgd = plt.legend(ABCD_lgd, Y, markerscale=2, \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "fig.savefig(os.path.join(img_dir, 'FigS32_ABCD_BWA_icc.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot individual scores\n",
    "#################################################\n",
    "fig,ax = plt.subplots(figsize=(8.5, 3.5))\n",
    "all_scores = []\n",
    "legend_handle = []\n",
    "lgd_handles = []\n",
    "#HCP_cog_ind = [1,2,3,4,5,6,8,10,25,26,29,59]\n",
    "#HCP_emo_ind = [23]\n",
    "#HCP_pers_ind = [7,31,32,34]\n",
    "#HCP_phy_ind = [14]\n",
    "#HCP_wb_ind = [47]\n",
    "#ABCD_cog_ind = [8,10,11,13,14,15,16,17,30,31,32,33,36]\n",
    "#ABCD_mh_ind = [5,29,6,3]\n",
    "    \n",
    "### cognition\n",
    "## ABCD\n",
    "limit = 5\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "for n in ABCD_cog_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(),color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_cog_ind[:-1]], ['ABCD Cog. Factor']))\n",
    "\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "for n in HCP_cog_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_cog_ind[:-1]], ['HCP Cog. Factor']))\n",
    "\n",
    "### mental health\n",
    "limit = 5\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:lightgrey,darkgrey\", n_colors=4)\n",
    "for n in ABCD_mh_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(),color=custom_colors[n_c], zorder=-1)\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_mh_ind]))\n",
    "\n",
    "### personality\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:powderblue,darkslateblue\", n_colors=4)\n",
    "for n in HCP_pers_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_pers_ind]))\n",
    "\n",
    "\n",
    "### physical\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:gold,gold\", n_colors=2)\n",
    "for n in HCP_phy_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_phy_ind]))\n",
    "\n",
    "### emotion\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:forestgreen,forestgreen\", n_colors=2)\n",
    "for n in HCP_emo_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_emo_ind]))\n",
    "\n",
    "### well being\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:magenta,magenta\", n_colors=2)\n",
    "for n in HCP_wb_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_wb_ind]))\n",
    "\n",
    "# plot fitted curve\n",
    "orsp.plot_curve(200, 15000)\n",
    "\n",
    "# figure parameters\n",
    "ax.set_ylim([6, 16])\n",
    "orsp.format_scatter_plot('Total scan duration (# participants x scan time per participant)',\n",
    "                    'Norm. reliability', ax)\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS32_ScanTime_AllBehavCurves_Tstats_10m.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot individual scores\n",
    "#################################################\n",
    "fig,ax = plt.subplots(figsize=(8.5, 2.5))\n",
    "all_scores = []\n",
    "legend_handle = []\n",
    "lgd_handles = []\n",
    "HCP_cog_ind = [1,2,3,4,5,6,8,10,25,26,29,59]\n",
    "HCP_emo_ind = [23]\n",
    "HCP_pers_ind = [7,31,32,34]\n",
    "HCP_phy_ind = [14]\n",
    "HCP_wb_ind = [47]\n",
    "ABCD_cog_ind = [8,10,11,13,14,15,16,17,30,31,32,33,36]\n",
    "ABCD_mh_ind = [5,29,6,3]\n",
    "    \n",
    "### cognition\n",
    "## ABCD\n",
    "limit = 5\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "for n in ABCD_cog_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(),color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_cog_ind[:-1]], ['Cog Factor (A)']))\n",
    "\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "for n in HCP_cog_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_cog_ind[:-1]], ['Cog Factor (H)']))\n",
    "\n",
    "### mental health\n",
    "limit = 5\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:lightgrey,darkgrey\", n_colors=4)\n",
    "for n in ABCD_mh_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(),color=custom_colors[n_c], zorder=-1)\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_mh_ind]))\n",
    "\n",
    "### personality\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:powderblue,darkslateblue\", n_colors=4)\n",
    "for n in HCP_pers_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_pers_ind]))\n",
    "\n",
    "\n",
    "### physical\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:gold,gold\", n_colors=2)\n",
    "for n in HCP_phy_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_phy_ind]))\n",
    "\n",
    "### emotion\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:forestgreen,forestgreen\", n_colors=2)\n",
    "for n in HCP_emo_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_emo_ind]))\n",
    "\n",
    "### well being\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:magenta,magenta\", n_colors=2)\n",
    "for n in HCP_wb_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_wb_ind]))\n",
    "\n",
    "## Add legend\n",
    "# Add the custom legend handle to the legend\n",
    "lgd = plt.legend(all_scores, handletextpad=0.01, bbox_to_anchor=[1.06, -0.27],\n",
    "           fontsize=9, ncol=6, columnspacing=0.5, frameon=False)\n",
    "\n",
    "# plot log curve\n",
    "X_fit = np.linspace(200, 15000, num=100, dtype=int)\n",
    "curve_val = np.log(X_fit) / np.log(2)\n",
    "plt.plot(np.log(X_fit)/ np.log(2), curve_val, color='k')\n",
    "\n",
    "# figure parameters\n",
    "ax.set_ylim([6, 16])\n",
    "#ax.set_xlim([8, 15.5])\n",
    "orsp.format_scatter_plot('log\\N{SUBSCRIPT TWO}(Total Scan Duration)',\n",
    "                    'Norm. reliability', ax)\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS32_ScanTime_Log_AllBehavCurves_Tstats_10m.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c1bb3",
   "metadata": {},
   "source": [
    "# Fig S33: BWAS scatter plot for ABCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8536c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = ABCD_rs_log_ind\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for n in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    for limit in [10,5]:\n",
    "        orsp.plot_scatter(6,behav,scan_duration,ABCD_subcolors,limit,axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].legend(ABCD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "        orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                            'Reliability (ICC)', axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].set_xlim(0,26000)\n",
    "        axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "        axs[plot_y][plot_x].set_title(scores_names[n] + ' (' + str(limit*2) + 'mins)')\n",
    "        \n",
    "        # move to next plot\n",
    "        if plot_x == 0:\n",
    "            plot_x += 1\n",
    "        else:\n",
    "            plot_x = 0\n",
    "            if plot_y != 2:\n",
    "                plot_y += 1\n",
    "            else: \n",
    "                plot_y = 0\n",
    "        # move to next figure\n",
    "        if (behav_count % 3) == 0 and limit == 5:\n",
    "            fig.savefig(os.path.join(img_dir, 'FigS33.' + str(plot_num) +\n",
    "                    '_ABCD_KRR_full_BWAS_scatter.svg'), bbox_inches='tight')\n",
    "            fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "            fig.tight_layout(h_pad=5, w_pad=7)\n",
    "            plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS33.' + str(plot_num) +\n",
    "                '_ABCD_KRR_full_BWAS_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371dfeb8",
   "metadata": {},
   "source": [
    "# Fig S34: BWAS scatter plot for HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471c6db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = HCP_rs_log_ind\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for n in behav_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,n].T),1)\n",
    "    for limit in [29,5]:\n",
    "        orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,limit,axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].legend(HCP_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "        orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                            'Reliability (ICC)', axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].set_xlim(0,26000)\n",
    "        axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "        axs[plot_y][plot_x].set_title(scores_names[n] + ' (' + str(limit*2) + 'mins)')\n",
    "        \n",
    "        # move to next plot\n",
    "        if plot_x == 0:\n",
    "            plot_x += 1\n",
    "        else:\n",
    "            plot_x = 0\n",
    "            if plot_y != 2:\n",
    "                plot_y += 1\n",
    "            else: \n",
    "                plot_y = 0\n",
    "        # move to next figure\n",
    "        if (behav_count % 3) == 0 and limit == 5:\n",
    "            fig.savefig(os.path.join(img_dir, 'FigS34.' + str(plot_num) +\n",
    "                    '_HCP_KRR_full_BWAS_scatter.svg'), bbox_inches='tight')\n",
    "            fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "            fig.tight_layout(h_pad=5, w_pad=7)\n",
    "            plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS34.' + str(plot_num) +\n",
    "                    '_HCP_KRR_full_BWAS_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c8ba53",
   "metadata": {},
   "source": [
    "# Fig S35: Reliability N and T are not equivalent (BWAS - factor score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10bae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Violin plot comparing same total scan time\n",
    "#################################################\n",
    "# ABCD: 2400 total scan time but different N and T\n",
    "b = 36\n",
    "n_seeds = 126\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','tstats',rep_dir)\n",
    "mat = os.path.join(ABCD_img_dir,'tstats_icc_indiv_landscape.mat')\n",
    "res = scipy.io.loadmat(mat)\n",
    "\n",
    "# extract points with 6000m of total scan time\n",
    "full_df = pd.DataFrame()\n",
    "twom_vals = []\n",
    "fourm_vals = []\n",
    "sixm_vals = []\n",
    "twelm_vals = []\n",
    "for n in range(0,n_seeds):\n",
    "    behav = res['tstats_landscape'][:,:,n,b]\n",
    "    dtwo = pd.DataFrame(data={'rel': [behav[5,0]]})\n",
    "    dtwo['Time'] = '2'\n",
    "    dtwo['Subs'] = '1200subs'\n",
    "    twom_vals.append(behav[5,0])\n",
    "    dfour = pd.DataFrame(data={'rel': [behav[2,1]]})\n",
    "    dfour['Time'] = '4'\n",
    "    dfour['Subs'] = '600subs'\n",
    "    fourm_vals.append(behav[2,1])\n",
    "    dsix = pd.DataFrame(data={'rel': [behav[1,2]]})\n",
    "    dsix['Time'] = '6'\n",
    "    dsix['Subs'] = '400subs'\n",
    "    sixm_vals.append(behav[1,2])\n",
    "    dtwel = pd.DataFrame(data={'rel': [behav[0,5]]})\n",
    "    dtwel['Time'] = '12'\n",
    "    dtwel['Subs'] = '200subs'\n",
    "    twelm_vals.append(behav[0,5])\n",
    "    full_df = pd.concat([full_df, dtwo, dfour, dsix, dtwel])\n",
    "\n",
    "# plot violin plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "vp=sns.violinplot(data=full_df, x=\"Time\", y=\"rel\", palette=\"Reds_r\",orient='v')\n",
    "vp.set(xticklabels=[])\n",
    "orsp.format_scatter_plot('', 'Reliability (ICC)', ax)\n",
    "fig.savefig(os.path.join(img_dir,'FigS35_ABCD_not1to1_violin.svg'), bbox_inches='tight')\n",
    "\n",
    "# mean accuracy\n",
    "print('2m mean:', np.mean(twom_vals))\n",
    "print('4m mean:', np.mean(fourm_vals))\n",
    "print('6m mean:', np.mean(sixm_vals))\n",
    "print('12m mean:', np.mean(twelm_vals))\n",
    "\n",
    "# stats\n",
    "print('2m vs 4m:', scipy.stats.ttest_rel(twom_vals, fourm_vals)) \n",
    "print('4m vs 6m:', scipy.stats.ttest_rel(fourm_vals, sixm_vals))\n",
    "print('6m vs 12m:', scipy.stats.ttest_rel(sixm_vals, twelm_vals))\n",
    "\n",
    "print('2m vs 4m:', orsp.corrected_resample_ttest([a - b for a, b in zip(twom_vals, fourm_vals)], 1/1, 0))\n",
    "print('4m vs 6m:', orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, sixm_vals)], 1/1, 0))\n",
    "print('6m vs 12m:', orsp.corrected_resample_ttest([a - b for a, b in zip(sixm_vals, twelm_vals)], 1/1, 0))\n",
    "\n",
    "# save pvals for FDR\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(twom_vals, fourm_vals)], 1/1, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, sixm_vals)], 1/1, 0))\n",
    "p_list.append(orsp.corrected_resample_ttest([a - b for a, b in zip(sixm_vals, twelm_vals)], 1/1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afd393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perform FDR\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "print(p_list)\n",
    "fdrcorrection(p_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d02d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Tom's theoretical equations\n",
    "#################################################\n",
    "# load HCP results\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'tstats', rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'tstats', rep_dir)\n",
    "b = 59\n",
    "behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,b].T),1)\n",
    "# scatter plot with theoretical equation fit\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "orsp.plot_scatter(len(Y),behav,scan_duration,HCP_subcolors,len(X),ax)\n",
    "# Tom's equation fit to full duration\n",
    "w = w_r_all[b,-1,:]\n",
    "X_fit = np.linspace(2, 58, num=100, dtype=int)\n",
    "for sub_lvl in range(0,len(Y)):\n",
    "    curve_val = w[0] / (w[0] + (1/(Y[sub_lvl]/2)) * (1 - 2*w[1]/(1+(w[2]/X_fit))))\n",
    "    plt.plot(X_fit*Y[sub_lvl], curve_val, color=HCP_theor_subcolors[sub_lvl])\n",
    "lgd = plt.legend(HCP_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,\n",
    "                 handletextpad=0.05, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                    'Reliability (ICC)', ax)\n",
    "fig.savefig(os.path.join(img_dir,'FigS35_HCP_CogFactor_Theoretical_rel.svg'), bbox_inches='tight')\n",
    "\n",
    "# load ABCD results\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'tstats', rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'tstats', rep_dir)\n",
    "b = 36\n",
    "behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,b].T),1)\n",
    "# scatter plot with theoretical equation fit\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "orsp.plot_scatter(len(Y),behav,scan_duration,ABCD_subcolors,len(X),ax)\n",
    "# Tom's equation fit to full duration\n",
    "w = w_r_all[b,-1,:]\n",
    "X_fit = np.linspace(2, 20, num=100, dtype=int)\n",
    "for sub_lvl in range(0,len(Y)):\n",
    "    curve_val = w[0] / (w[0] + (1/(Y[sub_lvl]/2)) * (1 - 2*w[1]/(1+(w[2]/X_fit))))\n",
    "    plt.plot(X_fit*Y[sub_lvl], curve_val, color=ABCD_theor_subcolors[sub_lvl])\n",
    "lgd = plt.legend(ABCD_lgd, Y, markerscale=2, ncol=2, labelspacing=0.1,\n",
    "                 handletextpad=0.05, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                    'Reliability (ICC)', ax)\n",
    "fig.savefig(os.path.join(img_dir,'FigS35_ABCD_CogFactor_Theoretical_rel.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573c02a",
   "metadata": {},
   "source": [
    "# Fig S36: N and T are not equivalent (BWAS - all scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfd948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Violin plot comparing same total scan time\n",
    "#################################################\n",
    "# ABCD: 2400 total scan time but different N and T\n",
    "c_vers = 'full'\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir,vers=c_vers)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','tstats',rep_dir,vers=c_vers)\n",
    "mat = os.path.join(ABCD_img_dir,'tstats_icc_indiv_landscape.mat')\n",
    "res = scipy.io.loadmat(mat)\n",
    "\n",
    "# extract points with 2400m of total scan time\n",
    "full_df = pd.DataFrame()\n",
    "twom_vals = []\n",
    "fourm_vals = []\n",
    "sixm_vals = []\n",
    "twelm_vals = []\n",
    "for b in ABCD_rs_log_ind:\n",
    "    behav = np.mean(res['tstats_landscape'][:,:,:,b],2)\n",
    "    dtwo = pd.DataFrame(data={'rel': [behav[5,0]]})\n",
    "    dtwo['Time'] = '2'\n",
    "    dtwo['Subs'] = '1200subs'\n",
    "    twom_vals.append(behav[5,0])\n",
    "    dfour = pd.DataFrame(data={'rel': [behav[2,1]]})\n",
    "    dfour['Time'] = '4'\n",
    "    dfour['Subs'] = '600subs'\n",
    "    fourm_vals.append(behav[2,1])\n",
    "    dsix = pd.DataFrame(data={'rel': [behav[1,2]]})\n",
    "    dsix['Time'] = '6'\n",
    "    dsix['Subs'] = '400subs'\n",
    "    sixm_vals.append(behav[1,2])\n",
    "    dtwel = pd.DataFrame(data={'rel': [behav[0,5]]})\n",
    "    dtwel['Time'] = '12'\n",
    "    dtwel['Subs'] = '200subs'\n",
    "    twelm_vals.append(behav[0,5])\n",
    "    full_df = pd.concat([full_df, dtwo, dfour, dsix, dtwel])\n",
    "\n",
    "# plot violin plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "vp=sns.violinplot(data=full_df, x=\"Time\", y=\"rel\", palette=\"Reds_r\",orient='v')\n",
    "orsp.format_scatter_plot('', 'Reliability (ICC)', ax)\n",
    "vp.set(xticklabels=[])\n",
    "ax.set_title('ABCD')\n",
    "fig.savefig(os.path.join(img_dir,'FigS36_ABCD_not1to1_violin.svg'), bbox_inches='tight')\n",
    "\n",
    "# mean accuracy\n",
    "print('2m mean:', np.mean(twom_vals))\n",
    "print('4m mean:', np.mean(fourm_vals))\n",
    "print('6m mean:', np.mean(sixm_vals))\n",
    "print('12m mean:', np.mean(twelm_vals))\n",
    "\n",
    "# stats\n",
    "print('2m vs 4m:', scipy.stats.ttest_rel(twom_vals, fourm_vals)) \n",
    "print('4m vs 6m:', scipy.stats.ttest_rel(fourm_vals, sixm_vals))\n",
    "print('6m vs 12m:', scipy.stats.ttest_rel(sixm_vals, twelm_vals))\n",
    "\n",
    "print('2m vs 4m:', orsp.corrected_resample_ttest([a - b for a, b in zip(twom_vals, fourm_vals)], 1/1, 0))\n",
    "print('4m vs 6m:', orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, sixm_vals)], 1/1, 0))\n",
    "print('6m vs 12m:', orsp.corrected_resample_ttest([a - b for a, b in zip(sixm_vals, twelm_vals)], 1/1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Violin plot comparing same total scan time\n",
    "#################################################\n",
    "# ABCD: 2400 total scan time but different N and T\n",
    "c_vers = 'full'\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir,vers=c_vers)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir,vers=c_vers)\n",
    "mat = os.path.join(HCP_img_dir,'tstats_icc_indiv_landscape.mat')\n",
    "res = scipy.io.loadmat(mat)\n",
    "\n",
    "# extract points with 1600m of total scan time\n",
    "full_df = pd.DataFrame()\n",
    "twom_vals = []\n",
    "fourm_vals = []\n",
    "sixm_vals = []\n",
    "twelm_vals = []\n",
    "for b in HCP_rs_log_ind:\n",
    "    behav = np.mean(res['tstats_landscape'][:,:,:,b],2)\n",
    "    dtwo = pd.DataFrame(data={'rel': [behav[5,1]]})\n",
    "    dtwo['Time'] = '4'\n",
    "    dtwo['Subs'] = '400subs'\n",
    "    twom_vals.append(behav[5,1])\n",
    "    dfour = pd.DataFrame(data={'rel': [behav[1,3]]})\n",
    "    dfour['Time'] = '8'\n",
    "    dfour['Subs'] = '200subs'\n",
    "    fourm_vals.append(behav[1,3])\n",
    "    dsix = pd.DataFrame(data={'rel': [behav[0,4]]})\n",
    "    dsix['Time'] = '~10'\n",
    "    dsix['Subs'] = '150subs'\n",
    "    sixm_vals.append(behav[0,4])\n",
    "    full_df = pd.concat([full_df, dtwo, dfour, dsix])\n",
    "\n",
    "# plot violin plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "vp=sns.violinplot(data=full_df, x=\"Time\", y=\"rel\", palette=\"Blues_r\",orient='v')\n",
    "orsp.format_scatter_plot('', 'Reliability (ICC)', ax)\n",
    "ax.set_title('HCP')\n",
    "vp.set(xticklabels=[])\n",
    "fig.savefig(os.path.join(img_dir,'FigS36_HCP_not1to1_violin.svg'), bbox_inches='tight')\n",
    "\n",
    "# mean accuracy\n",
    "print('4m mean:', np.mean(twom_vals))\n",
    "print('8m mean:', np.mean(fourm_vals))\n",
    "print('10m mean:', np.mean(sixm_vals))\n",
    "\n",
    "# stats\n",
    "print('4m vs 8m:', scipy.stats.ttest_rel(twom_vals, fourm_vals)) \n",
    "print('8m vs 10m:', scipy.stats.ttest_rel(fourm_vals, sixm_vals))\n",
    "\n",
    "print('4m vs 8m:', orsp.corrected_resample_ttest([a - b for a, b in zip(twom_vals, fourm_vals)], 1/1, 0))\n",
    "print('8m vs 10m:', orsp.corrected_resample_ttest([a - b for a, b in zip(fourm_vals, sixm_vals)], 1/1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43acd4d",
   "metadata": {},
   "source": [
    "# Fig S37: Theoretical fit for ABCD scores (BWAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ed0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','tstats',rep_dir,)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = ABCD_rs_log_ind\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['tstats_icc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(6,behav,scan_duration,ABCD_subcolors,10,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(ABCD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "             ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                            'Reliability (ICC)', axs[plot_y][plot_x])\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_r_all[b,-1,:]\n",
    "    X_fit = np.linspace(2, 20, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] / (w[0] + (1/(Y[sub_lvl]/2)) * (1 - 2*w[1]/(1+(w[2]/X_fit))))\n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=ABCD_subcolors[sub_lvl])\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS37.' + str(plot_num) +\n",
    "                '_ABCD_KRR_full_Tstats_TheoreticalFit_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS37.' + str(plot_num) +\n",
    "                '_ABCD_KRR_full_Tstats_TheoreticalFit_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a223a5f",
   "metadata": {},
   "source": [
    "# Fig S38: Theoretical fit for HCP scores (reliability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ba7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','tstats',rep_dir,)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = HCP_rs_log_ind\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for b in behav_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['tstats_icc_landscape'][:,:,b].T),1)\n",
    "    orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,29,axs[plot_y][plot_x])\n",
    "    axs[plot_y][plot_x].legend(HCP_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "             ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "    orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                            'Reliability (ICC)', axs[plot_y][plot_x])\n",
    "    # Tom's equation fit to full duration\n",
    "    w = w_r_all[b,-1,:]\n",
    "    X_fit = np.linspace(2, 58, num=100, dtype=int)\n",
    "    for sub_lvl in range(0,len(Y)):\n",
    "        curve_val = w[0] / (w[0] + (1/(Y[sub_lvl]/2)) * (1 - 2*w[1]/(1+(w[2]/X_fit))))\n",
    "        axs[plot_y][plot_x].plot(Y[sub_lvl]*X_fit, curve_val, color=HCP_subcolors[sub_lvl])\n",
    "    axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "    axs[plot_y][plot_x].set_title(scores_names[b])\n",
    "\n",
    "    # move to next plot\n",
    "    if plot_x == 0:\n",
    "        plot_x += 1\n",
    "    else:\n",
    "        plot_x = 0\n",
    "        if plot_y != 2:\n",
    "            plot_y += 1\n",
    "        else: \n",
    "            plot_y = 0\n",
    "    # move to next figure\n",
    "    if (behav_count % 6) == 0:\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS38.' + str(plot_num) +\n",
    "                '_HCP_KRR_full_Tstats_TheoreticalFit_scatter.svg'), bbox_inches='tight')\n",
    "        fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "        fig.tight_layout(h_pad=5, w_pad=7)\n",
    "        plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS38.' + str(plot_num) +\n",
    "                '_HCP_KRR_full_Tstats_TheoreticalFit_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2dcc4c",
   "metadata": {},
   "source": [
    "# Fig S39: Fit vs ICC\n",
    "# Fig S40: Shuffling (Tstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49718a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Acc against fit (ABCD)\n",
    "#################################################\n",
    "c_vers = 'full'\n",
    "cod_thresh = 0.8\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','predacc',rep_dir, vers = c_vers)\n",
    "ABCD_img_dir,rel_ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','tstats',rep_dir, vers = c_vers)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD', 'tstats', rep_dir, vers= c_vers)\n",
    "# score classifications\n",
    "bpass = []\n",
    "bfit = []\n",
    "cog_ind = np.array([9,10,11,12,13,14,15,16,17,18,31,32,33,34,35,36,37])-1\n",
    "per_ind = np.array([19,20,21,22,23,24,25,26,27])-1\n",
    "mh_ind = np.array([1,2,3,4,5,6,7,8,28,29,30])-1\n",
    "acc_all = np.array([])\n",
    "rel_all = np.array([])\n",
    "log_loss = np.array([])\n",
    "r_loss = np.array([])\n",
    "log_limit = 5\n",
    "r_limit = 10\n",
    "# remove unwanted scores\n",
    "for b_idx in range(0,37):\n",
    "    behav_acc = np.flip(np.flip(ABCD_res['acc_landscape'][:,:,b_idx].T),1)\n",
    "    behav_rel = np.flip(np.flip(rel_ABCD_res['tstats_icc_landscape'][:,:,b_idx].T),1)\n",
    "    if (np.sum(behav.flatten() < 0) < 10): # remove scores with > 10% negative predictions\n",
    "        bpass.append(b_idx)\n",
    "        if loss_log_all[b_idx,limit-3] > cod_thresh:\n",
    "            bfit.append(b_idx)\n",
    "    acc_all = np.append(acc_all, behav_acc[8,9])\n",
    "    rel_all = np.append(rel_all, behav_rel[5,9])\n",
    "    log_loss = np.append(log_loss, loss_log_all[b_idx,log_limit-3])\n",
    "    r_loss = np.append(r_loss , loss_r_all[b_idx,r_limit-3])\n",
    "for i in cog_ind:\n",
    "    if i not in bpass:\n",
    "        cog_ind = np.delete(cog_ind, np.where(cog_ind==i))\n",
    "for i in per_ind:\n",
    "    if i not in bpass:\n",
    "        per_ind = np.delete(per_ind, np.where(per_ind==i))\n",
    "for i in mh_ind:\n",
    "    if i not in bpass:\n",
    "        mh_ind = np.delete(mh_ind, np.where(mh_ind==i)) \n",
    "# final list of scores for reference\n",
    "print(\"Scores < 10% negative:\", bpass)\n",
    "print(\"Chosen scores:\", bfit)\n",
    "        \n",
    "# log fit at 10m\n",
    "print(\"Log Fit:\", scipy.stats.spearmanr(log_loss[bpass],rel_all[bpass]))\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "plt.scatter(rel_all[cog_ind],log_loss[cog_ind], c='orangered')\n",
    "plt.scatter(rel_all[per_ind],log_loss[per_ind], c='darkslateblue')\n",
    "plt.scatter(rel_all[mh_ind],log_loss[mh_ind], c='darkgray')\n",
    "plt.legend(['Cognition', 'Personality', 'Mental Health'], loc=\"lower right\", frameon=False,\n",
    "            prop={'family' : 'Arial'}, labelspacing=0.1,handletextpad=0.05, fontsize=10)\n",
    "orsp.format_scatter_plot('Reliability (ICC)','Goodness of fit (COD)',ax, fontsz=10)\n",
    "ax.set_title('ABCD (Logarithm)')\n",
    "# plot trend line\n",
    "x = rel_all[bpass]\n",
    "x_new = np.linspace(np.min(x), np.max(x), 50)\n",
    "y_new = f(x_new)\n",
    "y_new = 1 - np.exp(-5*x_new)\n",
    "plt.plot(x_new, y_new, color='k',linestyle='dashed')\n",
    "fig.savefig(os.path.join(img_dir,'FigS39_ABCD_AccvsFit_Log.svg'), bbox_inches='tight')\n",
    "# Nichols fit at 20m\n",
    "print(\"Theoretical Fit:\", scipy.stats.spearmanr(r_loss[bpass],rel_all[bpass]))\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "plt.scatter(rel_all[cog_ind],r_loss[cog_ind], c='orangered')\n",
    "plt.scatter(rel_all[per_ind],r_loss[per_ind], c='darkslateblue')\n",
    "plt.scatter(rel_all[mh_ind],r_loss[mh_ind], c='darkgray')\n",
    "plt.legend(['Cognition', 'Personality', 'Mental Health'], loc=\"lower right\", frameon=False,\n",
    "          prop={'family' : 'Arial'}, labelspacing=0.1,handletextpad=0.05, fontsize=10)\n",
    "orsp.format_scatter_plot('Reliability (ICC)','Goodness of fit (COD)',ax, fontsz=10)\n",
    "ax.set_xlim([-0.05,1])\n",
    "ax.set_ylim([-0.1,1])\n",
    "ax.set_title('ABCD (Theoretical)')\n",
    "# plot trend line\n",
    "x = rel_all[bpass]\n",
    "x_new = np.linspace(np.min(x), np.max(x), 50)\n",
    "y_new = f(x_new)\n",
    "y_new = 1 - np.exp(-5*x_new)\n",
    "plt.plot(x_new, y_new, color='k',linestyle='dashed')\n",
    "fig.savefig(os.path.join(img_dir,'FigS39_ABCD_AccvsFit_Theoretical.svg'), bbox_inches='tight')\n",
    "\n",
    "#################################################\n",
    "# Improvement to fit after shuffling (ABCD)\n",
    "#################################################\n",
    "# load ABCD data\n",
    "w_r_f,w_pa_f,zk_f,loss_r_f,loss_pa_f,loss_log_f = orsp.load_fits('ABCD','tstats',rep_dir,vers='full')\n",
    "w_r_r,w_pa_r,zk_r,loss_r_r,loss_pa_r,loss_log_r = orsp.load_fits('ABCD','tstats',rep_dir,vers='random')\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "# t test for selected behaviors\n",
    "print(\"Log:\", scipy.stats.ttest_rel(loss_log_f[bpass,r_limit-3], loss_log_r[bpass,r_limit-3]))\n",
    "df = pd.DataFrame(data={'COD': loss_log_f[bpass,r_limit-3]})\n",
    "df['Domain'] = 'Log Fit'\n",
    "df['Class'] = 'Original'\n",
    "dr = pd.DataFrame(data={'COD': loss_log_r[bpass,r_limit-3]})\n",
    "dr['Domain'] = 'Log Fit'\n",
    "dr['Class'] = 'Randomized'\n",
    "full_df = pd.concat([full_df, df, dr])\n",
    "print(\"Theoretical:\", scipy.stats.ttest_rel(loss_r_f[bpass,r_limit-3], loss_r_r[bpass,r_limit-3]))\n",
    "df = pd.DataFrame(data={'COD': loss_r_f[bpass,r_limit-3]})\n",
    "df['Domain'] = 'Theoretical Fit'\n",
    "df['Class'] = 'Original'\n",
    "dr = pd.DataFrame(data={'COD': loss_r_r[bpass,r_limit-3]})\n",
    "dr['Domain'] = 'Theoretical Fit'\n",
    "dr['Class'] = 'Randomized'\n",
    "full_df = pd.concat([full_df, df, dr])\n",
    "# plot box plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "sns.boxplot(data=full_df, x=\"Domain\", y=\"COD\", hue=\"Class\",palette=\"Reds\",orient='v')\n",
    "plt.legend(frameon=False, fontsize=10, bbox_to_anchor=(0.68,0.23))\n",
    "orsp.format_scatter_plot('','Goodness of fit (COD)',ax, fontsz=10)\n",
    "ax.set_title('ABCD')\n",
    "ax.set_ylim([-0.1,1])\n",
    "fig.savefig(os.path.join(img_dir,'FigS40_ABCD_origvsrandom.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ebe95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Acc against fit (HCP)\n",
    "#################################################\n",
    "c_vers = 'full'\n",
    "cod_thresh = 0.8\n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','predacc',rep_dir, vers=c_vers)\n",
    "HCP_img_dir,rel_HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','tstats',rep_dir, vers=c_vers)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP', 'tstats', rep_dir, vers=c_vers)\n",
    "# score classifications\n",
    "bpass = []\n",
    "bfit = []\n",
    "cog_ind = np.array([1,2,3,4,5,6,7,9,10,11,12,13,14,25,26,27,28,29,30,59])-1\n",
    "per_ind = np.array([8,31,32,33,34,35])-1\n",
    "emo_ind = np.array([24,36,37,38,39,40,41,42,43,44,45,46,47])-1\n",
    "phy_ind = np.array([15,16,17,18,19,20,21,22,23])-1\n",
    "wb_ind = np.array([48,49,50,51,52,53,54,55,56,57,58])-1\n",
    "acc_all = np.array([])\n",
    "log_loss = np.array([])\n",
    "r_loss = np.array([])\n",
    "log_limit = 5\n",
    "r_limit = 29\n",
    "# remove unwanted scores\n",
    "for b_idx in range(0,60):\n",
    "    behav_acc = np.flip(np.flip(HCP_res['acc_landscape'][:,:,b_idx].T),1)\n",
    "    behav_rel = np.flip(np.flip(rel_HCP_res['tstats_icc_landscape'][:,:,b_idx].T),1)\n",
    "    if (np.sum(behav.flatten() < 0) < 18) and b_idx != 58: # remove scores with > 10% negative predictions\n",
    "        bpass.append(b_idx)\n",
    "        if loss_log_all[b_idx,limit-3] > cod_thresh:\n",
    "            bfit.append(b_idx)\n",
    "    acc_all = np.append(acc_all, behav_acc[5,28])\n",
    "    rel_all = np.append(rel_all, behav_rel[5,28])\n",
    "    log_loss = np.append(log_loss, loss_log_all[b_idx,log_limit-3])\n",
    "    r_loss = np.append(r_loss, loss_r_all[b_idx,r_limit-3])\n",
    "for i in cog_ind:\n",
    "    if i not in bpass:\n",
    "        cog_ind = np.delete(cog_ind, np.where(cog_ind==i))\n",
    "for i in per_ind:\n",
    "    if i not in bpass:\n",
    "        per_ind = np.delete(per_ind, np.where(per_ind==i))\n",
    "for i in emo_ind:\n",
    "    if i not in bpass:\n",
    "        emo_ind = np.delete(emo_ind, np.where(emo_ind==i))\n",
    "for i in phy_ind:\n",
    "    if i not in bpass:\n",
    "        phy_ind = np.delete(phy_ind, np.where(phy_ind==i))\n",
    "for i in wb_ind:\n",
    "    if i not in bpass:\n",
    "        wb_ind = np.delete(wb_ind, np.where(wb_ind==i))  \n",
    "# final list of scores for reference\n",
    "print(\"Scores < 10% negative:\", bpass)\n",
    "print(\"Chosen scores:\", bfit)\n",
    "        \n",
    "# log fit at 10m\n",
    "print(\"Log Fit:\", scipy.stats.spearmanr(log_loss[bpass],rel_all[bpass]))\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "plt.scatter(rel_all[cog_ind],log_loss[cog_ind], c='orangered')\n",
    "plt.scatter(rel_all[per_ind],log_loss[per_ind], c='darkslateblue')\n",
    "plt.scatter(rel_all[emo_ind],log_loss[emo_ind], c='forestgreen')\n",
    "plt.scatter(rel_all[phy_ind],log_loss[phy_ind], c='goldenrod')\n",
    "plt.scatter(rel_all[wb_ind],log_loss[wb_ind], c='deeppink')\n",
    "plt.legend(['Cognition','Personality','Emotion', 'Physical','Well-being'], prop={'family' : 'Arial'},\n",
    "           loc=\"best\", labelspacing=0.1,handletextpad=0.05, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Reliability (ICC)','Goodness of fit (COD)',ax, fontsz=10)\n",
    "# plot trend line\n",
    "x = rel_all[bpass]\n",
    "x_new = np.linspace(np.min(x), np.max(x), 50)\n",
    "y_new = f(x_new)\n",
    "y_new = 1 - np.exp(-5*x_new)\n",
    "plt.plot(x_new, y_new, color='k',linestyle='dashed')\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_title('HCP (Logarithm)')\n",
    "fig.savefig(os.path.join(img_dir,'FigS39_HCP_AccvsFit_Log.svg'), bbox_inches='tight')\n",
    "\n",
    "# Nichols fit at 58m\n",
    "print(\"Theoretical Fit:\", scipy.stats.spearmanr(r_loss[bpass],rel_all[bpass]))\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "plt.scatter(rel_all[cog_ind],r_loss[cog_ind], c='orangered')\n",
    "plt.scatter(rel_all[per_ind],r_loss[per_ind], c='darkslateblue')\n",
    "plt.scatter(rel_all[emo_ind],r_loss[emo_ind], c='forestgreen')\n",
    "plt.scatter(rel_all[phy_ind],r_loss[phy_ind], c='goldenrod')\n",
    "plt.scatter(rel_all[wb_ind],r_loss[wb_ind], c='deeppink')\n",
    "plt.legend(['Cognition','Personality','Emotion', 'Physical','Well-being'], prop={'family' : 'Arial'},\n",
    "           loc=\"lower right\", labelspacing=0.1,handletextpad=0.05, frameon=False, fontsize=10)\n",
    "orsp.format_scatter_plot('Reliability (ICC)','Goodness of fit (COD)',ax, fontsz=10)\n",
    "# plot trend line\n",
    "x = rel_all[bpass]\n",
    "x_new = np.linspace(np.min(x), np.max(x), 50)\n",
    "y_new = f(x_new)\n",
    "y_new = 1 - np.exp(-5*x_new)\n",
    "plt.plot(x_new, y_new, color='k',linestyle='dashed')\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_title('HCP (Theoretical)')\n",
    "fig.savefig(os.path.join(img_dir,'FigS39_HCP_AccvsFit_Theoretical.svg'), bbox_inches='tight')\n",
    "\n",
    "#################################################\n",
    "# Improvement to fit after shuffling (HCP)\n",
    "#################################################\n",
    "# load HCP data\n",
    "w_r_f,w_pa_f,zk_f,loss_r_f,loss_pa_f,loss_log_f = orsp.load_fits('HCP','tstats',rep_dir,vers='full')\n",
    "w_r_r,w_pa_r,zk_r,loss_r_r,loss_pa_r,loss_log_r = orsp.load_fits('HCP','tstats',rep_dir,vers='random')\n",
    "full_df = pd.DataFrame()\n",
    "\n",
    "# t test for selected behaviors\n",
    "# use all 58 min for comparison\n",
    "print(\"Log:\", scipy.stats.ttest_rel(loss_log_f[bpass,r_limit-3], loss_log_r[bpass,r_limit-3]))\n",
    "df = pd.DataFrame(data={'COD': loss_log_f[bpass,r_limit-3]})\n",
    "df['Domain'] = 'Log Fit'\n",
    "df['Class'] = 'Original'\n",
    "dr = pd.DataFrame(data={'COD': loss_log_r[bpass,r_limit-3]})\n",
    "dr['Domain'] = 'Log Fit'\n",
    "dr['Class'] = 'Randomized'\n",
    "full_df = pd.concat([full_df, df, dr])\n",
    "\n",
    "print(\"Theoretical:\", scipy.stats.ttest_rel(loss_pa_f[bpass,r_limit-3], loss_pa_r[bpass,r_limit-3]))\n",
    "df = pd.DataFrame(data={'COD': loss_pa_f[bpass,r_limit-3]})\n",
    "df['Domain'] = 'Theoretical Fit'\n",
    "df['Class'] = 'Original'\n",
    "dr = pd.DataFrame(data={'COD': loss_pa_r[bpass,r_limit-3]})\n",
    "dr['Domain'] = 'Theoretical Fit'\n",
    "dr['Class'] = 'Randomized'\n",
    "full_df = pd.concat([full_df, df, dr])\n",
    "# plot box plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "sns.boxplot(data=full_df, x=\"Domain\", y=\"COD\", hue=\"Class\",palette=\"Blues\",orient='v')\n",
    "plt.legend(frameon=False, bbox_to_anchor=[0.82, 0.1], fontsize=10)\n",
    "orsp.format_scatter_plot('','Goodness of fit (COD)',ax,fontsz=10)\n",
    "ax.set_title('HCP')\n",
    "fig.savefig(os.path.join(img_dir,'FigS40_HCP_origvsrandom.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasthere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d7ae5",
   "metadata": {},
   "source": [
    "# Fig S41: Haufe Contour plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a1a1f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot contour plots\n",
    "#################################################\n",
    "fig,axs = plt.subplots(1,2,figsize=(8.5,4.5))\n",
    "fig.tight_layout(pad=7)\n",
    "\n",
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "# Cognition\n",
    "con_lines = [0.3, 0.4, 0.45]\n",
    "manual_locations = [(6.5,1.5),(10,3),(25,5)]\n",
    "behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,59].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, HCP_extent, \n",
    "                      fig, axs[1], Yax_lbl='ICC', Ax_Ttl='HCP')\n",
    "\n",
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','Haufe',rep_dir)\n",
    "# Cognition\n",
    "con_lines = [0.4, 0.65, 0.75]\n",
    "manual_locations = [(1,0.3),(4,2),(8,6)]\n",
    "behav = np.flip(np.flip(ABCD_res['fi_icc_landscape'][:,:,36].T),1)\n",
    "orsp.plot_contour(behav, X, Y, con_lines, manual_locations, ABCD_extent, \n",
    "                      fig, axs[0], Yax_lbl='ICC', Ax_Ttl='ABCD')\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS41_' +\n",
    "                    'KRR_full_rel_Haufe_cog_contour.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545449f6",
   "metadata": {},
   "source": [
    "# Fig S42: Correlation between common points in ABCD and HCP contour plots (Haufe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a96c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'Haufe', rep_dir)\n",
    "behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,59].T),1)\n",
    "hcp_behav = behav[[1,5],:10].ravel()\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'Haufe', rep_dir)\n",
    "behav = np.flip(np.flip(ABCD_res['fi_icc_landscape'][:,:,36].T),1)\n",
    "abcd_behav = behav[:2,:].ravel()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6, 6))\n",
    "plt.scatter(abcd_behav,hcp_behav)\n",
    "res = scipy.stats.linregress(abcd_behav,hcp_behav)\n",
    "xy_line = np.linspace(0.05,0.65,100)\n",
    "plt.plot(xy_line , res.intercept + res.slope*xy_line , 'k', linestyle='--')\n",
    "orsp.format_scatter_plot('ABCD Reliability (ICC)',\n",
    "                    'HCP Reliability (ICC)', ax)\n",
    "corr_val = np.corrcoef(abcd_behav,hcp_behav)\n",
    "ax.text(0.8,0.1,'r = ' + str(np.round(corr_val[0][1],2)), transform=ax.transAxes, size=12)\n",
    "plt.yticks(np.arange(0.1, 0.65, step=0.1)) \n",
    "plt.xticks(np.arange(0.1, 0.65, step=0.1)) \n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS42_ABCD_HCP_KRR_commonpts_haufe_correlation.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c0e031",
   "metadata": {},
   "source": [
    "# Fig S43: Haufe scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa599eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot scatter plot against total scan time\n",
    "#################################################\n",
    "limit=5\n",
    "# load HCP data\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP', 'Haufe', rep_dir)\n",
    "behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,59].T),1)\n",
    "# plot scatter plot\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "#orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,58,ax)\n",
    "#orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,limit,ax,outline='Y')\n",
    "for n_subs in range(0,6)[::-1]:\n",
    "    beh = behav[n_subs, :limit]\n",
    "    curr_scan = scan_duration[n_subs, :limit]\n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=beh.flatten(), ax=ax,\n",
    "                            color=HCP_subcolors[n_subs],s=40)\n",
    "for n_subs in range(0,6):\n",
    "    beh = behav[n_subs, limit:]\n",
    "    curr_scan = scan_duration[n_subs, limit:]\n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=beh.flatten(), ax=ax,\n",
    "                            color=HCP_subcolors[n_subs], edgecolor=\"k\", linewidth=0.75, s=30)\n",
    "orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                    'Reliability (ICC)', ax)\n",
    "lgd = plt.legend(HCP_lgd, Y, markerscale=2, \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "fig.savefig(os.path.join(img_dir, 'FigS43_HCP_Haufe_icc.svg'), bbox_inches='tight')\n",
    "\n",
    "# load ABCD data\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD', 'Haufe', rep_dir)\n",
    "behav = np.flip(np.flip(ABCD_res['fi_icc_landscape'][:,:,36].T),1)\n",
    "# Plot scatter\n",
    "fig,ax = plt.subplots(figsize=(4, 3))\n",
    "#orsp.plot_scatter(6,behav,scan_duration,ABCD_subcolors,10,ax)\n",
    "#orsp.plot_scatter(6,behav,scan_duration,ABCD_subcolors,limit,ax,outline='Y')\n",
    "for n_subs in range(0,6)[::-1]:\n",
    "    beh = behav[n_subs, :limit]\n",
    "    curr_scan = scan_duration[n_subs, :limit]\n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=beh.flatten(), ax=ax,\n",
    "                            color=ABCD_subcolors[n_subs],s=40)\n",
    "for n_subs in range(0,6):\n",
    "    beh = behav[n_subs, limit:]\n",
    "    curr_scan = scan_duration[n_subs, limit:]\n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=beh.flatten(), ax=ax,\n",
    "                            color=ABCD_subcolors[n_subs], edgecolor=\"k\", linewidth=0.75, s=30)\n",
    "orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                    'Reliability (ICC)', ax)\n",
    "lgd = plt.legend(ABCD_lgd, Y, markerscale=2, \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "fig.savefig(os.path.join(img_dir, 'FigS43_ABCD_Haufe_icc.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot individual scores\n",
    "#################################################\n",
    "fig,ax = plt.subplots(figsize=(8.5, 3.5))\n",
    "all_scores = []\n",
    "legend_handle = []\n",
    "lgd_handles = []\n",
    "HCP_cog_ind = [1,2,3,4,5,6,8,10,25,26,29,59]\n",
    "HCP_emo_ind = [23]\n",
    "HCP_pers_ind = [7,31,32,34]\n",
    "HCP_phy_ind = [14]\n",
    "HCP_wb_ind = [47]\n",
    "ABCD_cog_ind = [8,10,11,13,14,15,16,17,30,31,32,33,36]\n",
    "ABCD_mh_ind = [5,29,6,3]\n",
    "    \n",
    "### cognition\n",
    "## ABCD\n",
    "limit = 5\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "for n in ABCD_cog_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(),color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_cog_ind[:-1]], ['ABCD Cog. Factor']))\n",
    "\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "for n in HCP_cog_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_cog_ind[:-1]], ['HCP Cog. Factor']))\n",
    "\n",
    "### mental health\n",
    "limit = 5\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:lightgrey,darkgrey\", n_colors=4)\n",
    "for n in ABCD_mh_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(),color=custom_colors[n_c], zorder=-1)\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_mh_ind]))\n",
    "\n",
    "### personality\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:powderblue,darkslateblue\", n_colors=4)\n",
    "for n in HCP_pers_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_pers_ind]))\n",
    "\n",
    "\n",
    "### physical\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:gold,gold\", n_colors=2)\n",
    "for n in HCP_phy_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_phy_ind]))\n",
    "\n",
    "### emotion\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:forestgreen,forestgreen\", n_colors=2)\n",
    "for n in HCP_emo_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_emo_ind]))\n",
    "\n",
    "### well being\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:magenta,magenta\", n_colors=2)\n",
    "for n in HCP_wb_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=curr_scan.flatten(), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_wb_ind]))\n",
    "\n",
    "# plot fitted curve\n",
    "orsp.plot_curve(200, 15000)\n",
    "\n",
    "# figure parameters\n",
    "ax.set_ylim([6, 16])\n",
    "orsp.format_scatter_plot('Total scan duration (# participants x scan time per participant)',\n",
    "                    'Norm. reliability', ax)\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS43_ScanTime_AllBehavCurves_Haufe_10m.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e456859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# plot individual scores\n",
    "#################################################\n",
    "fig,ax = plt.subplots(figsize=(8.5, 2.5))\n",
    "all_scores = []\n",
    "legend_handle = []\n",
    "lgd_handles = []\n",
    "HCP_cog_ind = [1,2,3,4,5,6,8,10,25,26,29,59]\n",
    "HCP_emo_ind = [23]\n",
    "HCP_pers_ind = [7,31,32,34]\n",
    "HCP_phy_ind = [14]\n",
    "HCP_wb_ind = [47]\n",
    "ABCD_cog_ind = [8,10,11,13,14,15,16,17,30,31,32,33,36]\n",
    "ABCD_mh_ind = [5,29,6,3]\n",
    "    \n",
    "### cognition\n",
    "## ABCD\n",
    "limit = 5\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:bisque,orangered\", n_colors=13)\n",
    "for n in ABCD_cog_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(),color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_cog_ind[:-1]], ['Cog Factor (A)']))\n",
    "\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "for n in HCP_cog_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_cog_ind[:-1]], ['Cog Factor (H)']))\n",
    "\n",
    "### mental health\n",
    "limit = 5\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('ABCD','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:lightgrey,darkgrey\", n_colors=4)\n",
    "for n in ABCD_mh_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(),color=custom_colors[n_c], zorder=-1)\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, ABCD_scores_short[ABCD_mh_ind]))\n",
    "\n",
    "### personality\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:powderblue,darkslateblue\", n_colors=4)\n",
    "for n in HCP_pers_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_pers_ind]))\n",
    "\n",
    "\n",
    "### physical\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:gold,gold\", n_colors=2)\n",
    "for n in HCP_phy_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_phy_ind]))\n",
    "\n",
    "### emotion\n",
    "## HCP\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:forestgreen,forestgreen\", n_colors=2)\n",
    "for n in HCP_emo_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_emo_ind]))\n",
    "\n",
    "### well being\n",
    "limit = 5\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "w_r_all,w_pa_all,zk_all,loss_r_all,loss_pa_all,loss_log_all = orsp.load_fits('HCP','Haufe',rep_dir)\n",
    "n_c = 0\n",
    "custom_colors = sns.color_palette(\"blend:magenta,magenta\", n_colors=2)\n",
    "for n in HCP_wb_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    curr_scan = scan_duration[:,:limit]\n",
    "    behav = behav[:,:limit]\n",
    "    z = zk_all[n,limit-3,0]\n",
    "    k = zk_all[n,limit-3,1]\n",
    "    norm_acc = (behav - k) / z \n",
    "    sns.scatterplot(x=np.log(curr_scan.flatten())/ np.log(2), y=norm_acc.flatten(), color=custom_colors[n_c])\n",
    "    n_c += 1\n",
    "all_scores = np.concatenate((all_scores, HCP_scores_short[HCP_wb_ind]))\n",
    "\n",
    "## Add legend\n",
    "# Add the custom legend handle to the legend\n",
    "lgd = plt.legend(all_scores, handletextpad=0.01, loc='lower center', bbox_to_anchor=[0.48, -0.95],\n",
    "            fontsize=9, ncol=6, columnspacing=0.5, frameon=False)\n",
    "\n",
    "# plot log curve\n",
    "X_fit = np.linspace(200, 15000, num=100, dtype=int)\n",
    "curve_val = np.log(X_fit) / np.log(2)\n",
    "plt.plot(np.log(X_fit)/ np.log(2), curve_val, color='k')\n",
    "\n",
    "# figure parameters\n",
    "ax.set_ylim([6, 16])\n",
    "#ax.set_xlim([8, 15.5])\n",
    "orsp.format_scatter_plot('log\\N{SUBSCRIPT TWO}(Total Scan Duration)',\n",
    "                    'Norm. reliability', ax)\n",
    "\n",
    "fig.savefig(os.path.join(img_dir, 'FigS43_ScanTime_Log_AllBehavCurves_Haufe_10m.svg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59dd0ad",
   "metadata": {},
   "source": [
    "# Fig S44: Haufe scatter plot for ABCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444cbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for ABCD\n",
    "ABCD_img_dir,ABCD_res,X,Y,ABCD_extent,scan_duration = orsp.load_data('ABCD','Haufe',rep_dir)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = ABCD_rs_log_ind\n",
    "scores_names = np.append(ABCD_scores, ['Cognition Factor Score',\n",
    "                         'Mental Health Factor Score', 'Personality Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for n in behav_ind:\n",
    "    behav = np.flip(np.flip(ABCD_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    for limit in [10,5]:\n",
    "        orsp.plot_scatter(6,behav,scan_duration,ABCD_subcolors,limit,axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].legend(ABCD_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "        orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                            'Reliability (ICC)', axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].set_xlim(0,26000)\n",
    "        axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "        axs[plot_y][plot_x].set_title(scores_names[n] + ' (' + str(limit*2) + 'mins)')\n",
    "        \n",
    "        # move to next plot\n",
    "        if plot_x == 0:\n",
    "            plot_x += 1\n",
    "        else:\n",
    "            plot_x = 0\n",
    "            if plot_y != 2:\n",
    "                plot_y += 1\n",
    "            else: \n",
    "                plot_y = 0\n",
    "        # move to next figure\n",
    "        if (behav_count % 3) == 0 and limit == 5:\n",
    "            fig.savefig(os.path.join(img_dir, 'FigS44.' + str(plot_num) +\n",
    "                    '_ABCD_KRR_full_Haufe_scatter.svg'), bbox_inches='tight')\n",
    "            fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "            fig.tight_layout(h_pad=5, w_pad=7)\n",
    "            plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS44.' + str(plot_num) +\n",
    "                '_ABCD_KRR_full_Haufe_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d9556",
   "metadata": {},
   "source": [
    "# Fig S45: Haufe scatter plot for HCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings for HCP\n",
    "HCP_img_dir,HCP_res,X,Y,HCP_extent,scan_duration = orsp.load_data('HCP','Haufe',rep_dir)\n",
    "\n",
    "# initialize cognition scores\n",
    "behav_ind = HCP_rs_log_ind\n",
    "scores_names = np.append(HCP_scores, ['Dissatisfaction Factor Score',\n",
    "                         'Cognition Factor Score', 'Emotion Factor Score'])\n",
    "\n",
    "# plot scatter plots into 6 subplots\n",
    "fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "fig.tight_layout(h_pad=5, w_pad=7)\n",
    "behav_count = 1\n",
    "plot_num = 1\n",
    "plot_x = 0\n",
    "plot_y = 0\n",
    "for n in behav_ind:\n",
    "    behav = np.flip(np.flip(HCP_res['fi_icc_landscape'][:,:,n].T),1)\n",
    "    for limit in [29,5]:\n",
    "        orsp.plot_scatter(6,behav,scan_duration,HCP_subcolors,limit,axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].legend(HCP_lgd, Y, markerscale=2, loc='lower right', \\\n",
    "                 ncol=2, labelspacing=0.1, handletextpad=0.05, frameon=False, fontsize=10)\n",
    "        orsp.format_scatter_plot('Total scan duration (# participants \\nx scan time per participant)',\n",
    "                            'Reliability (ICC)', axs[plot_y][plot_x])\n",
    "        axs[plot_y][plot_x].set_xlim(0,26000)\n",
    "        axs[plot_y][plot_x].set_ylim(np.min(behav)-0.05,np.max(behav)+0.05)\n",
    "        axs[plot_y][plot_x].set_title(scores_names[n] + ' (' + str(limit*2) + 'mins)')\n",
    "        \n",
    "        # move to next plot\n",
    "        if plot_x == 0:\n",
    "            plot_x += 1\n",
    "        else:\n",
    "            plot_x = 0\n",
    "            if plot_y != 2:\n",
    "                plot_y += 1\n",
    "            else: \n",
    "                plot_y = 0\n",
    "        # move to next figure\n",
    "        if (behav_count % 3) == 0 and limit == 5:\n",
    "            fig.savefig(os.path.join(img_dir, 'FigS45.' + str(plot_num) +\n",
    "                    '_HCP_KRR_full_Haufe_scatter.svg'), bbox_inches='tight')\n",
    "            fig,axs = plt.subplots(3,2,figsize=(7.5,9.5))\n",
    "            fig.tight_layout(h_pad=5, w_pad=7)\n",
    "            plot_num += 1\n",
    "    # continue behavior count\n",
    "    # turn off remaining subplots if last behavior\n",
    "    if behav_count == len(behav_ind):\n",
    "        while plot_y != 3:\n",
    "            axs[plot_y][plot_x].axis('off')\n",
    "            if plot_x == 0:\n",
    "                plot_x += 1\n",
    "            else:\n",
    "                plot_x = 0\n",
    "                if plot_y != 3:\n",
    "                    plot_y += 1\n",
    "        fig.savefig(os.path.join(img_dir, 'FigS45.' + str(plot_num) +\n",
    "                    '_HCP_KRR_full_Haufe_scatter.svg'), bbox_inches='tight')\n",
    "    else:\n",
    "        behav_count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
